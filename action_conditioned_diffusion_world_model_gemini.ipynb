{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b40e0f-8c29-4a90-9e82-5995ef5a0506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import datetime\n",
    "import csv\n",
    "import config\n",
    "from torch.utils.data import random_split\n",
    "from importnb import Notebook\n",
    "with Notebook():\n",
    "    from jetbot_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e89e9ec-9f79-4a17-800e-243b0864cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Diffusion Helpers ---\n",
    "def linear_beta_schedule(timesteps, beta_start, beta_end):\n",
    "    return torch.linspace(beta_start, beta_end, timesteps)\n",
    "\n",
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps, dtype=torch.float64)\n",
    "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * np.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return torch.clip(betas, 0, 0.999)\n",
    "\n",
    "def get_index_from_list(vals, t, x_shape):\n",
    "    batch_size = t.shape[0]\n",
    "    out = vals.gather(-1, t)\n",
    "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n",
    "\n",
    "def forward_diffusion_sample(x_0, t, betas, alphas_cumprod, device=\"cpu\"):\n",
    "    noise = torch.randn_like(x_0)\n",
    "    sqrt_alphas_cumprod_t = get_index_from_list(torch.sqrt(alphas_cumprod), t, x_0.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(\n",
    "        torch.sqrt(1. - alphas_cumprod), t, x_0.shape\n",
    "    )\n",
    "    return sqrt_alphas_cumprod_t * x_0 + sqrt_one_minus_alphas_cumprod_t * noise, noise\n",
    "\n",
    "# --- U-Net Model ---\n",
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = np.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        # Ensure output matches the embedding dim even if input dim is odd\n",
    "        if self.dim % 2 == 1:\n",
    "             embeddings = F.pad(embeddings, (0, 1))\n",
    "        return embeddings\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, time_emb_dim, up=False):\n",
    "        super().__init__()\n",
    "        # Adjusted time_mlp input dimension\n",
    "        self.time_mlp =  nn.Linear(time_emb_dim, out_ch)\n",
    "        if up:\n",
    "            # Adjusted Conv2d input channels for concatenation\n",
    "            self.conv1 = nn.Conv2d(2*in_ch, out_ch, 3, padding=1)\n",
    "            self.transform = nn.ConvTranspose2d(out_ch, out_ch, 4, 2, 1)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
    "            self.transform = nn.Conv2d(out_ch, out_ch, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
    "        self.bnorm1 = nn.BatchNorm2d(out_ch)\n",
    "        self.bnorm2 = nn.BatchNorm2d(out_ch)\n",
    "        self.relu  = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, t_emb): # Modified to accept pre-computed embedding\n",
    "        h = self.bnorm1(self.relu(self.conv1(x)))\n",
    "        # Time embedding - Project and add\n",
    "        time_emb_proj = self.relu(self.time_mlp(t_emb))\n",
    "        time_emb_proj = time_emb_proj[(..., ) + (None, ) * 2] # Reshape for spatial broadcast\n",
    "        h = h + time_emb_proj # Add time embedding\n",
    "        h = self.bnorm2(self.relu(self.conv2(h)))\n",
    "        return self.transform(h)\n",
    "        \n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self, image_channels=3, time_emb_dim=32, num_prev_frames=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # --- Increased Channel Depth and Added Layer ---\n",
    "        down_channels = (128, 256, 512, 512) # Increased channels, added a level\n",
    "        up_channels = (512, 512, 256, 128)   # Increased channels, added a level\n",
    "\n",
    "        # Input channels = current frame + previous frames\n",
    "        in_img_channels = image_channels * (num_prev_frames + 1)\n",
    "        action_dim = 1 # Single motor action\n",
    "\n",
    "        # Effective embedding dimension including action\n",
    "        effective_time_emb_dim = time_emb_dim + action_dim\n",
    "\n",
    "        # Time embedding MLP\n",
    "        self.time_mlp = nn.Sequential(\n",
    "                SinusoidalPositionEmbeddings(time_emb_dim),\n",
    "                nn.Linear(time_emb_dim, time_emb_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "        # --- Model Layers ---\n",
    "        self.conv0 = nn.Conv2d(in_img_channels, down_channels[0], 3, padding=1)\n",
    "\n",
    "        self.downs = nn.ModuleList([])\n",
    "        for i in range(len(down_channels)-1):\n",
    "            self.downs.append(Block(down_channels[i], down_channels[i+1], effective_time_emb_dim))\n",
    "\n",
    "        # Bottleneck (implicitly defined by channel changes)\n",
    "        # No extra bottleneck block needed here, just the transition\n",
    "\n",
    "        self.ups = nn.ModuleList([])\n",
    "        for i in range(len(up_channels)-1):\n",
    "            self.ups.append(Block(up_channels[i], up_channels[i+1], effective_time_emb_dim, up=True))\n",
    "\n",
    "        # Final output layer (outputs noise prediction, same channels as original image)\n",
    "        self.output = nn.Conv2d(up_channels[-1], image_channels, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x, timestep, action, prev_frames):\n",
    "        # x: noisy next frame (batch, 3, H, W)\n",
    "        # timestep: (batch,)\n",
    "        # action: (batch, 1)\n",
    "        # prev_frames: (batch, num_prev_frames * 3, H, W)\n",
    "\n",
    "        # Concatenate the current noisy image with the previous frames\n",
    "        x = torch.cat([x, prev_frames], dim=1) # Shape: (batch, (N+1)*C, H, W)\n",
    "\n",
    "        # --- Prepare Time and Action Embedding ---\n",
    "        t_emb = self.time_mlp(timestep) # Shape: (batch, time_emb_dim)\n",
    "        if action is not None:\n",
    "            action = action.float()\n",
    "            if len(action.shape) == 1:\n",
    "                 action = action.unsqueeze(1) # Ensure shape is (batch, 1)\n",
    "            # Concatenate time embedding and action embedding\n",
    "            t_action_emb = torch.cat([t_emb, action], dim=1) # Shape: (batch, time_emb_dim + 1)\n",
    "        else:\n",
    "            # Handle cases where action might be None (e.g., unconditional generation if needed later)\n",
    "            # Pad action dimensions if needed - adjust padding based on your effective_time_emb_dim\n",
    "            padding = torch.zeros(t_emb.shape[0], 1, device=t_emb.device)\n",
    "            t_action_emb = torch.cat([t_emb, padding], dim=1)\n",
    "        # --- End Embedding Prep ---\n",
    "\n",
    "        # --- U-Net Architecture ---\n",
    "        x = self.conv0(x) # Initial processing of combined input\n",
    "        residual_inputs = []\n",
    "        # Downsampling path\n",
    "        for i, down_block in enumerate(self.downs):\n",
    "            x = down_block(x, t_action_emb) # Pass combined embedding to blocks\n",
    "            residual_inputs.append(x)\n",
    "\n",
    "        # Upsampling path\n",
    "        for i, up_block in enumerate(self.ups):\n",
    "            residual_x = residual_inputs.pop()\n",
    "            x = torch.cat((x, residual_x), dim=1) # Concatenate skip connection\n",
    "            x = up_block(x, t_action_emb) # Pass combined embedding to blocks\n",
    "\n",
    "        return self.output(x) # Predict noise\n",
    "\n",
    "# --- Training Loop ---\n",
    "def train(model, dataloader, optimizer, betas, alphas_cumprod, start_epoch, num_epochs,\n",
    "          device, save_every, sample_every, checkpoint_dir, sample_dir, plot_dir,\n",
    "          plot_every, use_fp16, accumulation_steps, num_prev_frames,\n",
    "          early_stopping_patience, early_stopping_percentage, min_epochs):\n",
    "    \"\"\"\n",
    "    Trains the diffusion model with early stopping and best model saving/deletion.\n",
    "    \"\"\"\n",
    "\n",
    "    all_losses = []\n",
    "    start_time = time.time()\n",
    "    last_plot_epoch = start_epoch - 1\n",
    "    best_loss = float('inf')\n",
    "    best_epoch = start_epoch\n",
    "    epochs_without_improvement = 0\n",
    "    moving_avg_window = 10\n",
    "    moving_avg_losses = []\n",
    "    previous_best_model_path = None  # Keep track of the previous best model's path\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_fp16)\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        model.train()\n",
    "        epoch_losses = []\n",
    "        optimizer.zero_grad()\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        for step, (images, actions, prev_frames) in enumerate(pbar):\n",
    "            images = images.to(device)\n",
    "            actions = actions.to(device)\n",
    "            prev_frames = prev_frames.to(device)\n",
    "            t = torch.randint(0, config.NUM_TIMESTEPS, (images.shape[0],), device=device).long()\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=use_fp16):\n",
    "                x_noisy, noise = forward_diffusion_sample(images, t, betas, alphas_cumprod, device)\n",
    "                predicted_noise = model(x_noisy, t, actions, prev_frames)\n",
    "                loss = F.mse_loss(noise, predicted_noise)\n",
    "                loss = loss / accumulation_steps\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (step + 1) % accumulation_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            epoch_losses.append(loss.item() * accumulation_steps)\n",
    "            pbar.set_postfix({\"Loss\": loss.item() * accumulation_steps})\n",
    "\n",
    "        if optimizer.param_groups[0]['params'][0].grad is not None:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        avg_epoch_loss = sum(epoch_losses) / len(epoch_losses)  if epoch_losses else float('nan') # Handle empty epoch_losses\n",
    "        if np.isnan(avg_epoch_loss):\n",
    "            print(f\"Warning: NaN loss detected for epoch {epoch+1}. Skipping update/plot.\")\n",
    "            # Optionally: break or handle NaN case differently\n",
    "            continue\n",
    "        all_losses.append(avg_epoch_loss)\n",
    "\n",
    "        moving_avg_losses.append(avg_epoch_loss)\n",
    "        if len(moving_avg_losses) > moving_avg_window:\n",
    "            moving_avg_losses.pop(0)\n",
    "        current_moving_avg = sum(moving_avg_losses) / len(moving_avg_losses)\n",
    "\n",
    "        if (epoch + 1) % save_every == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_epoch_loss,\n",
    "            }, os.path.join(checkpoint_dir, f\"model_epoch_{epoch+1}.pth\"))\n",
    "            print(f\"Saved model checkpoint at epoch {epoch+1}\")\n",
    "\n",
    "        if (epoch + 1) % sample_every == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                random_idx = torch.randint(0, len(dataset), (1,)).item()\n",
    "                real_current_frame, action, real_prev_frames = dataset[random_idx]\n",
    "                real_current_frame = real_current_frame.unsqueeze(0).to(device)\n",
    "                real_prev_frames = real_prev_frames.unsqueeze(0).to(device)\n",
    "                action = action.to(device)\n",
    "\n",
    "                t_sample = torch.tensor([config.NUM_TIMESTEPS - 1], device=device, dtype=torch.long)\n",
    "                x_noisy, _ = forward_diffusion_sample(real_current_frame, t_sample, betas, alphas_cumprod, device)\n",
    "                x = x_noisy\n",
    "\n",
    "                for i in reversed(range(1, config.NUM_TIMESTEPS)):\n",
    "                    t = (torch.ones(1) * i).long().to(device)\n",
    "                    with torch.cuda.amp.autocast(enabled=use_fp16):\n",
    "                        predicted_noise = model(x, t, action, real_prev_frames)\n",
    "\n",
    "                    alpha = alphas[t][:, None, None, None]\n",
    "                    alpha_hat = alphas_cumprod[t][:, None, None, None]\n",
    "                    beta = betas[t][:, None, None, None]\n",
    "\n",
    "                    if i > 1:\n",
    "                        noise = torch.randn_like(x)\n",
    "                    else:\n",
    "                        noise = torch.zeros_like(x)\n",
    "                    x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
    "                predicted_next_frame = (x.clamp(-1, 1) + 1) / 2\n",
    "                predicted_next_frame = (predicted_next_frame * 255).type(torch.uint8)\n",
    "                prev_images = []\n",
    "\n",
    "                for i in range(num_prev_frames):\n",
    "                    frame = real_prev_frames[0, (i * 3):(i + 1) * 3, :, :]\n",
    "                    frame = (frame.clamp(-1, 1) + 1) / 2\n",
    "                    frame = (frame * 255).type(torch.uint8)\n",
    "                    prev_images.append(transforms.ToPILImage()(frame))\n",
    "\n",
    "                current_tensor = (real_current_frame[0].clamp(-1, 1) + 1) / 2 * 255\n",
    "                current_image = transforms.ToPILImage()(current_tensor.type(torch.uint8)).convert(\"RGB\")\n",
    "                predicted_image = transforms.ToPILImage()(predicted_next_frame[0]).convert(\"RGB\")\n",
    "\n",
    "                total_width = (num_prev_frames + 2) * config.IMAGE_SIZE\n",
    "                max_height = config.IMAGE_SIZE\n",
    "                new_im = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "                x_offset = 0\n",
    "                for image in prev_images:\n",
    "                    new_im.paste(image, (x_offset,0))\n",
    "                    x_offset += config.IMAGE_SIZE\n",
    "                new_im.paste(current_image, (x_offset, 0))\n",
    "                x_offset += config.IMAGE_SIZE\n",
    "                new_im.paste(predicted_image, (x_offset, 0))\n",
    "\n",
    "                new_im.save(os.path.join(sample_dir, f\"sample_epoch_{epoch+1}.png\"))\n",
    "                print(f\"Saved sample image at epoch {epoch+1}\")\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            print(f\"Epoch {epoch+1}, Step {step}:\")\n",
    "            print(f\"  Mem Allocated: {torch.cuda.memory_allocated(config.DEVICE) / 1024**2:.2f} MB\")\n",
    "            print(f\"  Max Mem Allocated: {torch.cuda.max_memory_allocated(config.DEVICE) / 1024**2:.2f} MB\")\n",
    "            print(f\"  Mem Reserved: {torch.cuda.memory_reserved(config.DEVICE) / 1024**2:.2f} MB\")\n",
    "            print(f\"  Max Mem Reserved: {torch.cuda.max_memory_reserved(config.DEVICE) / 1024**2:.2f} MB\")\n",
    "        \n",
    "        \n",
    "        if (epoch + 1) % plot_every == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            formatted_time = str(datetime.timedelta(seconds=elapsed_time))\n",
    "    \n",
    "            fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "    \n",
    "            # --- Plot 1: Loss from START_EPOCH of this run ---\n",
    "            # X-axis: Absolute epoch numbers (start_epoch + 1 up to current epoch + 1)\n",
    "            # Y-axis: Losses collected *in this run* (all_losses indices 0 up to current)\n",
    "            current_run_epochs_plotted = range(start_epoch + 1, epoch + 2)\n",
    "            axes[0].plot(current_run_epochs_plotted, all_losses)\n",
    "            axes[0].set_xlabel(\"Epoch\")\n",
    "            axes[0].set_ylabel(\"Loss\")\n",
    "            axes[0].set_title(f\"Loss Since Start (Epoch {start_epoch+1}, Time: {formatted_time})\")\n",
    "            axes[0].grid(True)\n",
    "    \n",
    "            # --- Plot 2: Loss since last plot ---\n",
    "            # X-axis: Absolute epoch numbers for the segment\n",
    "            x_values_ax1 = range(last_plot_epoch + 2, epoch + 2)\n",
    "    \n",
    "            # Y-axis: Slice all_losses using indices relative to this run's start\n",
    "            # Calculate indices corresponding to the absolute epoch numbers\n",
    "            start_slice_index = (last_plot_epoch + 1) - start_epoch # Index in all_losses for epoch last_plot_epoch+1\n",
    "            end_slice_index = (epoch + 1) - start_epoch           # Index in all_losses for epoch epoch+1 (exclusive)\n",
    "            y_values_ax1 = all_losses[start_slice_index : end_slice_index]\n",
    "    \n",
    "            if x_values_ax1 and y_values_ax1:\n",
    "                if len(x_values_ax1) != len(y_values_ax1):\n",
    "                     # This check should ideally not be needed with correct logic, but good safeguard\n",
    "                     print(f\"!!! ERROR: Mismatch detected plotting axes[1]: len(x)={len(x_values_ax1)}, len(y)={len(y_values_ax1)}\")\n",
    "                else:\n",
    "                    axes[1].plot(x_values_ax1, y_values_ax1)\n",
    "                    axes[1].set_xlabel(\"Epoch\")\n",
    "                    axes[1].set_ylabel(\"Loss\")\n",
    "                    axes[1].set_title(f\"Loss Since Epoch {last_plot_epoch + 1}\")\n",
    "                    axes[1].grid(True)\n",
    "            else:\n",
    "                 axes[1].set_title(f\"Loss Since Epoch {last_plot_epoch + 1} (No new data)\")\n",
    "                 axes[1].grid(True)\n",
    "    \n",
    "    \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(plot_dir, f\"loss_plot_epoch_{epoch+1}.png\"))\n",
    "            plt.close()\n",
    "            print(f\"Epoch {epoch+1}: Avg Loss = {avg_epoch_loss:.6f}, Moving Avg = {current_moving_avg:.6f}, Time = {formatted_time}\")\n",
    "    \n",
    "            last_plot_epoch = epoch # Update absolute last plot epoch index\n",
    "\n",
    "        # --- Early Stopping (Dynamic Threshold) and Best Model Saving/Deletion---\n",
    "        if early_stopping_patience is not None and epoch + 1 > min_epochs:\n",
    "            if current_moving_avg < best_loss:\n",
    "                best_loss = current_moving_avg\n",
    "                best_epoch = epoch + 1\n",
    "                epochs_without_improvement = 0\n",
    "\n",
    "                # Save the *best* model\n",
    "                new_best_model_path = os.path.join(checkpoint_dir, f\"model_best_epoch_{best_epoch}.pth\")\n",
    "                torch.save({\n",
    "                    'epoch': best_epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': best_loss,  # Save the best loss\n",
    "                }, new_best_model_path)\n",
    "                print(f\"Saved best model at epoch {best_epoch} with loss {best_loss}\")\n",
    "\n",
    "                # Delete the *previous* best model (if it exists)\n",
    "                if previous_best_model_path and os.path.exists(previous_best_model_path):\n",
    "                    os.remove(previous_best_model_path)\n",
    "                    print(f\"Deleted previous best model: {previous_best_model_path}\")\n",
    "                previous_best_model_path = new_best_model_path # Update the path\n",
    "\n",
    "            else:\n",
    "                epochs_without_improvement += 1\n",
    "\n",
    "            if epochs_without_improvement >= early_stopping_patience:\n",
    "                if len(moving_avg_losses) == moving_avg_window:\n",
    "                    prev_moving_avg = sum(moving_avg_losses[:-1]) / (moving_avg_window - 1)\n",
    "                    improvement = (prev_moving_avg - current_moving_avg) / prev_moving_avg * 100\n",
    "                if improvement < early_stopping_percentage:\n",
    "                    print(f\"Early stopping triggered at epoch {epoch+1}.  Improvement: {improvement:.2f}%\")\n",
    "                    break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    formatted_time = str(datetime.timedelta(seconds=total_time))\n",
    "    print(f\"Total training time: {formatted_time}\")\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': avg_epoch_loss,\n",
    "    }, os.path.join(checkpoint_dir, \"model_last.pth\"))\n",
    "    print(f\"Saved last model at epoch {epoch+1} with loss {avg_epoch_loss}\")\n",
    "\n",
    "    return all_losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356d5ca4-d8af-471b-afce-8023111e6f15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded combined CSV with columns: ['session_id', 'image_path', 'timestamp', 'action']\n",
      "Total rows in CSV: 23081, Valid sequence start indices: 23037\n",
      "Loaded existing dataset split.\n",
      "Loaded checkpoint from epoch 45\n",
      "--- Training Configuration ---\n",
      "Model Parameters: 34,956,835\n",
      "  Mem Allocated: 537.50 MB\n",
      "  Max Mem Allocated: 537.50 MB\n",
      "  Mem Reserved: 554.00 MB\n",
      "  Max Mem Reserved: 554.00 MB\n",
      "--------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c076d0564bac4494b6d8f95d3410c9bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 46\n",
      "Epoch 46, Step 4607:\n",
      "  Mem Allocated: 563.15 MB\n",
      "  Max Mem Allocated: 1854.76 MB\n",
      "  Mem Reserved: 2238.00 MB\n",
      "  Max Mem Reserved: 2238.00 MB\n",
      "Saved best model at epoch 46 with loss 0.0026981648200950937\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67afa02138fb4f08a98e81e0b41dd9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 47\n",
      "Epoch 47, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2240.00 MB\n",
      "  Max Mem Reserved: 2240.00 MB\n",
      "Saved best model at epoch 47 with loss 0.00264527996398398\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_46.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c922d1ba0d434dca81645b19fa10613e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 48\n",
      "Epoch 48, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2240.00 MB\n",
      "  Max Mem Reserved: 2240.00 MB\n",
      "Saved best model at epoch 48 with loss 0.0026370867454843434\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_47.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879de979bca347d8833ec01c3f33a84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 49\n",
      "Epoch 49, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2240.00 MB\n",
      "  Max Mem Reserved: 2240.00 MB\n",
      "Saved best model at epoch 49 with loss 0.0026286655644965785\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_48.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5db18a77f224c79b2b244a8b8d10b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 50\n",
      "Epoch 50, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Epoch 50: Avg Loss = 0.002438, Moving Avg = 0.002591, Time = 1:08:04.441282\n",
      "Saved best model at epoch 50 with loss 0.0025906079998564897\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_49.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbcb020fe40c4ab1b15e26cf3af12d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 51/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 51\n",
      "Epoch 51, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Saved best model at epoch 51 with loss 0.0025814538655132076\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_50.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3fbb28acdd46af98eac93ae0e657e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 52/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 52\n",
      "Epoch 52, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Saved best model at epoch 52 with loss 0.0025814245701020083\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_51.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7068b4400e4226a04c53eaeb57d12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 53/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 53\n",
      "Epoch 53, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Saved best model at epoch 53 with loss 0.002552939325357113\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_52.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e562fe87384cfd9c0468c3f54d7b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 54/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 54\n",
      "Epoch 54, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Saved best model at epoch 54 with loss 0.002548779446864961\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_53.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f624184bb334f2897470a2c8bfcaf99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 55/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 55\n",
      "Epoch 55, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Saved best model at epoch 55 with loss 0.0025299194315774936\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_54.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19e96577f73476e9637a6c7fc9b1aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 56/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 56\n",
      "Epoch 56, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Saved best model at epoch 56 with loss 0.0025021579898588837\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_55.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2eb741941174eed9651d7550a82e35c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 57/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 57\n",
      "Epoch 57, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Saved best model at epoch 57 with loss 0.002496046151012226\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_56.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2da312fee214261a3063b57c19b7170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 58/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 58\n",
      "Epoch 58, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Saved best model at epoch 58 with loss 0.002485351083412961\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_57.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d67c0a220840319fd4911b1c87a3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 59/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 59\n",
      "Epoch 59, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Saved best model at epoch 59 with loss 0.002467426008808597\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_58.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c24988bc07b44bea9409df4ae7092d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 60/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 60\n",
      "Epoch 60, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Epoch 60: Avg Loss = 0.002468, Moving Avg = 0.002470, Time = 3:22:31.579400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1163f26d40524c89b5a7c7d0c3635f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 61/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 61\n",
      "Epoch 61, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Saved best model at epoch 61 with loss 0.002459503233069426\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_59.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783463de98944313bc36f72c1add372b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 62/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 62\n",
      "Epoch 62, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Saved best model at epoch 62 with loss 0.0024449884532348025\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742f6e296ea248fab66b66eb0a1af1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 63/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 63\n",
      "Epoch 63, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a2af90575a4b45a7f5d1fa6de7690c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 64/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 64\n",
      "Epoch 64, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Saved best model at epoch 64 with loss 0.0024309510097582335\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_62.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e27b71c74a426d8da95cefc906726e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 65/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 65\n",
      "Epoch 65, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Saved best model at epoch 65 with loss 0.002413161471441564\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_64.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fac934aa4434e4eba34b0ab143edbb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 66/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 66\n",
      "Epoch 66, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Saved best model at epoch 66 with loss 0.002395367413291972\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_65.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "553bd8f9240c41cdb492ea527367391f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 67/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 67\n",
      "Epoch 67, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Saved best model at epoch 67 with loss 0.002379805663510284\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_66.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c1d639bffe3446b9607aa0c72be9ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 68/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 68\n",
      "Epoch 68, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801835e8bb9a4c7a9eb69b1cc0f641aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 69/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 69\n",
      "Epoch 69, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Saved best model at epoch 69 with loss 0.0023679036107643646\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_67.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0279f7fc6c4e8595f4c428782ee2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 70/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 70\n",
      "Epoch 70, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Epoch 70: Avg Loss = 0.002476, Moving Avg = 0.002369, Time = 5:36:27.711079\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7739b90ab8dc438a8fffaa5e1740c4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 71/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 71\n",
      "Epoch 71, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Saved best model at epoch 71 with loss 0.00235959810770857\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_69.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d57495af2574c5fa9d5a5b189aa243b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 72/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample image at epoch 96\n",
      "Epoch 96, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Saved best model at epoch 96 with loss 0.0021212030719788624\n",
      "Deleted previous best model: output_two_action_model_v2_test\\checkpoints\\model_best_epoch_95.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e4399c106b44a5b7c581f2f7e9fd1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 97/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model checkpoint at epoch 100\n",
      "Saved sample image at epoch 100\n",
      "Epoch 100, Step 4607:\n",
      "  Mem Allocated: 562.94 MB\n",
      "  Max Mem Allocated: 1859.26 MB\n",
      "  Mem Reserved: 2242.00 MB\n",
      "  Max Mem Reserved: 2242.00 MB\n",
      "Epoch 100: Avg Loss = 0.002223, Moving Avg = 0.002137, Time = 12:16:57.753558\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee0ba799acb440298e211a76940e7974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 101/1000:   0%|          | 0/4608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # --- Data Transforms ---\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((config.IMAGE_SIZE, config.IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "    # --- Create Dataset and DataLoader ---\n",
    "    dataset = JetbotDataset(config.CSV_PATH, config.DATA_DIR, config.IMAGE_SIZE, config.NUM_PREV_FRAMES, transform=transform)\n",
    "    \n",
    "    # Try to load existing split\n",
    "    train_dataset, test_dataset = load_train_test_split(dataset, config.SPLIT_DATASET_FILENAME)\n",
    "    \n",
    "    if train_dataset is None or test_dataset is None:\n",
    "        print(\"Dataset split file not found, creating a new split...\")\n",
    "        train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "        test_size = len(dataset) - train_size\n",
    "        train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "    \n",
    "        save_existing_split(train_dataset, test_dataset, config.SPLIT_DATASET_FILENAME)\n",
    "    else:\n",
    "        print(\"Loaded existing dataset split.\")\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False) # Batch size 1 for easier evaluation\n",
    "    \n",
    "    # --- Calculate Betas and Alphas ---\n",
    "    betas = linear_beta_schedule(config.NUM_TIMESTEPS, config.BETA_START, config.BETA_END).to(config.DEVICE)\n",
    "    #betas = cosine_beta_schedule(NUM_TIMESTEPS).to(DEVICE) # Alternative\n",
    "    \n",
    "    alphas = (1. - betas).to(config.DEVICE)\n",
    "    alphas_cumprod = torch.cumprod(alphas, axis=0).to(config.DEVICE)\n",
    "    alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0).to(config.DEVICE)\n",
    "    sqrt_recip_alphas = torch.sqrt(1.0 / alphas).to(config.DEVICE)\n",
    "    \n",
    "    # --- Create Model and Optimizer ---\n",
    "    model = SimpleUNet(image_channels=3, time_emb_dim=32, num_prev_frames=config.NUM_PREV_FRAMES).to(config.DEVICE)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE)\n",
    "    \n",
    "    # --- Load Checkpoint (if available) ---\n",
    "    if config.LOAD_CHECKPOINT:\n",
    "        checkpoint = torch.load(config.LOAD_CHECKPOINT)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        START_EPOCH = checkpoint['epoch']\n",
    "        print(f\"Loaded checkpoint from epoch {START_EPOCH}\")\n",
    "    else:\n",
    "        START_EPOCH = 0\n",
    "\n",
    "    print(f\"--- Training Configuration ---\")\n",
    "    # Print model parameter count\n",
    "    print(f\"Model Parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "    print(f\"  Mem Allocated: {torch.cuda.memory_allocated(config.DEVICE) / 1024**2:.2f} MB\")\n",
    "    print(f\"  Max Mem Allocated: {torch.cuda.max_memory_allocated(config.DEVICE) / 1024**2:.2f} MB\")\n",
    "    print(f\"  Mem Reserved: {torch.cuda.memory_reserved(config.DEVICE) / 1024**2:.2f} MB\")\n",
    "    print(f\"  Max Mem Reserved: {torch.cuda.max_memory_reserved(config.DEVICE) / 1024**2:.2f} MB\")    \n",
    "    print(f\"--------------------------\")    \n",
    "    # --- Train the Model ---\n",
    "    losses = train(model, train_dataloader, optimizer, betas, alphas_cumprod, START_EPOCH, config.NUM_EPOCHS, config.DEVICE,\n",
    "                   config.SAVE_MODEL_EVERY, config.SAMPLE_EVERY, config.CHECKPOINT_DIR, config.SAMPLE_DIR, config.PLOT_DIR, config.PLOT_EVERY, config.USE_FP16,\n",
    "                   config.ACCUMULATION_STEPS, config.NUM_PREV_FRAMES, early_stopping_patience=config.EARLY_STOPPING_PATIENCE, early_stopping_percentage=config.EARLY_STOPPING_PERCENTAGE, min_epochs=config.MIN_EPOCHS)\n",
    "    print(\"Training complete!\")\n",
    "    \n",
    "    # --- Final Loss Plot ---\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(config.PLOT_DIR, \"loss_plot_final.png\"))  # Save to plot dir\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16933dd4-020b-40b6-9c67-b420f3ed3ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.SAMPLE_EVERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69705aac-316a-4771-aa0f-ccab7b3d9eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d410bf-97c6-44f0-a38c-4e378b0659ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
