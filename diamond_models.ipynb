{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b55bde81-780a-4ee2-b4ab-f46799cb1a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import math\n",
    "from typing import List, Optional, Tuple, Dict, Any\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b64eac-b871-4857-94ff-a76124ff4f54",
   "metadata": {},
   "source": [
    "# Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c0f2fb-8bd3-4a3a-878d-53df34c2eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv1x1 = partial(nn.Conv2d, kernel_size=1, stride=1, padding=0)\n",
    "Conv3x3 = partial(nn.Conv2d, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# GroupNorm and conditional GroupNorm\n",
    "GN_GROUP_SIZE = 32\n",
    "GN_EPS = 1e-5\n",
    "ATTN_HEAD_DIM = 8\n",
    "\n",
    "class GroupNorm(nn.Module):\n",
    "    def __init__(self, in_channels: int) -> None:\n",
    "        super().__init__()\n",
    "        num_groups = max(1, in_channels // GN_GROUP_SIZE)\n",
    "        self.norm = nn.GroupNorm(num_groups, in_channels, eps=GN_EPS)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "class AdaGroupNorm(nn.Module):\n",
    "    def __init__(self, in_channels: int, cond_channels: int) -> None:\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.num_groups = max(1, in_channels // GN_GROUP_SIZE)\n",
    "        self.linear = nn.Linear(cond_channels, in_channels * 2)\n",
    "\n",
    "    def forward(self, x: Tensor, cond: Tensor) -> Tensor:\n",
    "        assert x.size(1) == self.in_channels\n",
    "        x = F.group_norm(x, self.num_groups, eps=GN_EPS)\n",
    "        scale, shift = self.linear(cond)[:, :, None, None].chunk(2, dim=1)\n",
    "        return x * (1 + scale) + shift\n",
    "\n",
    "\n",
    "# Self Attention\n",
    "\n",
    "\n",
    "class SelfAttention2d(nn.Module):\n",
    "    def __init__(self, in_channels: int, head_dim: int = ATTN_HEAD_DIM) -> None:\n",
    "        super().__init__()\n",
    "        self.n_head = max(1, in_channels // head_dim)\n",
    "        assert in_channels % self.n_head == 0\n",
    "        self.norm = GroupNorm(in_channels)\n",
    "        self.qkv_proj = Conv1x1(in_channels, in_channels * 3)\n",
    "        self.out_proj = Conv1x1(in_channels, in_channels)\n",
    "        nn.init.zeros_(self.out_proj.weight)\n",
    "        nn.init.zeros_(self.out_proj.bias)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        n, c, h, w = x.shape\n",
    "        x = self.norm(x)\n",
    "        qkv = self.qkv_proj(x)\n",
    "        qkv = qkv.view(n, self.n_head * 3, c // self.n_head, h * w).transpose(2, 3).contiguous()\n",
    "        q, k, v = [x for x in qkv.chunk(3, dim=1)]\n",
    "        att = (q @ k.transpose(-2, -1)) / math.sqrt(k.size(-1))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        y = att @ v\n",
    "        y = y.transpose(2, 3).reshape(n, c, h, w)\n",
    "        return x + self.out_proj(y)\n",
    "\n",
    "\n",
    "# Embedding of the noise level\n",
    "\n",
    "\n",
    "class FourierFeatures(nn.Module):\n",
    "    def __init__(self, cond_channels: int) -> None:\n",
    "        super().__init__()\n",
    "        assert cond_channels % 2 == 0\n",
    "        self.register_buffer(\"weight\", torch.randn(1, cond_channels // 2))\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        assert input.ndim == 1\n",
    "        f = 2 * math.pi * input.unsqueeze(1) @ self.weight\n",
    "        return torch.cat([f.cos(), f.sin()], dim=-1)\n",
    "\n",
    "\n",
    "# [Down|Up]sampling\n",
    "\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, in_channels: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=2, padding=1)\n",
    "        nn.init.orthogonal_(self.conv.weight)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_channels: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = Conv3x3(in_channels, in_channels)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = F.interpolate(x, scale_factor=2.0, mode=\"nearest\")\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "# Small Residual block\n",
    "\n",
    "\n",
    "class SmallResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int) -> None:\n",
    "        super().__init__()\n",
    "        self.f = nn.Sequential(GroupNorm(in_channels), nn.SiLU(inplace=True), Conv3x3(in_channels, out_channels))\n",
    "        self.skip_projection = nn.Identity() if in_channels == out_channels else Conv1x1(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.skip_projection(x) + self.f(x)\n",
    "\n",
    "\n",
    "# Residual block (conditioning with AdaGroupNorm, no [down|up]sampling, optional self-attention)\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, cond_channels: int, attn: bool) -> None:\n",
    "        super().__init__()\n",
    "        should_proj = in_channels != out_channels\n",
    "        self.proj = Conv1x1(in_channels, out_channels) if should_proj else nn.Identity()\n",
    "        self.norm1 = AdaGroupNorm(in_channels, cond_channels)\n",
    "        self.conv1 = Conv3x3(in_channels, out_channels)\n",
    "        self.norm2 = AdaGroupNorm(out_channels, cond_channels)\n",
    "        self.conv2 = Conv3x3(out_channels, out_channels)\n",
    "        self.attn = SelfAttention2d(out_channels) if attn else nn.Identity()\n",
    "        nn.init.zeros_(self.conv2.weight)\n",
    "\n",
    "    def forward(self, x: Tensor, cond: Tensor) -> Tensor:\n",
    "        r = self.proj(x)\n",
    "        x = self.conv1(F.silu(self.norm1(x, cond)))\n",
    "        x = self.conv2(F.silu(self.norm2(x, cond)))\n",
    "        x = x + r\n",
    "        x = self.attn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Sequence of residual blocks (in_channels -> mid_channels -> ... -> mid_channels -> out_channels)\n",
    "\n",
    "\n",
    "class ResBlocks(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        list_in_channels: List[int],\n",
    "        list_out_channels: List[int],\n",
    "        cond_channels: int,\n",
    "        attn: bool,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        assert len(list_in_channels) == len(list_out_channels)\n",
    "        self.in_channels = list_in_channels[0]\n",
    "        self.resblocks = nn.ModuleList(\n",
    "            [\n",
    "                ResBlock(in_ch, out_ch, cond_channels, attn)\n",
    "                for (in_ch, out_ch) in zip(list_in_channels, list_out_channels)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor, cond: Tensor, to_cat: Optional[List[Tensor]] = None) -> Tensor:\n",
    "        outputs = []\n",
    "        for i, resblock in enumerate(self.resblocks):\n",
    "            x = x if to_cat is None else torch.cat((x, to_cat[i]), dim=1)\n",
    "            x = resblock(x, cond)\n",
    "            outputs.append(x)\n",
    "        return x, outputs\n",
    "\n",
    "\n",
    "# UNet\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, cond_channels: int, depths: List[int], channels: List[int], attn_depths: List[int]) -> None:\n",
    "        super().__init__()\n",
    "        assert len(depths) == len(channels) == len(attn_depths)\n",
    "        self._num_down = len(channels) - 1\n",
    "\n",
    "        d_blocks, u_blocks = [], []\n",
    "        for i, n in enumerate(depths):\n",
    "            c1 = channels[max(0, i - 1)]\n",
    "            c2 = channels[i]\n",
    "            d_blocks.append(\n",
    "                ResBlocks(\n",
    "                    list_in_channels=[c1] + [c2] * (n - 1),\n",
    "                    list_out_channels=[c2] * n,\n",
    "                    cond_channels=cond_channels,\n",
    "                    attn=attn_depths[i],\n",
    "                )\n",
    "            )\n",
    "            u_blocks.append(\n",
    "                ResBlocks(\n",
    "                    list_in_channels=[2 * c2] * n + [c1 + c2],\n",
    "                    list_out_channels=[c2] * n + [c1],\n",
    "                    cond_channels=cond_channels,\n",
    "                    attn=attn_depths[i],\n",
    "                )\n",
    "            )\n",
    "        self.d_blocks = nn.ModuleList(d_blocks)\n",
    "        self.u_blocks = nn.ModuleList(reversed(u_blocks))\n",
    "\n",
    "        self.mid_blocks = ResBlocks(\n",
    "            list_in_channels=[channels[-1]] * 2,\n",
    "            list_out_channels=[channels[-1]] * 2,\n",
    "            cond_channels=cond_channels,\n",
    "            attn=True,\n",
    "        )\n",
    "\n",
    "        downsamples = [nn.Identity()] + [Downsample(c) for c in channels[:-1]]\n",
    "        upsamples = [nn.Identity()] + [Upsample(c) for c in reversed(channels[:-1])]\n",
    "        self.downsamples = nn.ModuleList(downsamples)\n",
    "        self.upsamples = nn.ModuleList(upsamples)\n",
    "\n",
    "    def forward(self, x: Tensor, cond: Tensor) -> Tensor:\n",
    "        *_, h, w = x.size()\n",
    "        n = self._num_down\n",
    "        padding_h = math.ceil(h / 2 ** n) * 2 ** n - h\n",
    "        padding_w = math.ceil(w / 2 ** n) * 2 ** n - w\n",
    "        x = F.pad(x, (0, padding_w, 0, padding_h))\n",
    "\n",
    "        d_outputs = []\n",
    "        for block, down in zip(self.d_blocks, self.downsamples):\n",
    "            x_down = down(x)\n",
    "            x, block_outputs = block(x_down, cond)\n",
    "            d_outputs.append((x_down, *block_outputs))\n",
    "\n",
    "        x, _ = self.mid_blocks(x, cond)\n",
    "        \n",
    "        u_outputs = []\n",
    "        for block, up, skip in zip(self.u_blocks, self.upsamples, reversed(d_outputs)):\n",
    "            x_up = up(x)\n",
    "            x, block_outputs = block(x_up, cond, skip[::-1])\n",
    "            u_outputs.append((x_up, *block_outputs))\n",
    "\n",
    "        x = x[..., :h, :w]\n",
    "        return x, d_outputs, u_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc99cda-0f40-404c-868d-6f6dcbb23e97",
   "metadata": {},
   "source": [
    "# Inner Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406cdb8f-1631-47c4-a5fc-6078d69015b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class InnerModelConfig:\n",
    "    img_channels: int\n",
    "    num_steps_conditioning: int\n",
    "    cond_channels: int\n",
    "    depths: List[int]\n",
    "    channels: List[int]\n",
    "    attn_depths: List[bool]\n",
    "    num_actions: Optional[int] = None  # set by trainer after env creation\n",
    "    is_upsampler: Optional[bool] = None  # set by Denoiser\n",
    "\n",
    "\n",
    "class InnerModel(nn.Module):\n",
    "    def __init__(self, cfg: InnerModelConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.noise_emb = FourierFeatures(cfg.cond_channels)\n",
    "        self.noise_cond_emb = FourierFeatures(cfg.cond_channels)\n",
    "        self.act_emb = None if cfg.is_upsampler else nn.Sequential(\n",
    "            nn.Embedding(cfg.num_actions, cfg.cond_channels // cfg.num_steps_conditioning),\n",
    "            nn.Flatten(),  # b t e -> b (t e)\n",
    "        )\n",
    "        self.cond_proj = nn.Sequential(\n",
    "            nn.Linear(cfg.cond_channels, cfg.cond_channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(cfg.cond_channels, cfg.cond_channels),\n",
    "        )\n",
    "        self.conv_in = Conv3x3((cfg.num_steps_conditioning + int(cfg.is_upsampler) + 1) * cfg.img_channels, cfg.channels[0])\n",
    "\n",
    "        self.unet = UNet(cfg.cond_channels, cfg.depths, cfg.channels, cfg.attn_depths)\n",
    "\n",
    "        self.norm_out = GroupNorm(cfg.channels[0])\n",
    "        self.conv_out = Conv3x3(cfg.channels[0], cfg.img_channels)\n",
    "        nn.init.zeros_(self.conv_out.weight)\n",
    "\n",
    "    def forward(self, noisy_next_obs: Tensor, c_noise: Tensor, c_noise_cond: Tensor, obs: Tensor, act: Optional[Tensor]) -> Tensor:\n",
    "        if self.act_emb is not None:\n",
    "            assert act.ndim == 2 or (act.ndim == 3 and act.size(2) == self.act_emb[0].num_embeddings and set(act.unique().tolist()).issubset(set([0, 1])))\n",
    "            act_emb = self.act_emb(act) if act.ndim == 2 else self.act_emb[1]((act.float() @ self.act_emb[0].weight))\n",
    "        else:\n",
    "            assert act is None\n",
    "            act_emb = 0\n",
    "        cond = self.cond_proj(self.noise_emb(c_noise) + self.noise_cond_emb(c_noise_cond) + act_emb)\n",
    "        x = self.conv_in(torch.cat((obs, noisy_next_obs), dim=1))\n",
    "        x, _, _ = self.unet(x, cond)\n",
    "        x = self.conv_out(F.silu(self.norm_out(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a972157-cfea-43df-886c-fce97dd04337",
   "metadata": {},
   "source": [
    "# Denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6c650-ab09-410a-851f-522dd8f37fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LossAndLogs = Tuple[Tensor, Dict[str, Any]]\n",
    "\n",
    "def add_dims(input: Tensor, n: int) -> Tensor:\n",
    "    return input.reshape(input.shape + (1,) * (n - input.ndim))\n",
    "\n",
    "@dataclass\n",
    "class Batch:\n",
    "    obs: torch.Tensor  # Shape: (B, T, C, H, W), T = NUM_PREV_FRAMES + 1\n",
    "    act: torch.Tensor  # Shape: (B, NUM_PREV_FRAMES)\n",
    "    mask_padding: Optional[torch.Tensor] = None  # Shape: (B, T)\n",
    "    info: Optional[Dict[str, Any]] = None\n",
    "\n",
    "    def to(self, device: torch.device) -> \"Batch\":\n",
    "        \"\"\"Return a new Batch with tensors moved to the given device.\"\"\"\n",
    "        return Batch(\n",
    "            obs=self.obs.to(device),\n",
    "            act=self.act.to(device),\n",
    "            mask_padding=self.mask_padding.to(device) if self.mask_padding is not None else None,\n",
    "            info=self.info,\n",
    "        )\n",
    "\n",
    "@dataclass\n",
    "class Conditioners:\n",
    "    c_in: Tensor\n",
    "    c_out: Tensor\n",
    "    c_skip: Tensor\n",
    "    c_noise: Tensor\n",
    "    c_noise_cond: Tensor\n",
    "\n",
    "@dataclass\n",
    "class SigmaDistributionConfig:\n",
    "    loc: float\n",
    "    scale: float\n",
    "    sigma_min: float\n",
    "    sigma_max: float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DenoiserConfig:\n",
    "    inner_model: InnerModelConfig\n",
    "    sigma_data: float\n",
    "    sigma_offset_noise: float\n",
    "    noise_previous_obs: bool\n",
    "    upsampling_factor: Optional[int] = None\n",
    "\n",
    "\n",
    "class Denoiser(nn.Module):\n",
    "    def __init__(self, cfg: DenoiserConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.is_upsampler = cfg.upsampling_factor is not None\n",
    "        cfg.inner_model.is_upsampler = self.is_upsampler\n",
    "        self.inner_model = InnerModel(cfg.inner_model)\n",
    "        self.sample_sigma_training = None\n",
    "\n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        return self.inner_model.noise_emb.weight.device\n",
    "\n",
    "    def setup_training(self, cfg: SigmaDistributionConfig) -> None:\n",
    "        assert self.sample_sigma_training is None\n",
    "\n",
    "        def sample_sigma(n: int, device: torch.device):\n",
    "            s = torch.randn(n, device=device) * cfg.scale + cfg.loc\n",
    "            return s.exp().clip(cfg.sigma_min, cfg.sigma_max)\n",
    "\n",
    "        self.sample_sigma_training = sample_sigma\n",
    "    \n",
    "    def apply_noise(self, x: Tensor, sigma: Tensor, sigma_offset_noise: float) -> Tensor:\n",
    "        b, c, _, _ = x.shape \n",
    "        offset_noise = sigma_offset_noise * torch.randn(b, c, 1, 1, device=self.device)\n",
    "        return x + offset_noise + torch.randn_like(x) * add_dims(sigma, x.ndim)\n",
    "\n",
    "    def compute_conditioners(self, sigma: Tensor, sigma_cond: Optional[Tensor]) -> Conditioners:\n",
    "        sigma = (sigma**2 + self.cfg.sigma_offset_noise**2).sqrt()\n",
    "        c_in = 1 / (sigma**2 + self.cfg.sigma_data**2).sqrt()\n",
    "        c_skip = self.cfg.sigma_data**2 / (sigma**2 + self.cfg.sigma_data**2)\n",
    "        c_out = sigma * c_skip.sqrt()\n",
    "        c_noise = sigma.log() / 4\n",
    "        c_noise_cond = sigma_cond.log() / 4 if sigma_cond is not None else torch.zeros_like(c_noise)\n",
    "        return Conditioners(*(add_dims(c, n) for c, n in zip((c_in, c_out, c_skip, c_noise, c_noise_cond), (4, 4, 4, 1, 1))))\n",
    "\n",
    "    def compute_model_output(self, noisy_next_obs: Tensor, obs: Tensor, act: Optional[Tensor], cs: Conditioners) -> Tensor:\n",
    "        rescaled_obs = obs / self.cfg.sigma_data\n",
    "        rescaled_noise = noisy_next_obs * cs.c_in\n",
    "        return self.inner_model(rescaled_noise, cs.c_noise, cs.c_noise_cond, rescaled_obs, act)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def wrap_model_output(self, noisy_next_obs: Tensor, model_output: Tensor, cs: Conditioners) -> Tensor:\n",
    "        d = cs.c_skip * noisy_next_obs + cs.c_out * model_output\n",
    "        # Quantize to {0, ..., 255}, then back to [-1, 1]\n",
    "        d = d.clamp(-1, 1).add(1).div(2).mul(255).byte().div(255).mul(2).sub(1)\n",
    "        return d\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def denoise(self, noisy_next_obs: Tensor, sigma: Tensor, sigma_cond: Optional[Tensor], obs: Tensor, act: Optional[Tensor]) -> Tensor:\n",
    "        cs = self.compute_conditioners(sigma, sigma_cond)\n",
    "        model_output = self.compute_model_output(noisy_next_obs, obs, act, cs)\n",
    "        denoised = self.wrap_model_output(noisy_next_obs, model_output, cs)\n",
    "        return denoised\n",
    "    \n",
    "    def forward(self, batch: Batch) -> LossAndLogs:\n",
    "        b, t, c, h, w = batch.obs.size()\n",
    "        H, W = (self.cfg.upsampling_factor * h, self.cfg.upsampling_factor * w) if self.is_upsampler else (h, w)\n",
    "        n = self.cfg.inner_model.num_steps_conditioning\n",
    "        seq_length = t - n  # t = n + 1 + num_autoregressive_steps\n",
    "\n",
    "        if self.is_upsampler:\n",
    "            all_obs = torch.stack([x[\"full_res\"] for x in batch.info]).to(self.device)\n",
    "            low_res = F.interpolate(batch.obs.reshape(b * t, c, h, w), scale_factor=self.cfg.upsampling_factor, mode=\"bicubic\").reshape(b, t, c, H, W)\n",
    "            assert all_obs.shape == low_res.shape\n",
    "        else:\n",
    "            all_obs = batch.obs.clone()\n",
    "\n",
    "        loss = 0\n",
    "        for i in range(seq_length):\n",
    "            prev_obs = all_obs[:, i : n + i].reshape(b, n * c, H, W)\n",
    "            prev_act = None if self.is_upsampler else batch.act[:, i : n + i]\n",
    "            obs = all_obs[:, n + i]\n",
    "            mask = batch.mask_padding[:, n + i]\n",
    "\n",
    "            if self.cfg.noise_previous_obs:\n",
    "                sigma_cond = self.sample_sigma_training(b, self.device)\n",
    "                prev_obs = self.apply_noise(prev_obs, sigma_cond, self.cfg.sigma_offset_noise)\n",
    "            else:\n",
    "                sigma_cond = None\n",
    "\n",
    "            if self.is_upsampler:\n",
    "                prev_obs = torch.cat((prev_obs, low_res[:, n + i]), dim=1)\n",
    "\n",
    "            sigma = self.sample_sigma_training(b, self.device)\n",
    "            noisy_obs = self.apply_noise(obs, sigma, self.cfg.sigma_offset_noise)\n",
    "\n",
    "            cs = self.compute_conditioners(sigma, sigma_cond)\n",
    "            model_output = self.compute_model_output(noisy_obs, prev_obs, prev_act, cs)\n",
    "\n",
    "            target = (obs - cs.c_skip * noisy_obs) / cs.c_out\n",
    "            loss += F.mse_loss(model_output[mask], target[mask])\n",
    "\n",
    "            denoised = self.wrap_model_output(noisy_obs, model_output, cs)\n",
    "            all_obs[:, n + i] = denoised\n",
    "\n",
    "        loss /= seq_length\n",
    "        return loss, {\"loss_denoising\": loss.item()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d5325-394e-44fc-ae9e-596fce6d7be3",
   "metadata": {},
   "source": [
    "# Diffusion Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef952cd-e142-440b-b3c3-04ef67814d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DiffusionSamplerConfig:\n",
    "    num_steps_denoising: int\n",
    "    sigma_min: float = 2e-3\n",
    "    sigma_max: float = 5\n",
    "    rho: int = 7\n",
    "    order: int = 1\n",
    "    s_churn: float = 0\n",
    "    s_tmin: float = 0\n",
    "    s_tmax: float = float(\"inf\")\n",
    "    s_noise: float = 1\n",
    "    s_cond: float = 0\n",
    "\n",
    "\n",
    "class DiffusionSampler:\n",
    "    def __init__(self, denoiser: Denoiser, cfg: DiffusionSamplerConfig) -> None:\n",
    "        self.denoiser = denoiser\n",
    "        self.cfg = cfg\n",
    "        self.sigmas = build_sigmas(cfg.num_steps_denoising, cfg.sigma_min, cfg.sigma_max, cfg.rho, denoiser.device)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, prev_obs: Tensor, prev_act: Optional[Tensor]) -> Tuple[Tensor, List[Tensor]]:\n",
    "        device = prev_obs.device\n",
    "        b, t, c, h, w = prev_obs.size()\n",
    "        prev_obs = prev_obs.reshape(b, t * c, h, w)\n",
    "        s_in = torch.ones(b, device=device)\n",
    "        gamma_ = min(self.cfg.s_churn / (len(self.sigmas) - 1), 2**0.5 - 1)\n",
    "        x = torch.randn(b, c, h, w, device=device)\n",
    "        trajectory = [x]\n",
    "        for sigma, next_sigma in zip(self.sigmas[:-1], self.sigmas[1:]):\n",
    "            gamma = gamma_ if self.cfg.s_tmin <= sigma <= self.cfg.s_tmax else 0\n",
    "            sigma_hat = sigma * (gamma + 1)\n",
    "            if gamma > 0:\n",
    "                eps = torch.randn_like(x) * self.cfg.s_noise\n",
    "                x = x + eps * (sigma_hat**2 - sigma**2) ** 0.5\n",
    "            if self.cfg.s_cond > 0:\n",
    "                sigma_cond = torch.full((b,), fill_value=self.cfg.s_cond, device=device)\n",
    "                prev_obs = self.denoiser.apply_noise(prev_obs, sigma_cond, sigma_offset_noise=0)\n",
    "            else:\n",
    "                sigma_cond = None\n",
    "            denoised = self.denoiser.denoise(x, sigma, sigma_cond, prev_obs, prev_act)\n",
    "            d = (x - denoised) / sigma_hat\n",
    "            dt = next_sigma - sigma_hat\n",
    "            if self.cfg.order == 1 or next_sigma == 0:\n",
    "                # Euler method\n",
    "                x = x + d * dt\n",
    "            else:\n",
    "                # Heun's method\n",
    "                x_2 = x + d * dt\n",
    "                denoised_2 = self.denoiser.denoise(x_2, next_sigma * s_in, sigma_cond, prev_obs, prev_act)\n",
    "                d_2 = (x_2 - denoised_2) / next_sigma\n",
    "                d_prime = (d + d_2) / 2\n",
    "                x = x + d_prime * dt\n",
    "            trajectory.append(x)\n",
    "        return x, trajectory\n",
    "\n",
    "\n",
    "def build_sigmas(num_steps: int, sigma_min: float, sigma_max: float, rho: int, device: torch.device) -> Tensor:\n",
    "    min_inv_rho = sigma_min ** (1 / rho)\n",
    "    max_inv_rho = sigma_max ** (1 / rho)\n",
    "    l = torch.linspace(0, 1, num_steps, device=device)\n",
    "    sigmas = (max_inv_rho + l * (min_inv_rho - max_inv_rho)) ** rho\n",
    "    return torch.cat((sigmas, sigmas.new_zeros(1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
