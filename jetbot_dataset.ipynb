{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e5b50c6-5c4a-4f52-9e52-f34270603227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import config\n",
    "import csv\n",
    "from torch.utils.data import random_split\n",
    "from PIL import Image\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "from jetbot_dataset import JetbotDataset\n",
    "from jetbot_dataset import filter_dataset_for_action_after_inaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e117bab5-8ae3-451f-b2ee-5d0979588b86",
   "metadata": {
    "tags": [
     "removed"
    ]
   },
   "outputs": [],
   "source": [
    "# JetbotDataset class is defined in jetbot_dataset.py.\n",
    "# Helper functions like display_dataset_entry, filter_dataset_by_action etc. are defined in subsequent cells of this notebook or imported.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_existing_split(train_dataset, test_dataset, filename=\"dataset_split.pth\"):\n",
    "    \"\"\"Saves the indices of existing Subset objects to a file.\n",
    "\n",
    "    Args:\n",
    "        train_dataset: The Subset object representing the training set.\n",
    "        test_dataset: The Subset object representing the test set.\n",
    "        filename: The name of the file to save the indices to.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if they are actually Subset objects.  Important!\n",
    "    if not isinstance(train_dataset, Subset) or not isinstance(test_dataset, Subset):\n",
    "        raise TypeError(\"Both train_dataset and test_dataset must be Subset objects.\")\n",
    "\n",
    "    # Extract the indices. This is the key step.\n",
    "    train_indices = train_dataset.indices\n",
    "    test_indices = test_dataset.indices\n",
    "\n",
    "    # Combine them into a single list (or tuple) for saving.\n",
    "    all_indices = [train_indices, test_indices]\n",
    "\n",
    "    # Save the indices using torch.save\n",
    "    torch.save(all_indices, os.path.join(config.OUTPUT_DIR, filename))\n",
    "\n",
    "def load_train_test_split(dataset, filename=\"dataset_split.pth\"):\n",
    "    \"\"\"Loads the indices of existing Subset objects from a file.\"\"\"\n",
    "\n",
    "    filepath = os.path.join(config.OUTPUT_DIR, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        return None, None # Return None if file does not exist\n",
    "\n",
    "    splits = torch.load(filepath)\n",
    "    return tuple(Subset(dataset, indices) for indices in splits)\n",
    "\n",
    "def display_dataset_entry(dataset_entry):\n",
    "    frame, action, previous_frames = dataset_entry\n",
    "    \n",
    "    # Calculate the total number of frames to display\n",
    "    total_frames = config.NUM_PREV_FRAMES + 1  # Previous frames + current frame\n",
    "    \n",
    "    # Create a figure with horizontal subplots\n",
    "    plt.figure(figsize=(5*total_frames, 5))\n",
    "    \n",
    "    # Print the action\n",
    "    plt.suptitle(f'Action: {action}', fontsize=16)\n",
    "    \n",
    "    # Display previous frames\n",
    "    for i in range(config.NUM_PREV_FRAMES):\n",
    "        plt.subplot(1, total_frames, i+1)\n",
    "        prev_frame = previous_frames[(i * 3):(i + 1) * 3, :, :]  # Extract each frame (C, H, W)\n",
    "        display_frame(prev_frame, title=f'Previous Frame {i+1}')\n",
    "    \n",
    "    # Display current frame\n",
    "    plt.subplot(1, total_frames, total_frames)\n",
    "    display_frame(frame, title='Current Frame')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_frame(frame, title=None):\n",
    "    # Unnormalize the frame\n",
    "    frame = (frame.clamp(-1, 1) + 1) / 2  # Normalize to [0, 1]\n",
    "    frame = (frame * 255).type(torch.uint8)  # Convert to uint8\n",
    "    \n",
    "    # Convert to PIL Image and then to numpy for matplotlib\n",
    "    pil_frame = transforms.ToPILImage()(frame)\n",
    "    \n",
    "    # Display the frame\n",
    "    plt.imshow(pil_frame)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "\n",
    "def get_action_percentages():\n",
    "    try:\n",
    "        # Construct the full path using the config variable\n",
    "        full_csv_path = config.CSV_PATH\n",
    "    \n",
    "        print(f\"Loading combined dataset from: {full_csv_path}\")\n",
    "        df = pd.read_csv(full_csv_path)\n",
    "    \n",
    "        # --- Calculate Value Counts ---\n",
    "        action_counts = df['action'].value_counts()\n",
    "    \n",
    "        # --- Calculate Percentages ---\n",
    "        action_percentages = df['action'].value_counts(normalize=True) * 100\n",
    "    \n",
    "        # --- Print Results ---\n",
    "        print(\"\\n--- Action Split in Combined Dataset ---\")\n",
    "        print(\"Action Value Counts:\")\n",
    "        print(action_counts)\n",
    "        print(\"\\nAction Percentages:\")\n",
    "        print(action_percentages.map('{:.2f}%'.format)) # Format as percentage\n",
    "        print(\"----------------------------------------\")\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Combined CSV file not found at expected location: {full_csv_path}\")\n",
    "        print(\"Please ensure combine_data.py has run successfully and config.py points to the correct file.\")\n",
    "    except KeyError:\n",
    "        print(\"Error: 'action' column not found in the CSV file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")    \n",
    "\n",
    "def split_train_test_by_session_id(dataset, train_split=0.8, seed=42):\n",
    "    \"\"\"\n",
    "    Splits a dataset (expected to have a .dataframe attribute with 'session_id')\n",
    "    into training and testing Subsets based on session IDs.\n",
    "\n",
    "    Args:\n",
    "        dataset (torch.utils.data.Dataset): An instance of a dataset class\n",
    "            that has a `.dataframe` attribute (like your JetbotDataset)\n",
    "            containing a 'session_id' column and a `.valid_indices` list\n",
    "            mapping subset indices to dataframe indices.\n",
    "        train_split (float): The proportion of sessions to use for training (e.g., 0.8 for 80%).\n",
    "        seed (int): Random seed for reproducible shuffling of sessions.\n",
    "\n",
    "    Returns:\n",
    "        tuple(Subset, Subset): A tuple containing the training Subset and testing Subset.\n",
    "                               Returns (None, None) if splitting is not possible.\n",
    "    \"\"\"\n",
    "    if not hasattr(dataset, 'dataframe') or 'session_id' not in dataset.dataframe.columns:\n",
    "        raise AttributeError(\"Input dataset must have a '.dataframe' attribute with a 'session_id' column.\")\n",
    "    if not hasattr(dataset, 'valid_indices'):\n",
    "         raise AttributeError(\"Input dataset must have a '.valid_indices' attribute.\")\n",
    "    if len(dataset) == 0:\n",
    "        print(\"Warning: Input dataset has zero valid samples. Cannot create split.\")\n",
    "        return Subset(dataset, []), Subset(dataset, []) # Return empty subsets\n",
    "\n",
    "    # 1. Get unique session IDs from the underlying dataframe\n",
    "    # Ensure we only consider sessions present in the valid indices\n",
    "    valid_df_indices = dataset.valid_indices\n",
    "    session_ids = dataset.dataframe.iloc[valid_df_indices]['session_id'].unique().tolist()\n",
    "\n",
    "    if not session_ids:\n",
    "         print(\"Warning: No unique session IDs found within the valid indices.\")\n",
    "         return Subset(dataset, []), Subset(dataset, []) # Return empty subsets\n",
    "\n",
    "    # 2. Shuffle session IDs for random split\n",
    "    rng = random.Random(seed) # Use a specific RNG instance for reproducibility\n",
    "    rng.shuffle(session_ids)\n",
    "\n",
    "    # 3. Split session IDs\n",
    "    split_idx = int(train_split * len(session_ids))\n",
    "    train_session_ids = set(session_ids[:split_idx])\n",
    "    test_session_ids = set(session_ids[split_idx:])\n",
    "\n",
    "    if not train_session_ids or not test_session_ids:\n",
    "         print(\"Warning: Could not create a valid train/test split of session IDs. \"\n",
    "               \"Perhaps only one session exists or train_split is 0 or 1?\")\n",
    "         # Decide how to handle: maybe return full dataset as train, empty as test?\n",
    "         # Returning empty test set for now if split fails.\n",
    "         if not train_session_ids:\n",
    "              return Subset(dataset, []), dataset # All test\n",
    "         else:\n",
    "              return dataset, Subset(dataset, []) # All train\n",
    "\n",
    "    print(f\"Splitting by session: {len(train_session_ids)} train sessions, {len(test_session_ids)} test sessions.\")\n",
    "\n",
    "    # 4. Get sample indices (relative to the input dataset's length) for each split\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    for i in range(len(dataset)): # Iterate 0 to len(dataset)-1\n",
    "        actual_df_idx = dataset.valid_indices[i] # Get the actual index in the dataframe\n",
    "        # Handle potential IndexError if valid_indices is somehow wrong\n",
    "        try:\n",
    "            session_id = dataset.dataframe.iloc[actual_df_idx]['session_id']\n",
    "            if session_id in train_session_ids:\n",
    "                train_indices.append(i) # Append the index 'i' (relative to dataset)\n",
    "            elif session_id in test_session_ids:\n",
    "                test_indices.append(i) # Append the index 'i' (relative to dataset)\n",
    "        except IndexError:\n",
    "             print(f\"Warning: Index {actual_df_idx} out of bounds for dataframe (length {len(dataset.dataframe)}). Skipping index {i} in split creation.\")\n",
    "\n",
    "\n",
    "    # 5. Create Subset objects\n",
    "    train_subset = Subset(dataset, train_indices)\n",
    "    test_subset = Subset(dataset, test_indices)\n",
    "\n",
    "    if len(train_subset) == 0 or len(test_subset) == 0:\n",
    "        print(\"Warning: Created split resulted in an empty train or test Subset. \"\n",
    "              \"Check session distribution or data.\")\n",
    "\n",
    "    return train_subset, test_subset\n",
    "\n",
    "def filter_dataset_by_action(input_dataset, target_actions, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Creates a Subset of a dataset containing only samples with specific actions.\n",
    "\n",
    "    Args:\n",
    "        input_dataset (torch.utils.data.Dataset): The dataset or subset to filter\n",
    "            (e.g., your train_dataset or test_dataset). It assumes the dataset's\n",
    "            __getitem__ returns (image, action_tensor, prev_frames).\n",
    "        target_actions (float or list/tuple of float): The action value(s) to keep.\n",
    "        tolerance (float): Tolerance for floating-point comparison of actions.\n",
    "\n",
    "    Returns:\n",
    "        torch.utils.data.Subset: A new subset containing only the samples\n",
    "                                 with the target action(s). Returns an empty\n",
    "                                 Subset if no matching samples are found.\n",
    "    \"\"\"\n",
    "    if not isinstance(target_actions, (list, tuple)):\n",
    "        target_actions = [target_actions] # Ensure it's a list\n",
    "\n",
    "    print(f\"Filtering dataset with {len(input_dataset)} samples for actions: {target_actions}\")\n",
    "    filtered_indices = []\n",
    "    for i in tqdm(range(len(input_dataset)), desc=\"Filtering Dataset\"):\n",
    "        try:\n",
    "            # Access the data point to get the action\n",
    "            # __getitem__ returns: image, action_tensor, prev_frames\n",
    "            _, action_tensor, _ = input_dataset[i]\n",
    "            action_value = action_tensor.item() # Get scalar value\n",
    "\n",
    "            # Check if the action matches any of the target actions within tolerance\n",
    "            for target in target_actions:\n",
    "                if abs(action_value - target) < tolerance:\n",
    "                    filtered_indices.append(i)\n",
    "                    break # No need to check other targets for this index\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error processing index {i} during filtering: {e}\")\n",
    "            # Decide whether to skip or raise, depending on expected data integrity\n",
    "            continue\n",
    "\n",
    "    if not filtered_indices:\n",
    "        print(f\"Warning: No samples found matching actions {target_actions}.\")\n",
    "\n",
    "    print(f\"Filtered down to {len(filtered_indices)} samples.\")\n",
    "    return Subset(input_dataset, filtered_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8655f0ec-8424-4f77-8f84-5f6a19c49838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_small_debug_split(full_dataset, debug_train_size, debug_val_size, output_dir, debug_split_filename=\"dataset_split_debug.pth\", seed=42):\n",
    "    \"\"\"\n",
    "    Creates and saves a small, fixed-size train/validation split for fast testing.\n",
    "    Assumes debug_train_size + debug_val_size <= len(full_dataset).\n",
    "\n",
    "    Args:\n",
    "        full_dataset (Dataset): The complete dataset to sample from.\n",
    "        debug_train_size (int): The exact number of samples for the debug training set.\n",
    "        debug_val_size (int): The exact number of samples for the debug validation set.\n",
    "        output_dir (str): The directory where the split file will be saved.\n",
    "        debug_split_filename (str): The name of the file to save the split indices to.\n",
    "        seed (int): Random seed for reproducibility of the split.\n",
    "\n",
    "    Returns:\n",
    "        tuple(Subset, Subset): A tuple containing the debug_train_dataset and debug_val_dataset.\n",
    "    \"\"\"\n",
    "    print(f\"Creating new SMALL debug train/val split...\")\n",
    "    print(f\"Requested debug train size: {debug_train_size}, Requested debug val size: {debug_val_size}\")\n",
    "\n",
    "    total_full_dataset_size = len(full_dataset)\n",
    "    \n",
    "    # Calculate the number of unused samples\n",
    "    unused_size = total_full_dataset_size - (debug_train_size + debug_val_size)\n",
    "    \n",
    "    # Perform the split using the exact requested sizes\n",
    "    debug_train_dataset, debug_val_dataset, _ = random_split(\n",
    "        full_dataset,\n",
    "        [debug_train_size, debug_val_size, unused_size],\n",
    "        generator=torch.Generator().manual_seed(seed)\n",
    "    )\n",
    "\n",
    "    print(f\"Created debug_train_dataset with {len(debug_train_dataset)} samples.\")\n",
    "    print(f\"Created debug_val_dataset with {len(debug_val_dataset)} samples.\")\n",
    "\n",
    "    # Save the indices of these small subsets\n",
    "    debug_split_file_path = os.path.join(output_dir, debug_split_filename)\n",
    "    torch.save({\n",
    "        'train_indices': debug_train_dataset.indices,\n",
    "        'val_indices': debug_val_dataset.indices,\n",
    "        'source_dataset_size': total_full_dataset_size,\n",
    "        'debug_train_size_used': len(debug_train_dataset),\n",
    "        'debug_val_size_used': len(debug_val_dataset)\n",
    "    }, debug_split_file_path)\n",
    "    print(f\"Saved new DEBUG dataset split to {debug_split_file_path}\")\n",
    "\n",
    "    return debug_train_dataset, debug_val_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0d29428-2982-454b-8ee7-f4e09fc1a13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded combined CSV with columns: ['session_id', 'image_path', 'timestamp', 'action']\n",
      "Creating new train/val split...\n",
      "Saved new dataset split to C:\\Projects\\jetbot-diffusion-world-model-kong-finder-aux\\output_model_5hz_DIAMOND_laundry\\dataset_split.pth\n",
      "Creating new SMALL debug train/val split...\n",
      "Requested debug train size: 50, Requested debug val size: 10\n",
      "Created debug_train_dataset with 50 samples.\n",
      "Created debug_val_dataset with 10 samples.\n",
      "Saved new DEBUG dataset split to C:\\Projects\\jetbot-diffusion-world-model-kong-finder-aux\\output_model_5hz_DIAMOND_laundry\\dataset_split_debug.pth\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((config.IMAGE_SIZE, config.IMAGE_SIZE)),\n",
    "        # transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "    dataset = JetbotDataset(config.CSV_PATH, config.DATA_DIR, config.IMAGE_SIZE, config.NUM_PREV_FRAMES, transform=transform)\n",
    "    \n",
    "    split_file_path = os.path.join(config.OUTPUT_DIR, getattr(config, 'SPLIT_DATASET_FILENAME', 'dataset_split.pth'))\n",
    "    if os.path.exists(split_file_path):\n",
    "        print(f\"Loading dataset split from {split_file_path}\")\n",
    "        split_data = torch.load(split_file_path)\n",
    "        train_indices, val_indices = split_data['train_indices'], split_data['val_indices']\n",
    "        train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "        val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "    else:\n",
    "        print(\"Creating new train/val split...\")\n",
    "        total_size = len(dataset)\n",
    "        train_size = int(total_size * 0.9)\n",
    "        val_size = total_size - train_size\n",
    "        train_dataset, val_dataset = random_split(dataset, [train_size, val_size]) # Using torch.random_split by default\n",
    "        torch.save({\n",
    "            'train_indices': train_dataset.indices,\n",
    "            'val_indices': val_dataset.indices,\n",
    "        }, split_file_path)\n",
    "        print(f\"Saved new dataset split to {split_file_path}\")\n",
    "\n",
    "    # Define the small sizes for your debug split\n",
    "    desired_debug_train_size = 50\n",
    "    desired_debug_val_size = 10\n",
    "    train_debug_set, val_debug_set = create_small_debug_split(\n",
    "            dataset,\n",
    "            desired_debug_train_size,\n",
    "            desired_debug_val_size,\n",
    "            output_dir=config.OUTPUT_DIR, # Pass your config.OUTPUT_DIR\n",
    "        )\n",
    "    # train_dataset, test_dataset = split_train_test_by_session_id(dataset)\n",
    "\n",
    "    # print(dataset[40])\n",
    "    \n",
    "    # display_dataset_entry(test_dataset[40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f33b594-43ca-4934-aaa7-21955f0118bf",
   "metadata": {},
   "source": [
    "print(len(dataset))\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "\n",
    "print(\"===DEBUG===\")\n",
    "print(len(train_debug_set))\n",
    "print(len(val_debug_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09a5e807-676d-4e54-aa58-2d02e40e3525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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: |-
I have successfully modified the notebook content in memory.
The cell with ID `e117bab5-8ae3-451f-b2ee-5d0979588b86` (index 1) has its source updated.
The cell with ID `22dd70d7-8df1-4106-924c-b1f46a523712` (which was at index 3 and contained the redundant function definition) has been removed.

Now, I will overwrite the `jetbot_dataset.ipynb` file with this corrected structure.
The notebook has been successfully updated. The "removed" cell's source has been changed, and the redundant function definition cell has been removed.

All steps for this subtask are complete.
