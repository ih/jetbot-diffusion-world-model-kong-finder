{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111c1d4e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset # Modified this line\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import config\n",
    "from tqdm.auto import tqdm # Added this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c35bb8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class JetbotDataset(Dataset):\n",
    "    def __init__(self, csv_path, data_dir, image_size, num_prev_frames, transform=None, seed=42): # Renamed args\n",
    "        \"\"\"\n",
    "        Loads combined Jetbot data and prepares sequences.\n",
    "        Train/test splitting should be done externally.\n",
    "\n",
    "        Args:\n",
    "            csv_path: Path to the combined CSV file (e.g., 'jetbot_data/data.csv').\n",
    "            data_dir: Path to the base directory containing the combined 'images' folder\n",
    "                      (e.g., 'jetbot_data').\n",
    "            image_size: Target image size.\n",
    "            num_prev_frames: Number of previous frames for history.\n",
    "            transform: PyTorch transforms to apply to images.\n",
    "            seed: Random seed for reproducible train/test splits if done externally.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.csv_path = csv_path\n",
    "        self.data_dir = data_dir # Base directory for combined data\n",
    "        self.image_size = image_size\n",
    "        self.transform = transform\n",
    "        self.num_prev_frames = num_prev_frames\n",
    "        self.seed = seed\n",
    "\n",
    "        self.dataframe = self.load_data()\n",
    "        # Calculate indices in the dataframe that are valid STARTING points for a sequence\n",
    "        self.valid_indices = self._calculate_valid_indices()\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Loads the combined dataframe.\"\"\"\n",
    "        if not os.path.exists(self.csv_path):\n",
    "            raise FileNotFoundError(f\"Combined CSV file not found: {self.csv_path}\")\n",
    "        df = pd.read_csv(self.csv_path)\n",
    "        print(f\"Loaded combined CSV with columns: {df.columns.tolist()}\")\n",
    "        if 'session_id' not in df.columns:\n",
    "             raise ValueError(\"'session_id' column not found in CSV. Please run combine_data.py again.\")\n",
    "        return df\n",
    "\n",
    "    def _calculate_valid_indices(self):\n",
    "        \"\"\"\n",
    "        Valid START indices i such that\n",
    "           • i, i-stride, i-2*stride, … are in the same session\n",
    "           • stride == config.FRAME_STRIDE  (e.g. 6 for 5 Hz)\n",
    "        \"\"\"\n",
    "        stride = config.FRAME_STRIDE\n",
    "        valid = []\n",
    "        for i in range(self.num_prev_frames * stride, len(self.dataframe)):\n",
    "            if i % stride:                # keep only every Nth frame\n",
    "                continue\n",
    "            sess_now = self.dataframe.iloc[i]['session_id']\n",
    "            sess_hist = self.dataframe.iloc[i - self.num_prev_frames*stride]['session_id']\n",
    "            if sess_now == sess_hist:\n",
    "                valid.append(i)\n",
    "        return valid\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        stride      = config.FRAME_STRIDE\n",
    "        actual_idx  = self.valid_indices[idx]\n",
    "\n",
    "        cur_row     = self.dataframe.iloc[actual_idx]\n",
    "        cur_img     = Image.open(os.path.join(self.data_dir, cur_row['image_path'])).convert(\"RGB\")\n",
    "        action      = cur_row['action']\n",
    "\n",
    "        prev_frames = []\n",
    "        for n in range(self.num_prev_frames, 0, -1):\n",
    "            prev_row = self.dataframe.iloc[actual_idx - n*stride]\n",
    "            prev_img = Image.open(os.path.join(self.data_dir, prev_row['image_path'])).convert(\"RGB\")\n",
    "            prev_frames.append(self.transform(prev_img) if self.transform else prev_img)\n",
    "\n",
    "        cur_img = self.transform(cur_img) if self.transform else cur_img\n",
    "        prev_frames_tensor = torch.cat(prev_frames, dim=0)\n",
    "\n",
    "        return cur_img, torch.tensor([action], dtype=torch.float32), prev_frames_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7add0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataset_for_action_after_inaction(input_dataset, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Creates a Subset of a dataset containing only samples where the current action\n",
    "    is non-zero, but the action for at least one of the recent previous frames is zero.\n",
    "\n",
    "    Args:\n",
    "        input_dataset (torch.utils.data.Dataset): The dataset or subset to filter.\n",
    "            It assumes the dataset's __getitem__ returns (image, action_tensor, prev_frames_tensor).\n",
    "            It also assumes the input_dataset has an underlying 'dataset' attribute\n",
    "            which is the original JetbotDataset, and 'indices' if it's a Subset.\n",
    "            The original JetbotDataset should have 'dataframe' and 'valid_indices' attributes.\n",
    "        tolerance (float): Tolerance for floating-point comparison of actions.\n",
    "\n",
    "    Returns:\n",
    "        torch.utils.data.Subset: A new subset containing only the samples\n",
    "                                 matching the criteria. Returns an empty\n",
    "                                 Subset if no matching samples are found.\n",
    "    \"\"\"\n",
    "    filtered_indices = []\n",
    "\n",
    "    # Determine the base dataset\n",
    "    if isinstance(input_dataset, Subset):\n",
    "        base_dataset = input_dataset.dataset\n",
    "    else: # It's the full JetbotDataset\n",
    "        base_dataset = input_dataset\n",
    "\n",
    "    print(f\"Filtering dataset with {len(input_dataset)} samples for action after inaction...\")\n",
    "\n",
    "    for i in tqdm(range(len(input_dataset)), desc=\"Filtering for Action after Inaction\"):\n",
    "        try:\n",
    "            # Get current action from the input_dataset's __getitem__\n",
    "            _, current_action_tensor, _ = input_dataset[i]\n",
    "            current_action_value = current_action_tensor.item()\n",
    "\n",
    "            if abs(current_action_value) > tolerance: # Current action is non-zero\n",
    "                # Determine the actual index in the base_dataset.dataframe\n",
    "                if isinstance(input_dataset, Subset):\n",
    "                    # 'i' is an index into the Subset. We need the corresponding index in base_dataset.valid_indices\n",
    "                    actual_base_valid_idx = input_dataset.indices[i]\n",
    "                else:\n",
    "                    # 'i' is already an index into base_dataset.valid_indices\n",
    "                    actual_base_valid_idx = i\n",
    "\n",
    "                # This is the index in the original full dataframe\n",
    "                dataframe_idx = base_dataset.valid_indices[actual_base_valid_idx]\n",
    "\n",
    "                action_in_prev_frames_is_zero = False\n",
    "                # Iterate through the N previous frames in the dataframe\n",
    "                for k in range(1, base_dataset.num_prev_frames + 1):\n",
    "                    # Calculate index for the k-th previous frame in the dataframe\n",
    "                    prev_dataframe_idx = dataframe_idx - (k * config.FRAME_STRIDE)\n",
    "\n",
    "                    prev_action_value = base_dataset.dataframe.iloc[prev_dataframe_idx]['action']\n",
    "                    if abs(prev_action_value) < tolerance: # Previous action is zero\n",
    "                        action_in_prev_frames_is_zero = True\n",
    "                        break\n",
    "\n",
    "                if action_in_prev_frames_is_zero:\n",
    "                    filtered_indices.append(i) # 'i' is relative to input_dataset\n",
    "\n",
    "        except IndexError as e:\n",
    "            print(f\"Warning: IndexError while accessing previous frame for index {i} (dataframe_idx {dataframe_idx if 'dataframe_idx' in locals() else 'unknown'}): {e}. Skipping.\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error processing index {i} (dataframe_idx {dataframe_idx if 'dataframe_idx' in locals() else 'unknown'}) during filtering: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not filtered_indices:\n",
    "        print(\"Warning: No samples found matching the 'action after inaction' criteria.\")\n",
    "\n",
    "    print(f\"Filtered down to {len(filtered_indices)} samples.\")\n",
    "    return Subset(input_dataset, filtered_indices)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
