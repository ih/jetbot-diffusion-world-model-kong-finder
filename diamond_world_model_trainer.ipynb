{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc8be96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fad2cdd-72f3-4e90-b3b8-fb431351836e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "\n",
    "get_ipython().system('pip install wandb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f774b0df-a65b-4d3b-a41b-5f091156381d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "\n",
    "get_ipython().system('pip install --upgrade typing_extensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa79c0b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import datetime # For epoch timing and timestamping\n",
    "from torchvision import transforms\n",
    "from collections import deque # For moving average\n",
    "from dataclasses import dataclass \n",
    "from typing import List, Optional, Dict, Any \n",
    "import random\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "import wandb\n",
    "\n",
    "# Your project's specific imports\n",
    "import config # Your config.py\n",
    "import models # Your models.py (which should import from diamond_models.ipynb)\n",
    "\n",
    "# Import dataset from your jetbot_dataset.ipynb\n",
    "from importnb import Notebook\n",
    "with Notebook():\n",
    "    from jetbot_dataset import JetbotDataset, filter_dataset_by_action \n",
    "\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "print(\"Imports successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d8226",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"--- Configuration ---\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582e24f0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Denoiser & InnerModel specific\n",
    "DM_SIGMA_DATA = getattr(config, 'DM_SIGMA_DATA', 0.5)\n",
    "DM_SIGMA_OFFSET_NOISE = getattr(config, 'DM_SIGMA_OFFSET_NOISE', 0.1)\n",
    "DM_NOISE_PREVIOUS_OBS = getattr(config, 'DM_NOISE_PREVIOUS_OBS', True)\n",
    "DM_IMG_CHANNELS = getattr(config, 'DM_IMG_CHANNELS', 3)\n",
    "DM_NUM_STEPS_CONDITIONING = getattr(config, 'DM_NUM_STEPS_CONDITIONING', config.NUM_PREV_FRAMES)\n",
    "DM_COND_CHANNELS = getattr(config, 'DM_COND_CHANNELS', 256)\n",
    "DM_UNET_DEPTHS = getattr(config, 'DM_UNET_DEPTHS', [2, 2, 2, 2])\n",
    "DM_UNET_CHANNELS = getattr(config, 'DM_UNET_CHANNELS', [128, 256, 512, 1024]) # Using config.py\n",
    "DM_UNET_ATTN_DEPTHS = getattr(config, 'DM_UNET_ATTN_DEPTHS', [False, False, True, True])\n",
    "DM_NUM_ACTIONS = getattr(config, 'DM_NUM_ACTIONS', 2)\n",
    "DM_IS_UPSAMPLER = getattr(config, 'DM_IS_UPSAMPLER', False)\n",
    "DM_UPSAMPLING_FACTOR = getattr(config, 'DM_UPSAMPLING_FACTOR', None)\n",
    "\n",
    "# Sampler specific (for inference/visualization)\n",
    "SAMPLER_NUM_STEPS = getattr(config, 'SAMPLER_NUM_STEPS', 50)\n",
    "SAMPLER_SIGMA_MIN = getattr(config, 'SAMPLER_SIGMA_MIN', 0.002)\n",
    "SAMPLER_SIGMA_MAX = getattr(config, 'SAMPLER_SIGMA_MAX', 80.0)\n",
    "SAMPLER_RHO = getattr(config, 'SAMPLER_RHO', 7.0)\n",
    "# Additional Karras sampler params from config if they exist, otherwise defaults in dataclass used\n",
    "SAMPLER_ORDER = getattr(config, 'SAMPLER_ORDER', 1)\n",
    "SAMPLER_S_CHURN = getattr(config, 'SAMPLER_S_CHURN', 0.0)\n",
    "SAMPLER_S_TMIN = getattr(config, 'SAMPLER_S_TMIN', 0.0)\n",
    "SAMPLER_S_TMAX = getattr(config, 'SAMPLER_S_TMAX', float(\"inf\"))\n",
    "SAMPLER_S_NOISE = getattr(config, 'SAMPLER_S_NOISE', 1.0)\n",
    "\n",
    "\n",
    "# Training specific\n",
    "BATCH_SIZE = config.BATCH_SIZE\n",
    "LEARNING_RATE = config.LEARNING_RATE\n",
    "NUM_EPOCHS = config.NUM_EPOCHS\n",
    "SAVE_MODEL_EVERY = config.SAVE_MODEL_EVERY\n",
    "SAMPLE_EVERY = config.SAMPLE_EVERY\n",
    "PLOT_EVERY = config.PLOT_EVERY\n",
    "GRAD_CLIP_VALUE = getattr(config, 'GRAD_CLIP_VALUE', 1.0)\n",
    "\n",
    "DM_SIGMA_P_MEAN = getattr(config, 'DM_SIGMA_P_MEAN', -1.2) \n",
    "DM_SIGMA_P_STD = getattr(config, 'DM_SIGMA_P_STD', 1.2)   \n",
    "DM_SIGMA_MIN_TRAIN = getattr(config, 'DM_SIGMA_MIN_TRAIN', 0.002) \n",
    "DM_SIGMA_MAX_TRAIN = getattr(config, 'DM_SIGMA_MAX_TRAIN', 80.0)  \n",
    "\n",
    "EARLY_STOPPING_PATIENCE = getattr(config, 'EARLY_STOPPING_PATIENCE', 10)\n",
    "EARLY_STOPPING_MIN_EPOCHS = getattr(config, 'MIN_EPOCHS', 20) # Renamed from MIN_EPOCHS in config to avoid ambiguity\n",
    "EARLY_STOPPING_PERCENTAGE = getattr(config, 'EARLY_STOPPING_PERCENTAGE', 0.1) \n",
    "TRAIN_MOVING_AVG_WINDOW = getattr(config, 'TRAIN_MOVING_AVG_WINDOW', 10) \n",
    "VAL_MOVING_AVG_WINDOW = getattr(config, 'VAL_MOVING_AVG_WINDOW', 5) \n",
    "\n",
    "print(\"Configuration loaded.\")\n",
    "\n",
    "# Create a dictionary of your configurations to log with Wandb\n",
    "wandb_config = {\n",
    "    # Denoiser & InnerModel specific\n",
    "    'DM_SIGMA_DATA': DM_SIGMA_DATA,\n",
    "    'DM_SIGMA_OFFSET_NOISE': DM_SIGMA_OFFSET_NOISE,\n",
    "    'DM_NOISE_PREVIOUS_OBS': DM_NOISE_PREVIOUS_OBS,\n",
    "    'DM_IMG_CHANNELS': DM_IMG_CHANNELS,\n",
    "    'DM_NUM_STEPS_CONDITIONING': DM_NUM_STEPS_CONDITIONING,\n",
    "    'DM_COND_CHANNELS': DM_COND_CHANNELS,\n",
    "    'DM_UNET_DEPTHS': DM_UNET_DEPTHS,\n",
    "    'DM_UNET_CHANNELS': DM_UNET_CHANNELS,\n",
    "    'DM_UNET_ATTN_DEPTHS': DM_UNET_ATTN_DEPTHS,\n",
    "    'DM_NUM_ACTIONS': DM_NUM_ACTIONS,\n",
    "    'DM_IS_UPSAMPLER': DM_IS_UPSAMPLER,\n",
    "    'DM_UPSAMPLING_FACTOR': DM_UPSAMPLING_FACTOR,\n",
    "    # Sampler specific\n",
    "    'SAMPLER_NUM_STEPS': SAMPLER_NUM_STEPS,\n",
    "    'SAMPLER_SIGMA_MIN': SAMPLER_SIGMA_MIN,\n",
    "    'SAMPLER_SIGMA_MAX': SAMPLER_SIGMA_MAX,\n",
    "    'SAMPLER_RHO': SAMPLER_RHO,\n",
    "    'SAMPLER_ORDER': SAMPLER_ORDER,\n",
    "    'SAMPLER_S_CHURN': SAMPLER_S_CHURN,\n",
    "    'SAMPLER_S_TMIN': SAMPLER_S_TMIN,\n",
    "    'SAMPLER_S_TMAX': SAMPLER_S_TMAX,\n",
    "    'SAMPLER_S_NOISE': SAMPLER_S_NOISE,\n",
    "    # Training specific\n",
    "    'BATCH_SIZE': BATCH_SIZE,\n",
    "    'LEARNING_RATE': LEARNING_RATE,\n",
    "    'NUM_EPOCHS': NUM_EPOCHS,\n",
    "    'GRAD_CLIP_VALUE': GRAD_CLIP_VALUE,\n",
    "    'DM_SIGMA_P_MEAN': DM_SIGMA_P_MEAN,\n",
    "    'DM_SIGMA_P_STD': DM_SIGMA_P_STD,\n",
    "    'DM_SIGMA_MIN_TRAIN': DM_SIGMA_MIN_TRAIN,\n",
    "    'DM_SIGMA_MAX_TRAIN': DM_SIGMA_MAX_TRAIN,\n",
    "    'EARLY_STOPPING_PATIENCE': EARLY_STOPPING_PATIENCE,\n",
    "    'EARLY_STOPPING_MIN_EPOCHS': EARLY_STOPPING_MIN_EPOCHS,\n",
    "    'EARLY_STOPPING_PERCENTAGE': EARLY_STOPPING_PERCENTAGE,\n",
    "    'TRAIN_MOVING_AVG_WINDOW': TRAIN_MOVING_AVG_WINDOW,\n",
    "    'VAL_MOVING_AVG_WINDOW': VAL_MOVING_AVG_WINDOW,\n",
    "    # From your config.py directly\n",
    "    'IMAGE_SIZE': config.IMAGE_SIZE,\n",
    "    'NUM_PREV_FRAMES': config.NUM_PREV_FRAMES,\n",
    "    'PROJECT_NAME': getattr(config, 'PROJECT_NAME', 'jetbot-diamond-world-model'), # Add a project name\n",
    "    'FIXED_VIS_SAMPLE_IDX': getattr(config, 'FIXED_VIS_SAMPLE_IDX', 0), # For fixed visualization\n",
    "    'MOVING_ACTION_VALUE_FOR_VIS': getattr(config, 'MOVING_ACTION_VALUE_FOR_VIS', 0.13) # For moving visualization\n",
    "\n",
    "}\n",
    "\n",
    "wandb.init(project=wandb_config['PROJECT_NAME'], config=wandb_config)\n",
    "print(\"Wandb initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22fdd4c-5dec-45dd-b934-271c783baa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset():\n",
    "    full_dataset = JetbotDataset(\n",
    "        csv_path=config.CSV_PATH,\n",
    "        data_dir=config.DATA_DIR,\n",
    "        image_size=config.IMAGE_SIZE,\n",
    "        num_prev_frames=config.NUM_PREV_FRAMES,\n",
    "        transform=config.TRANSFORM\n",
    "    )\n",
    "    print(f\"Full dataset size: {len(full_dataset)}\")\n",
    "    split_file_path = os.path.join(config.OUTPUT_DIR, getattr(config, 'SPLIT_DATASET_FILENAME', 'dataset_split.pth'))\n",
    "    if os.path.exists(split_file_path):\n",
    "        print(f\"Loading dataset split from {split_file_path}\")\n",
    "        split_data = torch.load(split_file_path)\n",
    "        train_indices, val_indices = split_data['train_indices'], split_data['val_indices']\n",
    "        train_dataset = torch.utils.data.Subset(full_dataset, train_indices)\n",
    "        val_dataset = torch.utils.data.Subset(full_dataset, val_indices)\n",
    "    else:\n",
    "        print(\"Creating new train/val split...\")\n",
    "        total_size = len(full_dataset)\n",
    "        train_size = int(total_size * 0.9)\n",
    "        val_size = total_size - train_size\n",
    "        train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size]) # Using torch.random_split by default\n",
    "        torch.save({\n",
    "            'train_indices': train_dataset.indices,\n",
    "            'val_indices': val_dataset.indices,\n",
    "        }, split_file_path)\n",
    "        print(f\"Saved new dataset split to {split_file_path}\")\n",
    "\n",
    "    return train_dataset, val_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e99d46b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"--- Initializing Models ---\")\n",
    "\n",
    "# 1. InnerModel (U-Net part of the Denoiser)\n",
    "try:\n",
    "    inner_model_config = models.InnerModelConfig( # This is diamond_models.InnerModelConfig\n",
    "        img_channels=DM_IMG_CHANNELS,\n",
    "        num_steps_conditioning=DM_NUM_STEPS_CONDITIONING, # This is NUM_PREV_FRAMES\n",
    "        cond_channels=DM_COND_CHANNELS,\n",
    "        depths=DM_UNET_DEPTHS,\n",
    "        channels=DM_UNET_CHANNELS,\n",
    "        attn_depths=DM_UNET_ATTN_DEPTHS,\n",
    "        num_actions=DM_NUM_ACTIONS, # From config, e.g., 2 for JetBot\n",
    "        is_upsampler=DM_IS_UPSAMPLER # Will be set by DenoiserConfig later too\n",
    "    )\n",
    "    inner_model_instance = models.InnerModel(inner_model_config).to(DEVICE) # diamond_models.InnerModelImpl\n",
    "    print(\"Using InnerModel (Diamond-style U-Net) as the inner model.\")\n",
    "    print(f\"InnerModelImpl parameter count: {sum(p.numel() for p in inner_model_instance.parameters() if p.requires_grad):,}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not instantiate InnerModelImpl due to: {e}. Ensure 'InnerModelConfig', 'InnerModelImpl', dependencies, and DM_* config parameters are correct.\")\n",
    "    raise\n",
    "\n",
    "# 2. Denoiser (using diamond_models.Denoiser)\n",
    "try:\n",
    "    denoiser_cfg = models.DenoiserConfig( # Our new dataclass\n",
    "        inner_model=inner_model_config, # Pass the config, not the instance here if Denoiser instantiates it.\n",
    "                                        # diamond_models.Denoiser takes an InnerModelConfig for its own InnerModel.\n",
    "                                        # Re-checking diamond_models.py: Denoiser.__init__(self, cfg: DenoiserConfig)\n",
    "                                        # cfg.inner_model.is_upsampler = self.is_upsampler\n",
    "                                        # self.inner_model = InnerModel(cfg.inner_model) <--- Correct, it expects InnerModelConfig in DenoiserConfig\n",
    "        sigma_data=DM_SIGMA_DATA,\n",
    "        sigma_offset_noise=DM_SIGMA_OFFSET_NOISE,\n",
    "        noise_previous_obs=DM_NOISE_PREVIOUS_OBS,\n",
    "        upsampling_factor=DM_UPSAMPLING_FACTOR\n",
    "    )\n",
    "    # Ensure DenoiserConfig's inner_model field matches diamond_models.InnerModelConfig type\n",
    "    # The `models.InnerModelConfig` is already an alias to `diamond_models.InnerModelConfig`\n",
    "    denoiser = models.Denoiser(cfg=denoiser_cfg).to(DEVICE) # Pass the config object\n",
    "    \n",
    "    # Setup training sigma distribution for the Denoiser\n",
    "    sigma_dist_train_cfg = models.SigmaDistributionConfig(\n",
    "        loc=DM_SIGMA_P_MEAN,\n",
    "        scale=DM_SIGMA_P_STD,\n",
    "        sigma_min=DM_SIGMA_MIN_TRAIN,\n",
    "        sigma_max=DM_SIGMA_MAX_TRAIN\n",
    "    )\n",
    "    denoiser.setup_training(sigma_dist_train_cfg) # Call setup_training\n",
    "    print(f\"Denoiser model created and training sigma distribution configured. Total parameter count: {sum(p.numel() for p in denoiser.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Could not instantiate or configure Denoiser (from diamond_models.py) due to: {e}.\")\n",
    "    raise\n",
    "\n",
    "# 3. DiffusionSampler (using diamond_models.DiffusionSampler)\n",
    "try:\n",
    "    sampler_cfg = models.DiffusionSamplerConfig( # Our new dataclass\n",
    "        num_steps_denoising=SAMPLER_NUM_STEPS,\n",
    "        sigma_min=SAMPLER_SIGMA_MIN,\n",
    "        sigma_max=SAMPLER_SIGMA_MAX,\n",
    "        rho=SAMPLER_RHO,\n",
    "        order=SAMPLER_ORDER,\n",
    "        s_churn=SAMPLER_S_CHURN,\n",
    "        s_tmin=SAMPLER_S_TMIN,\n",
    "        s_tmax=SAMPLER_S_TMAX,\n",
    "        s_noise=SAMPLER_S_NOISE\n",
    "    )\n",
    "    diffusion_sampler = models.DiffusionSampler( # This is diamond_models.DiffusionSampler\n",
    "        denoiser=denoiser, # Pass the denoiser instance\n",
    "        cfg=sampler_cfg    # Pass the sampler config object\n",
    "    ) # Sampler itself might not need .to(DEVICE) if it doesn't have parameters\n",
    "    print(\"DiffusionSampler created for visualization.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not instantiate DiffusionSampler (from diamond_models.py) due to: {e}.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f3d4d0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"--- Setting up Optimizer and Scheduler ---\")\n",
    "optimizer = torch.optim.AdamW(\n",
    "    denoiser.parameters(),\n",
    "    lr=config.LEARNING_RATE,\n",
    "    weight_decay=config.LEARNING_RATE_WEIGHT_DECAY,\n",
    "    eps=config.LEARNING_RATE_EPS\n",
    ")\n",
    "print(f\"Optimizer: AdamW with LR={config.LEARNING_RATE}, Weight Decay={config.LEARNING_RATE_WEIGHT_DECAY}\")\n",
    "\n",
    "# Learning Rate Scheduler with Warmup\n",
    "def lr_lambda(current_step: int):\n",
    "    if current_step < config.LEARNING_RATE_WARMUP_STEPS:\n",
    "        return float(current_step) / float(max(1, config.LEARNING_RATE_WARMUP_STEPS))\n",
    "    return 1.0\n",
    "\n",
    "lr_scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "print(f\"LR Scheduler: LambdaLR with {config.LEARNING_RATE_WARMUP_STEPS} warmup steps.\")\n",
    "\n",
    "\n",
    "### WANDB: Added wandb.watch() for gradient tracking ###\n",
    "# Watch the model to log gradients and parameters. log_freq can be adjusted.\n",
    "# For example, log_freq=len(train_dataloader) would log once per epoch.\n",
    "# log_freq=100 means log every 100 batches.\n",
    "# `log=\"all\"` logs gradients and parameters.\n",
    "wandb.watch(denoiser, log=\"all\", log_freq=100) # Adjust log_freq as needed\n",
    "print(\"Wandb is watching the denoiser model for gradients and parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12764654",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "START_EPOCH = 0\n",
    "BEST_TRAIN_LOSS_MA_FROM_CKPT = float('inf')\n",
    "PREVIOUS_BEST_TRAIN_MODEL_PATH = None\n",
    "BEST_VAL_LOSS_MA_FROM_CKPT = float('inf') # Added for validation loss tracking\n",
    "PREVIOUS_BEST_VAL_MODEL_PATH = None # Added for best validation model path\n",
    "\n",
    "# Correctly use LOAD_CHECKPOINT from config.py for the specific path\n",
    "load_path_config = config.LOAD_CHECKPOINT \n",
    "best_train_loss_model_default_path = os.path.join(config.CHECKPOINT_DIR, \"denoiser_model_best_train_loss.pth\")\n",
    "best_val_loss_model_default_path = os.path.join(config.CHECKPOINT_DIR, \"denoiser_model_best_val_loss.pth\") # Added for val loss checkpoint\n",
    "\n",
    "load_path = load_path_config\n",
    "if load_path: # If a specific path is set in config, use it\n",
    "    print(f\"Attempting to load checkpoint from config.LOAD_CHECKPOINT: {load_path}\")\n",
    "elif os.path.exists(best_val_loss_model_default_path): # Else, try the default best val loss model\n",
    "    load_path = best_val_loss_model_default_path\n",
    "    print(f\"No specific checkpoint in config.LOAD_CHECKPOINT. Found existing best_val_loss model: {load_path}\")\n",
    "elif os.path.exists(best_train_loss_model_default_path): # Else, try the default best train loss model\n",
    "    load_path = best_train_loss_model_default_path\n",
    "    print(f\"No specific checkpoint in config.LOAD_CHECKPOINT. Found existing best_train_loss model: {load_path}\")\n",
    "\n",
    "\n",
    "if load_path and os.path.exists(load_path):\n",
    "    print(f\"Loading checkpoint from: {load_path}\")\n",
    "    try:\n",
    "        checkpoint = torch.load(load_path, map_location=DEVICE)\n",
    "        denoiser.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        START_EPOCH = checkpoint.get('epoch', 0) + 1\n",
    "        BEST_TRAIN_LOSS_MA_FROM_CKPT = checkpoint.get('best_train_loss_ma', float('inf'))\n",
    "        BEST_VAL_LOSS_MA_FROM_CKPT = checkpoint.get('best_val_loss_ma', float('inf')) # Load best_val_loss_ma\n",
    "        if load_path.endswith(\"denoiser_model_best_train_loss.pth\"): \n",
    "            PREVIOUS_BEST_TRAIN_MODEL_PATH = load_path\n",
    "        elif load_path.endswith(\"denoiser_model_best_val_loss.pth\"): # Check if best val loss model is loaded\n",
    "            PREVIOUS_BEST_VAL_MODEL_PATH = load_path # Update path for best val model\n",
    "        print(f\"Resuming training from epoch {START_EPOCH}. Last best train_loss_ma: {BEST_TRAIN_LOSS_MA_FROM_CKPT:.6f}, Last best val_loss_ma: {BEST_VAL_LOSS_MA_FROM_CKPT:.6f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading checkpoint: {e}. Starting from scratch.\")\n",
    "        START_EPOCH = 0\n",
    "        BEST_TRAIN_LOSS_MA_FROM_CKPT = float('inf')\n",
    "        BEST_VAL_LOSS_MA_FROM_CKPT = float('inf') # Reset on error\n",
    "else:\n",
    "    if load_path_config: # If a path was specified but not found\n",
    "        print(f\"Specified checkpoint not found: {load_path_config}. Starting from scratch.\")\n",
    "    else: # No checkpoint specified and default best not found\n",
    "        print(\"No checkpoint found or specified. Starting from scratch.\")\n",
    "        # Ensure vars are initialized even if starting from scratch (though defaults are usually fine)\n",
    "        BEST_TRAIN_LOSS_MA_FROM_CKPT = float('inf')\n",
    "        BEST_VAL_LOSS_MA_FROM_CKPT = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e65b76",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tensor_to_pil(tensor_img):\n",
    "    tensor_img = (tensor_img.clamp(-1, 1) + 1) / 2\n",
    "    tensor_img = tensor_img.detach().cpu().permute(1, 2, 0).numpy()\n",
    "    if tensor_img.shape[2] == 1:\n",
    "        tensor_img = tensor_img.squeeze(2)\n",
    "    # Ensure array is writeable for PIL\n",
    "    if not tensor_img.flags.writeable:\n",
    "        tensor_img = np.ascontiguousarray(tensor_img)\n",
    "    if tensor_img.dtype != np.uint8: # This check might be problematic if tensor_img is already uint8\n",
    "        pil_img_array = (tensor_img * 255).astype(np.uint8)\n",
    "    else:\n",
    "        pil_img_array = tensor_img # Already uint8\n",
    "    pil_img = PILImage.fromarray(pil_img_array)\n",
    "    return pil_img\n",
    "\n",
    "def save_visualization_samples(generated_tensor, gt_current_tensor, gt_prev_frames_sequence, epoch, save_dir, prefix=\"val_vis\"):\n",
    "    \"\"\"\n",
    "    Saves a visualization comparing a single generated image, its corresponding GT current image,\n",
    "    and the sequence of GT previous frames.\n",
    "    - generated_tensor, gt_current_tensor: [C, H, W]\n",
    "    - gt_prev_frames_sequence: [NumPrev, C, H, W]\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    generated_tensor = generated_tensor.detach().cpu()\n",
    "    gt_current_tensor = gt_current_tensor.detach().cpu()\n",
    "    gt_prev_frames_sequence = gt_prev_frames_sequence.detach().cpu()\n",
    "\n",
    "    num_prev_frames = config.NUM_PREV_FRAMES # Get from global config\n",
    "\n",
    "    num_cols = num_prev_frames + 1  # N previous frames + 1 current GT\n",
    "    # Create a 2 rows, num_cols columns subplot\n",
    "    fig, axs = plt.subplots(2, num_cols, figsize=(num_cols * 3, 6), squeeze=False) # squeeze=False ensures axs is always 2D\n",
    "\n",
    "    try:\n",
    "        # Top row: Previous GT frames and Current GT frame\n",
    "        for i in range(num_prev_frames):\n",
    "            axs[0, i].imshow(tensor_to_pil(gt_prev_frames_sequence[i]))\n",
    "            axs[0, i].set_title(f\"GT Prev {i+1}\")\n",
    "            axs[0, i].axis('off')\n",
    "            axs[1, i].axis('off') # Keep bottom row empty under previous GT frames\n",
    "\n",
    "        axs[0, num_prev_frames].imshow(tensor_to_pil(gt_current_tensor))\n",
    "        axs[0, num_prev_frames].set_title(\"GT Current\")\n",
    "        axs[0, num_prev_frames].axis('off')\n",
    "\n",
    "        # Bottom row, last column: Generated frame (aligned under Current GT)\n",
    "        axs[1, num_prev_frames].imshow(tensor_to_pil(generated_tensor))\n",
    "        axs[1, num_prev_frames].set_title(\"Generated\")\n",
    "        axs[1, num_prev_frames].axis('off')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error visualizing image for prefix {prefix}, epoch {epoch}: {e}\")\n",
    "        # Clear figure and display error text\n",
    "        for r in range(axs.shape[0]):\n",
    "            for c in range(axs.shape[1]):\n",
    "                axs[r,c].axis('off')\n",
    "        fig.clear() \n",
    "        plt.text(0.5, 0.5, \"Error displaying image\", ha=\"center\", va=\"center\", transform=fig.transFigure)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(save_dir, f\"{prefix}_epoch_{epoch:04d}.png\") \n",
    "    plt.savefig(save_path)\n",
    "    plt.close(fig)\n",
    "    return save_path\n",
    "    \n",
    "def prepare_single_sample_for_sampler(sample_data, device):\n",
    "    target_img, action_single, prev_frames_flat_unbatched = sample_data # prev_frames_flat_unbatched is [NumPrev*C, H, W]\n",
    "    \n",
    "    # Add batch dimension (B=1) and move to device\n",
    "    gt_current_frame_batch = target_img.unsqueeze(0).to(device) # Shape: [1, C, H, W]\n",
    "    action_single_batch = action_single.unsqueeze(0).to(device) # Shape: [1, 1]\n",
    "    # prev_frames_flat_for_sampler_input needs to be [B, NumPrev*C, H, W] for the view later if used directly by sampler\n",
    "    # but for DIAMOND sampler, prev_obs is [B, NumPrevFrames, C, H, W]\n",
    "    \n",
    "    num_prev_frames_const = config.NUM_PREV_FRAMES\n",
    "    img_channels_const = DM_IMG_CHANNELS # Assumes DM_IMG_CHANNELS is globally available or from config\n",
    "    img_h_const = config.IMAGE_SIZE\n",
    "    img_w_const = config.IMAGE_SIZE\n",
    "\n",
    "    # Reshape prev_frames_flat_unbatched for sampler input [1, NumPrev, C, H, W]\n",
    "    prev_obs_for_sampler_input_5d = prev_frames_flat_unbatched.view(\n",
    "        num_prev_frames_const,\n",
    "        img_channels_const,\n",
    "        img_h_const,\n",
    "        img_w_const\n",
    "    ).unsqueeze(0).to(device) # Add batch dim and send to device\n",
    "\n",
    "    action_sequence_for_sampler = action_single_batch.repeat(1, config.NUM_PREV_FRAMES).long()\n",
    "    \n",
    "    # For visualization, we want the GT previous frames, unbatched and sequenced: [NumPrev, C, H, W]\n",
    "    gt_prev_frames_seq_for_vis = prev_frames_flat_unbatched.view(\n",
    "        num_prev_frames_const,\n",
    "        img_channels_const,\n",
    "        img_h_const,\n",
    "        img_w_const\n",
    "    ) # This is already on CPU if sample_data came directly from dataset before .to(device)\n",
    "      # It will be detached and moved to CPU again in save_visualization_samples\n",
    "    \n",
    "    return prev_obs_for_sampler_input_5d, action_sequence_for_sampler, gt_current_frame_batch, gt_prev_frames_seq_for_vis\n",
    "\n",
    "print(\"Visualization helpers defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa79752",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_denoiser_epoch(denoiser_model, train_dl, opt, scheduler, grad_clip_val, device, epoch_num_for_log, num_train_batches_total, num_val_batches_total):\n",
    "    denoiser_model.train()\n",
    "    total_loss = 0.0\n",
    "    progress_bar = tqdm(train_dl, desc=f\"Epoch {epoch_num_for_log} [Train]\", leave=False)\n",
    "\n",
    "    num_prev_frames = config.NUM_PREV_FRAMES\n",
    "    c, h, w = config.DM_IMG_CHANNELS, config.IMAGE_SIZE, config.IMAGE_SIZE\n",
    "    accumulation_steps = config.ACCUMULATION_STEPS\n",
    "\n",
    "    opt.zero_grad()\n",
    "\n",
    "    for batch_idx, (target_img_batch, action_batch, prev_frames_flat_batch) in enumerate(progress_bar):\n",
    "        current_batch_size = target_img_batch.shape[0]\n",
    "        target_img_batch = target_img_batch.to(device)\n",
    "        action_batch = action_batch.to(device)\n",
    "        prev_frames_flat_batch = prev_frames_flat_batch.to(device)\n",
    "\n",
    "        prev_frames_seq_batch = prev_frames_flat_batch.view(current_batch_size, num_prev_frames, c, h, w)\n",
    "        batch_obs_tensor = torch.cat((prev_frames_seq_batch, target_img_batch.unsqueeze(1)), dim=1)\n",
    "        batch_act_tensor = action_batch.repeat(1, num_prev_frames).long()\n",
    "        batch_mask_padding = torch.ones(current_batch_size, num_prev_frames + 1, device=device, dtype=torch.bool)\n",
    "        \n",
    "        # Corrected Batch instantiation\n",
    "        current_batch_obj = models.Batch(obs=batch_obs_tensor, act=batch_act_tensor, mask_padding=batch_mask_padding, info=[{}] * current_batch_size)\n",
    "\n",
    "        loss, logs = denoiser_model(current_batch_obj)\n",
    "        loss = loss / accumulation_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if (batch_idx + 1) % accumulation_steps == 0:\n",
    "            if grad_clip_val > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(denoiser_model.parameters(), grad_clip_val)\n",
    "            opt.step()\n",
    "            scheduler.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        total_loss += loss.item() * accumulation_steps\n",
    "        progress_bar.set_postfix({\"Loss\": loss.item() * accumulation_steps, \"LR\": scheduler.get_last_lr()[0]})\n",
    "\n",
    "        # Restored wandb logging\n",
    "        if batch_idx % 10 == 0:\n",
    "            global_step = (epoch_num_for_log - 1) * (num_train_batches_total + num_val_batches_total) + batch_idx\n",
    "            wandb.log({\n",
    "                \"train_batch_loss\": loss.item() * accumulation_steps, # Log un-normalized loss\n",
    "                \"train_batch_denoising_loss\": logs.get(\"loss_denoising\"),\n",
    "            }, step=global_step)\n",
    "\n",
    "    return total_loss / len(train_dl) if len(train_dl) > 0 else 0.0\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_denoiser_epoch(denoiser_model, val_dl, device, epoch_num_for_log, num_train_batches_total, num_val_batches_total):\n",
    "    denoiser_model.eval()\n",
    "    total_loss = 0.0\n",
    "    progress_bar = tqdm(val_dl, desc=f\"Epoch {epoch_num_for_log} [Valid]\", leave=False)\n",
    "    num_prev_frames = config.NUM_PREV_FRAMES\n",
    "    c, h, w = config.DM_IMG_CHANNELS, config.IMAGE_SIZE, config.IMAGE_SIZE\n",
    "\n",
    "    for batch_idx, (target_img_batch, action_batch, prev_frames_flat_batch) in enumerate(progress_bar):\n",
    "        current_batch_size = target_img_batch.shape[0]\n",
    "        target_img_batch = target_img_batch.to(device)\n",
    "        action_batch = action_batch.to(device)\n",
    "        prev_frames_flat_batch = prev_frames_flat_batch.to(device)\n",
    "        prev_frames_seq_batch = prev_frames_flat_batch.view(current_batch_size, num_prev_frames, c, h, w)\n",
    "        batch_obs_tensor = torch.cat((prev_frames_seq_batch, target_img_batch.unsqueeze(1)), dim=1)\n",
    "        batch_act_tensor = action_batch.repeat(1, num_prev_frames).long()\n",
    "        batch_mask_padding = torch.ones(current_batch_size, num_prev_frames + 1, device=device, dtype=torch.bool)\n",
    "        \n",
    "        # Corrected Batch instantiation\n",
    "        current_batch_obj = models.Batch(obs=batch_obs_tensor, act=batch_act_tensor, mask_padding=batch_mask_padding, info=[{}]*current_batch_size)\n",
    "        \n",
    "        loss, logs = denoiser_model(current_batch_obj)\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({\"Val Loss\": loss.item()})\n",
    "        \n",
    "        # Restored wandb logging\n",
    "        if batch_idx % 10 == 0:\n",
    "            global_step = (epoch_num_for_log - 1) * (num_train_batches_total + num_val_batches_total) + num_train_batches_total + batch_idx\n",
    "            wandb.log({\n",
    "                \"val_batch_loss\": loss.item(),\n",
    "                \"val_batch_denoising_loss\": logs.get(\"loss_denoising\"),\n",
    "             }, step=global_step)\n",
    "             \n",
    "    return total_loss / len(val_dl) if len(val_dl) > 0 else 0.0\n",
    "\n",
    "\n",
    "print(\"Training and validation epoch functions adapted for Batch object and Denoiser.forward.\")\n",
    "\n",
    "\n",
    "def train_diamond_model(train_loader, val_loader, start_checkpoint=None, max_steps=None):\n",
    "    \"\"\"Train a denoiser model with the provided dataloaders.\n",
    "\n",
    "    ``max_steps`` bounds training time regardless of dataset size.\"\"\"\n",
    "    device = config.DEVICE\n",
    "    num_steps = max_steps or config.NUM_TRAIN_STEPS\n",
    "\n",
    "    inner_cfg = models.InnerModelConfig(\n",
    "        img_channels=config.DM_IMG_CHANNELS,\n",
    "        num_steps_conditioning=config.NUM_PREV_FRAMES,\n",
    "        cond_channels=config.DM_COND_CHANNELS,\n",
    "        depths=config.DM_UNET_DEPTHS,\n",
    "        channels=config.DM_UNET_CHANNELS,\n",
    "        attn_depths=config.DM_UNET_ATTN_DEPTHS,\n",
    "        num_actions=config.DM_NUM_ACTIONS,\n",
    "        is_upsampler=config.DM_IS_UPSAMPLER,\n",
    "    )\n",
    "    denoiser_cfg = models.DenoiserConfig(\n",
    "        inner_model=inner_cfg,\n",
    "        sigma_data=config.DM_SIGMA_DATA,\n",
    "        sigma_offset_noise=config.DM_SIGMA_OFFSET_NOISE,\n",
    "        noise_previous_obs=config.DM_NOISE_PREVIOUS_OBS,\n",
    "        upsampling_factor=config.DM_UPSAMPLING_FACTOR,\n",
    "    )\n",
    "    denoiser = models.Denoiser(cfg=denoiser_cfg).to(device)\n",
    "    sigma_cfg = models.SigmaDistributionConfig(\n",
    "        loc=config.DM_SIGMA_P_MEAN,\n",
    "        scale=config.DM_SIGMA_P_STD,\n",
    "        sigma_min=config.DM_SIGMA_MIN_TRAIN,\n",
    "        sigma_max=config.DM_SIGMA_MAX_TRAIN,\n",
    "    )\n",
    "    denoiser.setup_training(sigma_cfg)\n",
    "\n",
    "    if start_checkpoint and os.path.exists(start_checkpoint):\n",
    "        state = torch.load(start_checkpoint, map_location=device)\n",
    "        if 'model_state_dict' in state:\n",
    "            denoiser.load_state_dict(state['model_state_dict'])\n",
    "\n",
    "    opt = torch.optim.AdamW(\n",
    "        denoiser.parameters(),\n",
    "        lr=config.LEARNING_RATE,\n",
    "        weight_decay=config.LEARNING_RATE_WEIGHT_DECAY,\n",
    "        eps=config.LEARNING_RATE_EPS,\n",
    "    )\n",
    "\n",
    "    def lr_lambda(step: int):\n",
    "        warmup = config.LEARNING_RATE_WARMUP_STEPS\n",
    "        return float(step) / float(max(1, warmup)) if step < warmup else 1.0\n",
    "\n",
    "    scheduler = LambdaLR(opt, lr_lambda)\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    best_path = os.path.join(config.CHECKPOINT_DIR, \"tmp_incremental_best.pth\")\n",
    "\n",
    "    # Sampler for visualization (similar to _main_training)\n",
    "    sampler_cfg_vis = models.DiffusionSamplerConfig(\n",
    "        num_steps_denoising=config.SAMPLER_NUM_STEPS,\n",
    "        sigma_min=config.SAMPLER_SIGMA_MIN,\n",
    "        sigma_max=config.SAMPLER_SIGMA_MAX,\n",
    "        rho=config.SAMPLER_RHO,\n",
    "        order=config.SAMPLER_ORDER,\n",
    "        s_churn=config.SAMPLER_S_CHURN,\n",
    "        s_tmin=config.SAMPLER_S_TMIN,\n",
    "        s_tmax=config.SAMPLER_S_TMAX,\n",
    "        s_noise=config.SAMPLER_S_NOISE\n",
    "    )\n",
    "    diffusion_sampler_vis = models.DiffusionSampler(denoiser=denoiser, cfg=sampler_cfg_vis)\n",
    "\n",
    "    # Prepare filtered validation subsets for visualization (similar to _main_training)\n",
    "    val_stopped_subset_inc = []\n",
    "    val_moving_subset_inc = []\n",
    "    if hasattr(val_loader, 'dataset') and len(val_loader.dataset) > 0:\n",
    "        val_dataset_for_filter = val_loader.dataset\n",
    "        val_stopped_subset_inc = filter_dataset_by_action(val_dataset_for_filter, target_actions=0.0)\n",
    "        moving_action_val_vis_inc = getattr(config, 'MOVING_ACTION_VALUE_FOR_VIS', 0.13)\n",
    "        val_moving_subset_inc = filter_dataset_by_action(val_dataset_for_filter, target_actions=moving_action_val_vis_inc)\n",
    "\n",
    "    train_iter = iter(train_loader)\n",
    "    pbar = tqdm(range(num_steps), desc=\"Incremental Training Steps\")\n",
    "\n",
    "    for step in pbar:\n",
    "        try:\n",
    "            batch = next(train_iter)\n",
    "        except StopIteration:\n",
    "            train_iter = iter(train_loader)\n",
    "            batch = next(train_iter)\n",
    "\n",
    "        # Ensure batch is on the correct device\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        denoiser.train()\n",
    "        loss, logs = denoiser(batch) # Get logs as well\n",
    "        train_loss_val = loss.item() # Store for logging\n",
    "        loss = loss / config.ACCUMULATION_STEPS\n",
    "        loss.backward()\n",
    "\n",
    "        if (step + 1) % config.ACCUMULATION_STEPS == 0:\n",
    "            if config.GRAD_CLIP_VALUE > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(denoiser.parameters(), config.GRAD_CLIP_VALUE)\n",
    "            opt.step()\n",
    "            scheduler.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        # Logging to wandb (more frequently for steps)\n",
    "        if wandb.run and (step + 1) % 10 == 0: # Log every 10 steps\n",
    "            wandb.log({\n",
    "                \"incremental_step_train_loss\": train_loss_val,\n",
    "                \"incremental_step_denoising_loss\": logs.get(\"loss_denoising\"),\n",
    "                \"incremental_step_learning_rate\": scheduler.get_last_lr()[0]\n",
    "            }, step=step)\n",
    "\n",
    "        if (step + 1) % config.SAVE_MODEL_EVERY == 0 or (step + 1) == num_steps:\n",
    "            current_val_loss = validate_denoiser_epoch(\n",
    "                denoiser, val_loader, device, step + 1, 0, 0 # epoch_num_for_log set to step, might need adjustment if used for global step\n",
    "            )\n",
    "\n",
    "            if wandb.run:\n",
    "                wandb.log({\"incremental_eval_val_loss\": current_val_loss}, step=step)\n",
    "\n",
    "            if current_val_loss < best_val:\n",
    "                best_val = current_val_loss\n",
    "                torch.save({\"model_state_dict\": denoiser.state_dict(), 'step': step, 'val_loss': best_val}, best_path)\n",
    "                if wandb.run:\n",
    "                    wandb.log({\"incremental_best_val_loss\": best_val}, step=step)\n",
    "\n",
    "            # Image Sampling (similar to _main_training, simplified for step-based)\n",
    "            if wandb.run and (step + 1) % config.SAMPLE_EVERY == 0: # Check SAMPLE_EVERY from config\n",
    "                denoiser.eval()\n",
    "                vis_wandb_log_data_inc = {}\n",
    "                fixed_sample_idx_inc = getattr(config, 'FIXED_VIS_SAMPLE_IDX', 0)\n",
    "\n",
    "                if hasattr(val_loader, 'dataset') and fixed_sample_idx_inc < len(val_loader.dataset):\n",
    "                    fixed_sample_data_inc = val_loader.dataset[fixed_sample_idx_inc]\n",
    "                    # Ensure sample_data is a tuple (img, act, prev_frames_flat)\n",
    "                    if not (isinstance(fixed_sample_data_inc, tuple) and len(fixed_sample_data_inc) == 3):\n",
    "                         # Try to get it from .dataset if val_loader.dataset is a Subset\n",
    "                        if isinstance(val_loader.dataset, torch.utils.data.Subset):\n",
    "                            original_dataset = val_loader.dataset.dataset\n",
    "                            original_idx = val_loader.dataset.indices[fixed_sample_idx_inc]\n",
    "                            fixed_sample_data_inc = original_dataset[original_idx]\n",
    "                        else:\n",
    "                            print(f\"Skipping fixed sample visualization: data format error or direct access failed.\")\n",
    "                            fixed_sample_data_inc = None \n",
    "                            \n",
    "                    if fixed_sample_data_inc:\n",
    "                        prev_obs_fixed_inc, prev_act_fixed_inc, gt_fixed_batch_inc, gt_prev_frames_fixed_seq_inc = prepare_single_sample_for_sampler(fixed_sample_data_inc, device)\n",
    "                        with torch.no_grad():\n",
    "                            generated_output_tuple_fixed_inc = diffusion_sampler_vis.sample(prev_obs=prev_obs_fixed_inc, prev_act=prev_act_fixed_inc)\n",
    "                        if generated_output_tuple_fixed_inc:\n",
    "                            generated_image_to_save_fixed_inc = generated_output_tuple_fixed_inc[0][0]\n",
    "                            gt_image_to_save_fixed_inc = gt_fixed_batch_inc[0]\n",
    "                            vis_path_fixed_inc = save_visualization_samples(\n",
    "                                generated_image_to_save_fixed_inc, gt_image_to_save_fixed_inc, gt_prev_frames_fixed_seq_inc,\n",
    "                                step + 1, config.SAMPLE_DIR, prefix=f\"inc_vis_fixed_step{step+1}\"\n",
    "                            )\n",
    "                            vis_wandb_log_data_inc[f\"incremental_samples/fixed_idx_{fixed_sample_idx_inc}\"] = wandb.Image(vis_path_fixed_inc, caption=f\"Step {step+1} Fixed Sample\")\n",
    "\n",
    "                # Simplified: Add one random sample from val_stopped_subset_inc if available\n",
    "                if len(val_stopped_subset_inc) > 0:\n",
    "                    stopped_sample_data_inc = val_stopped_subset_inc[random.randint(0, len(val_stopped_subset_inc) - 1)]\n",
    "                    prev_obs_stop, prev_act_stop, gt_batch_stop, gt_prev_seq_stop = prepare_single_sample_for_sampler(stopped_sample_data_inc, device)\n",
    "                    with torch.no_grad():\n",
    "                        gen_out_stop = diffusion_sampler_vis.sample(prev_obs=prev_obs_stop, prev_act=prev_act_stop)\n",
    "                    if gen_out_stop:\n",
    "                        vis_path_stop = save_visualization_samples(gen_out_stop[0][0], gt_batch_stop[0], gt_prev_seq_stop, step+1, config.SAMPLE_DIR, prefix=f\"inc_vis_stopped_step{step+1}\")\n",
    "                        vis_wandb_log_data_inc[\"incremental_samples/random_stopped\"] = wandb.Image(vis_path_stop, caption=f\"Step {step+1} Random Stopped\")\n",
    "                \n",
    "                if vis_wandb_log_data_inc:\n",
    "                    wandb.log(vis_wandb_log_data_inc, step=step)\n",
    "                denoiser.train() # Set back to train mode\n",
    "        pbar.set_postfix({\"Train Loss\": f\"{train_loss_val:.4f}\", \"Val Loss\": f\"{best_val:.4f}\", \"LR\": f\"{scheduler.get_last_lr()[0]:.2e}\"})\n",
    "\n",
    "    pbar.close()\n",
    "    return best_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3225f4c2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _main_training():\n",
    "\n",
    "    train_dataset, val_dataset = split_dataset()\n",
    "    \n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, pin_memory=True, drop_last=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8, pin_memory=True, drop_last=False)\n",
    "    \n",
    "    print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "    print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "    print(f\"Train Dataloader: {len(train_dataloader)} batches of size {BATCH_SIZE}\")\n",
    "    print(f\"Validation Dataloader: {len(val_dataloader)} batches of size {BATCH_SIZE}\")\n",
    "    \n",
    "    # Prepare filtered validation subsets for visualization ###\n",
    "    if len(val_dataset) > 0:\n",
    "        print(\"Preparing filtered validation subsets for visualization...\")\n",
    "        val_stopped_subset = filter_dataset_by_action(val_dataset, target_actions=0.0)\n",
    "        print(f\"  Found {len(val_stopped_subset)} stopped samples in validation set.\")\n",
    "        \n",
    "        moving_action_val = wandb_config['MOVING_ACTION_VALUE_FOR_VIS']\n",
    "        val_moving_subset = filter_dataset_by_action(val_dataset, target_actions=moving_action_val)\n",
    "        print(f\"  Found {len(val_moving_subset)} moving samples (action {moving_action_val}) in validation set.\")\n",
    "    else:\n",
    "        print(\"Validation dataset is empty. Skipping creation of filtered subsets.\")\n",
    "        val_stopped_subset = Subset(val_dataset, [])\n",
    "        val_moving_subset = Subset(val_dataset, [])\n",
    "    \n",
    "    print(\"--- Starting Training Process ---\")\n",
    "    overall_training_start_time = time.time() \n",
    "    \n",
    "    all_train_losses_for_plot = [] \n",
    "    all_val_losses_for_plot = []   \n",
    "    \n",
    "    train_loss_moving_avg_q = deque(maxlen=TRAIN_MOVING_AVG_WINDOW)\n",
    "    best_train_loss_ma = BEST_TRAIN_LOSS_MA_FROM_CKPT \n",
    "    epochs_without_improvement_train = 0\n",
    "    previous_best_train_model_path = PREVIOUS_BEST_TRAIN_MODEL_PATH \n",
    "    \n",
    "    val_loss_moving_avg_q = deque(maxlen=VAL_MOVING_AVG_WINDOW)\n",
    "    best_val_loss_ma = BEST_VAL_LOSS_MA_FROM_CKPT # Initialize best_val_loss_ma\n",
    "    previous_best_val_model_path = PREVIOUS_BEST_VAL_MODEL_PATH # Initialize previous_best_val_model_path\n",
    "    \n",
    "    final_epoch_completed = START_EPOCH -1 # Corrected initialization\n",
    "    \n",
    "    num_train_batches = len(train_dataloader)\n",
    "    num_val_batches = len(val_dataloader)\n",
    "    \n",
    "    for epoch in range(START_EPOCH, NUM_EPOCHS):\n",
    "        epoch_start_time = time.time()\n",
    "        current_epoch_num_for_log = epoch + 1\n",
    "        # final_epoch_completed = epoch # Moved to end of loop for correct value if early stopping\n",
    "    \n",
    "        avg_train_loss = train_denoiser_epoch(\n",
    "            denoiser_model=denoiser,\n",
    "            train_dl=train_dataloader,\n",
    "            opt=optimizer,\n",
    "            scheduler=lr_scheduler,\n",
    "            grad_clip_val=config.GRAD_CLIP_VALUE,\n",
    "            device=DEVICE,\n",
    "            epoch_num_for_log=current_epoch_num_for_log,\n",
    "            num_train_batches_total=num_train_batches,\n",
    "            num_val_batches_total=num_val_batches\n",
    "        )\n",
    "        \n",
    "        all_train_losses_for_plot.append(avg_train_loss)\n",
    "        train_loss_moving_avg_q.append(avg_train_loss)\n",
    "        current_train_moving_avg = sum(train_loss_moving_avg_q) / len(train_loss_moving_avg_q) if train_loss_moving_avg_q else float('inf')\n",
    "    \n",
    "        avg_val_loss = validate_denoiser_epoch(\n",
    "            denoiser_model=denoiser, \n",
    "            val_dl=val_dataloader, \n",
    "            device=DEVICE, \n",
    "            epoch_num_for_log=current_epoch_num_for_log,\n",
    "            num_train_batches_total=num_train_batches, \n",
    "            num_val_batches_total=num_val_batches      \n",
    "        )\n",
    "        all_val_losses_for_plot.append(avg_val_loss)\n",
    "        val_loss_moving_avg_q.append(avg_val_loss) \n",
    "        current_val_moving_avg = sum(val_loss_moving_avg_q) / len(val_loss_moving_avg_q) if val_loss_moving_avg_q else float('inf')\n",
    "    \n",
    "        epoch_duration_seconds = time.time() - epoch_start_time\n",
    "        epoch_duration_formatted = str(datetime.timedelta(seconds=epoch_duration_seconds))\n",
    "    \n",
    "        print(f\"Epoch {current_epoch_num_for_log}/{NUM_EPOCHS} - Train Loss: {avg_train_loss:.4f} (MA: {current_train_moving_avg:.4f}), Val Loss: {avg_val_loss:.4f} (MA: {current_val_moving_avg:.4f}), Duration: {epoch_duration_formatted}\")\n",
    "    \n",
    "        ### WANDB: Log epoch-level metrics ###\n",
    "        \n",
    "        wandb_log_data = {\n",
    "            \"epoch\": current_epoch_num_for_log,\n",
    "            \"avg_train_loss\": avg_train_loss,\n",
    "            \"train_loss_ma\": current_train_moving_avg,\n",
    "            \"avg_val_loss\": avg_val_loss,\n",
    "            \"val_loss_ma\": current_val_moving_avg,\n",
    "            \"best_val_loss_ma_so_far\": best_val_loss_ma, # Log best val loss MA so far\n",
    "            \"epoch_duration_sec\": epoch_duration_seconds,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr']\n",
    "        }\n",
    "        \n",
    "        if lr_scheduler: lr_scheduler.step(avg_val_loss if isinstance(lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau) else None)\n",
    "    \n",
    "        # Save model based on Validation Loss MA\n",
    "        if current_val_moving_avg < best_val_loss_ma:\n",
    "            improvement_val_over_absolute_best = (best_val_loss_ma - current_val_moving_avg) / abs(best_val_loss_ma + 1e-9) * 100\n",
    "            print(f\"  Val Loss MA improved to {current_val_moving_avg:.6f} from {best_val_loss_ma:.6f} ({improvement_val_over_absolute_best:.2f}% improvement).\")\n",
    "            best_val_loss_ma = current_val_moving_avg\n",
    "            new_best_val_model_path = os.path.join(config.CHECKPOINT_DIR, \"denoiser_model_best_val_loss.pth\")\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': denoiser.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_train_loss,\n",
    "                'val_loss': avg_val_loss,\n",
    "                'best_train_loss_ma': best_train_loss_ma, \n",
    "                'best_val_loss_ma': best_val_loss_ma\n",
    "            }, new_best_val_model_path)\n",
    "            print(f\"  Saved new best model (val loss MA) at epoch {current_epoch_num_for_log}\")\n",
    "            if previous_best_val_model_path and previous_best_val_model_path != new_best_val_model_path and os.path.exists(previous_best_val_model_path):\n",
    "                try:\n",
    "                    os.remove(previous_best_val_model_path)\n",
    "                    print(f\"  Deleted previous best val model: {previous_best_val_model_path}\")\n",
    "                except OSError as e:\n",
    "                    print(f\"  Warning: Could not delete previous best val model '{previous_best_val_model_path}': {e}\")\n",
    "            previous_best_val_model_path = new_best_val_model_path\n",
    "    \n",
    "        should_stop_early = False\n",
    "        # Early stopping logic (using EARLY_STOPPING_MIN_EPOCHS correctly)\n",
    "        if current_epoch_num_for_log > EARLY_STOPPING_MIN_EPOCHS: # Check after min epochs completed\n",
    "            if current_train_moving_avg < best_train_loss_ma : \n",
    "                # ... (rest of early stopping logic seems okay, ensure it uses current_epoch_num_for_log correctly)\n",
    "                improvement_over_absolute_best = (best_train_loss_ma - current_train_moving_avg) / abs(best_train_loss_ma + 1e-9) * 100\n",
    "                print(f\"  Train Loss MA improved to {current_train_moving_avg:.6f} from {best_train_loss_ma:.6f} ({improvement_over_absolute_best:.2f}% improvement).\")\n",
    "                best_train_loss_ma = current_train_moving_avg\n",
    "                epochs_without_improvement_train = 0\n",
    "                new_best_model_path = os.path.join(config.CHECKPOINT_DIR, \"denoiser_model_best_train_loss.pth\")\n",
    "                torch.save({\n",
    "                    'epoch': epoch, 'model_state_dict': denoiser.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(), 'loss': avg_train_loss, \n",
    "                    'val_loss': avg_val_loss, 'best_train_loss_ma': best_train_loss_ma,\n",
    "                    'best_val_loss_ma': best_val_loss_ma # Also save best_val_loss_ma when saving based on train loss\n",
    "                }, new_best_model_path)\n",
    "                print(f\"  Saved new best model (train loss MA) at epoch {current_epoch_num_for_log}\")\n",
    "                if previous_best_train_model_path and previous_best_train_model_path != new_best_model_path and os.path.exists(previous_best_train_model_path):\n",
    "                    try: os.remove(previous_best_train_model_path); print(f\"  Deleted previous best train model: {previous_best_train_model_path}\")\n",
    "                    except OSError as e: print(f\"  Warning: Could not delete previous best train model '{previous_best_train_model_path}': {e}\")\n",
    "                previous_best_train_model_path = new_best_model_path\n",
    "            else: \n",
    "                epochs_without_improvement_train += 1\n",
    "                print(f\"  No improvement in train loss MA for {epochs_without_improvement_train} epoch(s). Best MA: {best_train_loss_ma:.6f}, Current MA: {current_train_moving_avg:.6f}\")\n",
    "                if epochs_without_improvement_train >= EARLY_STOPPING_PATIENCE:\n",
    "                    # ... (percentage improvement check)\n",
    "                    idx_before_streak_started = len(all_train_losses_for_plot) - epochs_without_improvement_train -1 # Index of the epoch before non-improvement streak\n",
    "                    # Ensure indices are valid\n",
    "                    if idx_before_streak_started >= 0:\n",
    "                        # Calculate MA from historical_losses_for_ma of length TRAIN_MOVING_AVG_WINDOW ending at idx_before_streak_started\n",
    "                        historical_window_start = max(0, idx_before_streak_started - TRAIN_MOVING_AVG_WINDOW + 1)\n",
    "                        historical_losses_for_ma_calc = all_train_losses_for_plot[historical_window_start : idx_before_streak_started + 1]\n",
    "    \n",
    "                        if len(historical_losses_for_ma_calc) >= TRAIN_MOVING_AVG_WINDOW // 2 : # Need at least half window\n",
    "                            historical_train_ma = sum(historical_losses_for_ma_calc) / len(historical_losses_for_ma_calc)\n",
    "                            # Improvement is positive if current_train_moving_avg is smaller\n",
    "                            percentage_improvement_vs_historical = (historical_train_ma - current_train_moving_avg) / abs(historical_train_ma + 1e-9) * 100\n",
    "                            print(f\"  Patience met. Current Train MA: {current_train_moving_avg:.6f}, Historical MA before streak ({len(historical_losses_for_ma_calc)} epochs): {historical_train_ma:.6f}. Improvement: {percentage_improvement_vs_historical:.2f}%\")\n",
    "                            if percentage_improvement_vs_historical < EARLY_STOPPING_PERCENTAGE:\n",
    "                                should_stop_early = True\n",
    "                                print(f\"Early stopping triggered: Improvement {percentage_improvement_vs_historical:.2f}% < threshold {EARLY_STOPPING_PERCENTAGE}%.\")\n",
    "                        else:\n",
    "                            print(f\"  Patience met, but not enough historical data ({len(historical_losses_for_ma_calc)} points out of {TRAIN_MOVING_AVG_WINDOW}) to reliably calculate percentage improvement for early stopping.\")\n",
    "                    else:\n",
    "                         print(f\"  Patience met, but not enough historical data (idx_before_streak_started = {idx_before_streak_started}) to compare.\")\n",
    "    \n",
    "        \n",
    "        if (current_epoch_num_for_log % SAVE_MODEL_EVERY == 0) or (epoch == NUM_EPOCHS - 1):\n",
    "            is_best_this_epoch = current_train_moving_avg == best_train_loss_ma # Check if current MA is the best overall\n",
    "            # Avoid saving regular checkpoint if it's also the best_train_loss epoch to prevent duplicate saves\n",
    "            if not (is_best_this_epoch and os.path.join(config.CHECKPOINT_DIR, \"denoiser_model_best_train_loss.pth\") == previous_best_train_model_path):\n",
    "                 torch.save({\n",
    "                    'epoch': epoch, 'model_state_dict': denoiser.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(), 'loss': avg_train_loss,\n",
    "                    'val_loss': avg_val_loss, 'best_train_loss_ma': best_train_loss_ma, # Save current best_train_loss_ma\n",
    "                    'best_val_loss_ma': best_val_loss_ma # Also save best_val_loss_ma for regular epoch saves\n",
    "                }, os.path.join(config.CHECKPOINT_DIR, f\"denoiser_model_epoch_{current_epoch_num_for_log:04d}.pth\"))\n",
    "                 print(f\"Saved model checkpoint at epoch {current_epoch_num_for_log}\")\n",
    "        \n",
    "        final_epoch_completed = epoch # Update last completed epoch here\n",
    "        if should_stop_early: break\n",
    "    \n",
    "        if (current_epoch_num_for_log % SAMPLE_EVERY == 0) or (epoch == NUM_EPOCHS - 1) or should_stop_early:\n",
    "            print(f\"Epoch {current_epoch_num_for_log}: Generating multiple visualization samples...\")\n",
    "            denoiser.eval()\n",
    "            vis_wandb_log_data = {} # Accumulate images here for a single wandb.log call\n",
    "    \n",
    "            # --- 1. Fixed Sample ---\n",
    "            fixed_sample_idx = wandb_config.get('FIXED_VIS_SAMPLE_IDX', 0)\n",
    "            if fixed_sample_idx < len(val_dataset):\n",
    "                print(f\"  Generating fixed sample (index {fixed_sample_idx} from val_dataset)...\")\n",
    "                fixed_sample_data = val_dataset[fixed_sample_idx]\n",
    "                prev_obs_fixed, prev_act_fixed, gt_fixed_batch, gt_prev_frames_fixed_seq = prepare_single_sample_for_sampler(fixed_sample_data, DEVICE) # gt_fixed_batch is [1,C,H,W]\n",
    "                with torch.no_grad():\n",
    "                    generated_output_tuple_fixed = diffusion_sampler.sample(prev_obs=prev_obs_fixed, prev_act=prev_act_fixed)\n",
    "                \n",
    "                if generated_output_tuple_fixed:\n",
    "                    generated_image_batch_fixed = generated_output_tuple_fixed[0] # This is [1, C, H, W]\n",
    "                    if generated_image_batch_fixed.ndim == 4 and generated_image_batch_fixed.shape[0] == 1:\n",
    "                        generated_image_to_save_fixed = generated_image_batch_fixed[0] # Extract single image: [C, H, W]\n",
    "                    else:\n",
    "                        generated_image_to_save_fixed = generated_image_batch_fixed # Fallback, though should be 4D\n",
    "        \n",
    "                    gt_image_to_save_fixed = gt_fixed_batch[0] # Extract single GT image: [C, H, W]\n",
    "        \n",
    "                    vis_path_fixed = save_visualization_samples(\n",
    "                        generated_image_to_save_fixed, # Should be [C,H,W]\n",
    "                        gt_image_to_save_fixed,        # Should be [C,H,W]\n",
    "                        gt_prev_frames_fixed_seq,\n",
    "                        current_epoch_num_for_log,\n",
    "                        config.SAMPLE_DIR,\n",
    "                        prefix=f\"val_vis_fixed_idx{fixed_sample_idx}\"\n",
    "                    )\n",
    "                    if vis_path_fixed and wandb.run:\n",
    "                        vis_wandb_log_data[f\"validation_samples/fixed_idx_{fixed_sample_idx}\"] = wandb.Image(vis_path_fixed, caption=f\"Epoch {current_epoch_num_for_log} Fixed Sample (Val Idx {fixed_sample_idx})\")\n",
    "                else:\n",
    "                    print(\"  Warning: Sampler did not return output for fixed sample.\")\n",
    "            else:\n",
    "                print(f\"  Warning: FIXED_SAMPLE_IDX {fixed_sample_idx} is out of bounds for val_dataset (size {len(val_dataset)}). Skipping fixed sample.\")\n",
    "        \n",
    "            # --- 2. Random Stopped Sample (Action 0.0) ---\n",
    "            if len(val_stopped_subset) > 0:\n",
    "                print(\"  Generating random stopped sample...\")\n",
    "                random_stopped_idx_in_subset = random.randint(0, len(val_stopped_subset) - 1)\n",
    "                stopped_sample_data = val_stopped_subset[random_stopped_idx_in_subset]\n",
    "                prev_obs_stopped, prev_act_stopped, gt_stopped_batch, gt_prev_frames_stopped_seq = prepare_single_sample_for_sampler(stopped_sample_data, DEVICE) # gt_stopped_batch is [1,C,H,W]\n",
    "                with torch.no_grad():\n",
    "                    generated_output_tuple_stopped = diffusion_sampler.sample(prev_obs=prev_obs_stopped, prev_act=prev_act_stopped)\n",
    "                \n",
    "                if generated_output_tuple_stopped:\n",
    "                    generated_image_batch_stopped = generated_output_tuple_stopped[0] # This is [1, C, H, W]\n",
    "                    if generated_image_batch_stopped.ndim == 4 and generated_image_batch_stopped.shape[0] == 1:\n",
    "                        generated_image_to_save_stopped = generated_image_batch_stopped[0] # Extract single image: [C, H, W]\n",
    "                    else:\n",
    "                        generated_image_to_save_stopped = generated_image_batch_stopped\n",
    "        \n",
    "                    gt_image_to_save_stopped = gt_stopped_batch[0] # Extract single GT image: [C, H, W]\n",
    "        \n",
    "                    vis_path_stopped = save_visualization_samples(\n",
    "                        generated_image_to_save_stopped, # Should be [C,H,W]\n",
    "                        gt_image_to_save_stopped,        # Should be [C,H,W]\n",
    "                        gt_prev_frames_stopped_seq,\n",
    "                        current_epoch_num_for_log,\n",
    "                        config.SAMPLE_DIR,\n",
    "                        prefix=\"val_vis_stopped_random\"\n",
    "                    )\n",
    "                    if vis_path_stopped and wandb.run:\n",
    "                        vis_wandb_log_data[\"validation_samples/random_stopped\"] = wandb.Image(vis_path_stopped, caption=f\"Epoch {current_epoch_num_for_log} Random Stopped Sample\")\n",
    "                else:\n",
    "                    print(\"  Warning: Sampler did not return output for stopped sample.\")\n",
    "            else:\n",
    "                print(\"  Warning: No stopped (action 0.0) samples found in validation set. Skipping random stopped sample.\")\n",
    "        \n",
    "            # --- 3. Random Moving Sample ---\n",
    "            moving_action_val_vis = wandb_config.get('MOVING_ACTION_VALUE_FOR_VIS', 0.1)\n",
    "            if len(val_moving_subset) > 0:\n",
    "                print(f\"  Generating random moving sample (action {moving_action_val_vis})...\")\n",
    "                random_moving_idx_in_subset = random.randint(0, len(val_moving_subset) - 1)\n",
    "                moving_sample_data = val_moving_subset[random_moving_idx_in_subset]\n",
    "                prev_obs_moving, prev_act_moving, gt_moving_batch, gt_prev_frames_moving_seq = prepare_single_sample_for_sampler(moving_sample_data, DEVICE) # gt_moving_batch is [1,C,H,W]\n",
    "                with torch.no_grad():\n",
    "                    generated_output_tuple_moving = diffusion_sampler.sample(prev_obs=prev_obs_moving, prev_act=prev_act_moving)\n",
    "        \n",
    "                if generated_output_tuple_moving:\n",
    "                    generated_image_batch_moving = generated_output_tuple_moving[0] # This is [1, C, H, W]\n",
    "                    if generated_image_batch_moving.ndim == 4 and generated_image_batch_moving.shape[0] == 1:\n",
    "                        generated_image_to_save_moving = generated_image_batch_moving[0] # Extract single image: [C, H, W]\n",
    "                    else:\n",
    "                        generated_image_to_save_moving = generated_image_batch_moving\n",
    "        \n",
    "                    gt_image_to_save_moving = gt_moving_batch[0] # Extract single GT image: [C, H, W]\n",
    "        \n",
    "                    vis_path_moving = save_visualization_samples(\n",
    "                        generated_image_to_save_moving, # Should be [C,H,W]\n",
    "                        gt_image_to_save_moving,        # Should be [C,H,W]\n",
    "                        gt_prev_frames_moving_seq,\n",
    "                        current_epoch_num_for_log,\n",
    "                        config.SAMPLE_DIR,\n",
    "                        prefix=f\"val_vis_moving_act{str(moving_action_val_vis).replace('.', 'p')}_random\"\n",
    "                    )\n",
    "                    if vis_path_moving and wandb.run:\n",
    "                        vis_wandb_log_data[f\"validation_samples/random_moving_act{str(moving_action_val_vis).replace('.', 'p')}\"] = wandb.Image(vis_path_moving, caption=f\"Epoch {current_epoch_num_for_log} Random Moving Sample (Action {moving_action_val_vis})\")\n",
    "                else:\n",
    "                    print(\"  Warning: Sampler did not return output for moving sample.\")\n",
    "            else:\n",
    "                print(f\"  Warning: No moving (action {moving_action_val_vis}) samples found in validation set. Skipping random moving sample.\")\n",
    "            \n",
    "            denoiser.train() # Set model back to training mode\n",
    "            # Log all accumulated data for this epoch (losses + images)\n",
    "            if wandb.run:\n",
    "                wandb.log({**wandb_log_data, **vis_wandb_log_data})\n",
    "        elif wandb.run: # If not sampling, still log epoch metrics\n",
    "             wandb.log(wandb_log_data)\n",
    "    \n",
    "    \n",
    "        if (current_epoch_num_for_log % PLOT_EVERY == 0) or (epoch == NUM_EPOCHS - 1) or should_stop_early :\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(all_train_losses_for_plot, label=\"Avg Train Loss\")\n",
    "            plt.plot(all_val_losses_for_plot, label=\"Avg Validation Loss\")\n",
    "            if len(all_train_losses_for_plot) >= TRAIN_MOVING_AVG_WINDOW:\n",
    "                train_ma_plot = [sum(all_train_losses_for_plot[i-TRAIN_MOVING_AVG_WINDOW+1:i+1])/TRAIN_MOVING_AVG_WINDOW for i in range(TRAIN_MOVING_AVG_WINDOW-1, len(all_train_losses_for_plot))]\n",
    "                plt.plot(range(TRAIN_MOVING_AVG_WINDOW-1, len(all_train_losses_for_plot)), train_ma_plot, label=f'Train Loss MA ({TRAIN_MOVING_AVG_WINDOW} epochs)', linestyle=':')\n",
    "            if len(all_val_losses_for_plot) >= VAL_MOVING_AVG_WINDOW:\n",
    "                val_ma_plot = [sum(all_val_losses_for_plot[i-VAL_MOVING_AVG_WINDOW+1:i+1])/VAL_MOVING_AVG_WINDOW for i in range(VAL_MOVING_AVG_WINDOW-1, len(all_val_losses_for_plot))]\n",
    "                plt.plot(range(VAL_MOVING_AVG_WINDOW-1, len(all_val_losses_for_plot)), val_ma_plot, label=f'Val Loss MA ({VAL_MOVING_AVG_WINDOW} epochs)', linestyle='--')\n",
    "            plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(f\"Progress (Epoch {current_epoch_num_for_log})\")\n",
    "            plt.legend(); plt.grid(True)\n",
    "            plt.savefig(os.path.join(config.PLOT_DIR, f\"loss_plot_epoch_{current_epoch_num_for_log:04d}.png\"))\n",
    "            ### WANDB: Log epoch loss plot ###\n",
    "            wandb.log({\"epoch_loss_plot\": wandb.Image(plt, caption=f\"Loss Plot Epoch {current_epoch_num_for_log}\")})\n",
    "            plt.close()\n",
    "            print(f\"Saved loss plot up to epoch {current_epoch_num_for_log}\")\n",
    "    \n",
    "    overall_training_end_time = time.time()\n",
    "    total_training_duration_seconds = overall_training_end_time - overall_training_start_time\n",
    "    total_training_duration_formatted = str(datetime.timedelta(seconds=total_training_duration_seconds))\n",
    "    \n",
    "    # final_epoch_completed is the last epoch index that ran (0-indexed)\n",
    "    print(f\"--- Training Complete (Stopped after epoch {final_epoch_completed + 1}) ---\") \n",
    "    print(f\"Total training duration: {total_training_duration_formatted}\") \n",
    "    \n",
    "    # Final Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(all_train_losses_for_plot, label=\"Avg Train Loss\")\n",
    "    plt.plot(all_val_losses_for_plot, label=\"Avg Validation Loss\")\n",
    "    if len(all_train_losses_for_plot) >= TRAIN_MOVING_AVG_WINDOW:\n",
    "        train_ma_plot = [sum(all_train_losses_for_plot[i-TRAIN_MOVING_AVG_WINDOW+1:i+1])/TRAIN_MOVING_AVG_WINDOW for i in range(TRAIN_MOVING_AVG_WINDOW-1, len(all_train_losses_for_plot))]\n",
    "        plt.plot(range(TRAIN_MOVING_AVG_WINDOW-1, len(all_train_losses_for_plot)), train_ma_plot, label=f'Train Loss MA ({TRAIN_MOVING_AVG_WINDOW} epochs)', linestyle=':')\n",
    "    if len(all_val_losses_for_plot) >= VAL_MOVING_AVG_WINDOW:\n",
    "        val_ma_plot = [sum(all_val_losses_for_plot[i-VAL_MOVING_AVG_WINDOW+1:i+1])/VAL_MOVING_AVG_WINDOW for i in range(VAL_MOVING_AVG_WINDOW-1, len(all_val_losses_for_plot))]\n",
    "        plt.plot(range(VAL_MOVING_AVG_WINDOW-1, len(all_val_losses_for_plot)), val_ma_plot, label=f'Val Loss MA ({VAL_MOVING_AVG_WINDOW} epochs)', linestyle='--')\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(f\"Denoiser Final Training & Validation Loss (Up to Epoch {final_epoch_completed + 1})\")\n",
    "    plt.legend(); plt.grid(True)\n",
    "    final_loss_plot_path = os.path.join(config.PLOT_DIR, \"denoiser_final_loss_plot.png\")\n",
    "    plt.savefig(final_loss_plot_path)\n",
    "    # plt.show() # Usually not needed in script, but can be uncommented for interactive\n",
    "    print(f\"Final loss plot saved to {final_loss_plot_path}\")\n",
    "    \n",
    "    ### WANDB: Log final loss plot and finish run ###\n",
    "    wandb.log({\"final_loss_plot\": wandb.Image(final_loss_plot_path, caption=f\"Final Loss Plot up to Epoch {final_epoch_completed + 1}\")})\n",
    "    wandb.finish()\n",
    "    print(\"Wandb run finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9771991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    _main_training()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
