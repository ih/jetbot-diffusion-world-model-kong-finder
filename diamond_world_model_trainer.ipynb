{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0214e4d-468c-4115-88d0-9c659ec33d2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (0.19.11)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from wandb) (4.25.5)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from wandb) (6.0.0)\n",
      "Requirement already satisfied: pydantic<3 in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from wandb) (2.11.5)\n",
      "Requirement already satisfied: pyyaml in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from wandb) (2.29.1)\n",
      "Requirement already satisfied: setproctitle in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from wandb) (65.5.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from wandb) (4.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from pydantic<3->wandb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from pydantic<3->wandb) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e48a2dd2-c368-4297-bcfe-1212dc70fee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing_extensions in c:\\projects\\pythonenv-deeprl\\lib\\site-packages (4.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "327770bd-1d2e-478f-9c59-a289daaf1d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import datetime # For epoch timing and timestamping\n",
    "from torchvision import transforms\n",
    "from collections import deque # For moving average\n",
    "from dataclasses import dataclass \n",
    "from typing import List, Optional, Dict, Any \n",
    "import random\n",
    "\n",
    "import wandb\n",
    "\n",
    "# Your project's specific imports\n",
    "import config # Your config.py\n",
    "import models # Your models.py (which should import from diamond_models.ipynb)\n",
    "\n",
    "# Import dataset from your jetbot_dataset.ipynb\n",
    "from importnb import Notebook\n",
    "with Notebook():\n",
    "    from jetbot_dataset import JetbotDataset, filter_dataset_by_action \n",
    "\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "print(\"Imports successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad3c713d-d3a3-4ea0-97d0-0c322d3048d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Configuration ---\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Configuration ---\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41855c34-51a6-4282-bb58-c7037352d217",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: irvin-hwang (irvin-hwang-simulacra-systems) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Projects\\jetbot-diffusion-world-model-kong-finder\\wandb\\run-20250603_215808-m0nnnuss</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/irvin-hwang-simulacra-systems/jetbot-diamond-world-model/runs/m0nnnuss' target=\"_blank\">firm-thunder-16</a></strong> to <a href='https://wandb.ai/irvin-hwang-simulacra-systems/jetbot-diamond-world-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/irvin-hwang-simulacra-systems/jetbot-diamond-world-model' target=\"_blank\">https://wandb.ai/irvin-hwang-simulacra-systems/jetbot-diamond-world-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/irvin-hwang-simulacra-systems/jetbot-diamond-world-model/runs/m0nnnuss' target=\"_blank\">https://wandb.ai/irvin-hwang-simulacra-systems/jetbot-diamond-world-model/runs/m0nnnuss</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wandb initialized.\n"
     ]
    }
   ],
   "source": [
    "# Denoiser & InnerModel specific\n",
    "DM_SIGMA_DATA = getattr(config, 'DM_SIGMA_DATA', 0.5)\n",
    "DM_SIGMA_OFFSET_NOISE = getattr(config, 'DM_SIGMA_OFFSET_NOISE', 0.1)\n",
    "DM_NOISE_PREVIOUS_OBS = getattr(config, 'DM_NOISE_PREVIOUS_OBS', True)\n",
    "DM_IMG_CHANNELS = getattr(config, 'DM_IMG_CHANNELS', 3)\n",
    "DM_NUM_STEPS_CONDITIONING = getattr(config, 'DM_NUM_STEPS_CONDITIONING', config.NUM_PREV_FRAMES)\n",
    "DM_COND_CHANNELS = getattr(config, 'DM_COND_CHANNELS', 256)\n",
    "DM_UNET_DEPTHS = getattr(config, 'DM_UNET_DEPTHS', [2, 2, 2, 2])\n",
    "DM_UNET_CHANNELS = getattr(config, 'DM_UNET_CHANNELS', [128, 256, 512, 1024]) # Using config.py\n",
    "DM_UNET_ATTN_DEPTHS = getattr(config, 'DM_UNET_ATTN_DEPTHS', [False, False, True, True])\n",
    "DM_NUM_ACTIONS = getattr(config, 'DM_NUM_ACTIONS', 2)\n",
    "DM_IS_UPSAMPLER = getattr(config, 'DM_IS_UPSAMPLER', False)\n",
    "DM_UPSAMPLING_FACTOR = getattr(config, 'DM_UPSAMPLING_FACTOR', None)\n",
    "\n",
    "# Sampler specific (for inference/visualization)\n",
    "SAMPLER_NUM_STEPS = getattr(config, 'SAMPLER_NUM_STEPS', 50)\n",
    "SAMPLER_SIGMA_MIN = getattr(config, 'SAMPLER_SIGMA_MIN', 0.002)\n",
    "SAMPLER_SIGMA_MAX = getattr(config, 'SAMPLER_SIGMA_MAX', 80.0)\n",
    "SAMPLER_RHO = getattr(config, 'SAMPLER_RHO', 7.0)\n",
    "# Additional Karras sampler params from config if they exist, otherwise defaults in dataclass used\n",
    "SAMPLER_ORDER = getattr(config, 'SAMPLER_ORDER', 1)\n",
    "SAMPLER_S_CHURN = getattr(config, 'SAMPLER_S_CHURN', 0.0)\n",
    "SAMPLER_S_TMIN = getattr(config, 'SAMPLER_S_TMIN', 0.0)\n",
    "SAMPLER_S_TMAX = getattr(config, 'SAMPLER_S_TMAX', float(\"inf\"))\n",
    "SAMPLER_S_NOISE = getattr(config, 'SAMPLER_S_NOISE', 1.0)\n",
    "\n",
    "\n",
    "# Training specific\n",
    "BATCH_SIZE = config.BATCH_SIZE\n",
    "LEARNING_RATE = config.LEARNING_RATE\n",
    "NUM_EPOCHS = config.NUM_EPOCHS\n",
    "SAVE_MODEL_EVERY = config.SAVE_MODEL_EVERY\n",
    "SAMPLE_EVERY = config.SAMPLE_EVERY\n",
    "PLOT_EVERY = config.PLOT_EVERY\n",
    "GRAD_CLIP_VALUE = getattr(config, 'GRAD_CLIP_VALUE', 1.0)\n",
    "\n",
    "DM_SIGMA_P_MEAN = getattr(config, 'DM_SIGMA_P_MEAN', -1.2) \n",
    "DM_SIGMA_P_STD = getattr(config, 'DM_SIGMA_P_STD', 1.2)   \n",
    "DM_SIGMA_MIN_TRAIN = getattr(config, 'DM_SIGMA_MIN_TRAIN', 0.002) \n",
    "DM_SIGMA_MAX_TRAIN = getattr(config, 'DM_SIGMA_MAX_TRAIN', 80.0)  \n",
    "\n",
    "EARLY_STOPPING_PATIENCE = getattr(config, 'EARLY_STOPPING_PATIENCE', 10)\n",
    "EARLY_STOPPING_MIN_EPOCHS = getattr(config, 'MIN_EPOCHS', 20) # Renamed from MIN_EPOCHS in config to avoid ambiguity\n",
    "EARLY_STOPPING_PERCENTAGE = getattr(config, 'EARLY_STOPPING_PERCENTAGE', 0.1) \n",
    "TRAIN_MOVING_AVG_WINDOW = getattr(config, 'TRAIN_MOVING_AVG_WINDOW', 10) \n",
    "VAL_MOVING_AVG_WINDOW = getattr(config, 'VAL_MOVING_AVG_WINDOW', 5) \n",
    "\n",
    "print(\"Configuration loaded.\")\n",
    "\n",
    "# Create a dictionary of your configurations to log with Wandb\n",
    "wandb_config = {\n",
    "    # Denoiser & InnerModel specific\n",
    "    'DM_SIGMA_DATA': DM_SIGMA_DATA,\n",
    "    'DM_SIGMA_OFFSET_NOISE': DM_SIGMA_OFFSET_NOISE,\n",
    "    'DM_NOISE_PREVIOUS_OBS': DM_NOISE_PREVIOUS_OBS,\n",
    "    'DM_IMG_CHANNELS': DM_IMG_CHANNELS,\n",
    "    'DM_NUM_STEPS_CONDITIONING': DM_NUM_STEPS_CONDITIONING,\n",
    "    'DM_COND_CHANNELS': DM_COND_CHANNELS,\n",
    "    'DM_UNET_DEPTHS': DM_UNET_DEPTHS,\n",
    "    'DM_UNET_CHANNELS': DM_UNET_CHANNELS,\n",
    "    'DM_UNET_ATTN_DEPTHS': DM_UNET_ATTN_DEPTHS,\n",
    "    'DM_NUM_ACTIONS': DM_NUM_ACTIONS,\n",
    "    'DM_IS_UPSAMPLER': DM_IS_UPSAMPLER,\n",
    "    'DM_UPSAMPLING_FACTOR': DM_UPSAMPLING_FACTOR,\n",
    "    # Sampler specific\n",
    "    'SAMPLER_NUM_STEPS': SAMPLER_NUM_STEPS,\n",
    "    'SAMPLER_SIGMA_MIN': SAMPLER_SIGMA_MIN,\n",
    "    'SAMPLER_SIGMA_MAX': SAMPLER_SIGMA_MAX,\n",
    "    'SAMPLER_RHO': SAMPLER_RHO,\n",
    "    'SAMPLER_ORDER': SAMPLER_ORDER,\n",
    "    'SAMPLER_S_CHURN': SAMPLER_S_CHURN,\n",
    "    'SAMPLER_S_TMIN': SAMPLER_S_TMIN,\n",
    "    'SAMPLER_S_TMAX': SAMPLER_S_TMAX,\n",
    "    'SAMPLER_S_NOISE': SAMPLER_S_NOISE,\n",
    "    # Training specific\n",
    "    'BATCH_SIZE': BATCH_SIZE,\n",
    "    'LEARNING_RATE': LEARNING_RATE,\n",
    "    'NUM_EPOCHS': NUM_EPOCHS,\n",
    "    'GRAD_CLIP_VALUE': GRAD_CLIP_VALUE,\n",
    "    'DM_SIGMA_P_MEAN': DM_SIGMA_P_MEAN,\n",
    "    'DM_SIGMA_P_STD': DM_SIGMA_P_STD,\n",
    "    'DM_SIGMA_MIN_TRAIN': DM_SIGMA_MIN_TRAIN,\n",
    "    'DM_SIGMA_MAX_TRAIN': DM_SIGMA_MAX_TRAIN,\n",
    "    'EARLY_STOPPING_PATIENCE': EARLY_STOPPING_PATIENCE,\n",
    "    'EARLY_STOPPING_MIN_EPOCHS': EARLY_STOPPING_MIN_EPOCHS,\n",
    "    'EARLY_STOPPING_PERCENTAGE': EARLY_STOPPING_PERCENTAGE,\n",
    "    'TRAIN_MOVING_AVG_WINDOW': TRAIN_MOVING_AVG_WINDOW,\n",
    "    'VAL_MOVING_AVG_WINDOW': VAL_MOVING_AVG_WINDOW,\n",
    "    # From your config.py directly\n",
    "    'IMAGE_SIZE': config.IMAGE_SIZE,\n",
    "    'NUM_PREV_FRAMES': config.NUM_PREV_FRAMES,\n",
    "    'PROJECT_NAME': getattr(config, 'PROJECT_NAME', 'jetbot-diamond-world-model'), # Add a project name\n",
    "    'FIXED_VIS_SAMPLE_IDX': getattr(config, 'FIXED_VIS_SAMPLE_IDX', 0), # For fixed visualization\n",
    "    'MOVING_ACTION_VALUE_FOR_VIS': getattr(config, 'MOVING_ACTION_VALUE_FOR_VIS', 0.13) # For moving visualization\n",
    "\n",
    "}\n",
    "\n",
    "wandb.init(project=wandb_config['PROJECT_NAME'], config=wandb_config)\n",
    "print(\"Wandb initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f4822b7-5130-47a2-b7a9-1715de7e42ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded combined CSV with columns: ['session_id', 'image_path', 'timestamp', 'action']\n",
      "Full dataset size: 14460\n",
      "Loading dataset split from C:\\Projects\\jetbot-diffusion-world-model-kong-finder-aux\\output_model_5hz_DIAMOND_laundry\\dataset_split.pth\n",
      "Training dataset size: 13014\n",
      "Validation dataset size: 1446\n",
      "Train Dataloader: 3253 batches of size 4\n",
      "Validation Dataloader: 362 batches of size 4\n",
      "Preparing filtered validation subsets for visualization...\n",
      "Filtering dataset with 1446 samples for actions: [0.0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16237e209c534cd3aeb0f875dba01ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering Dataset:   0%|          | 0/1446 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered down to 728 samples.\n",
      "  Found 728 stopped samples in validation set.\n",
      "Filtering dataset with 1446 samples for actions: [0.13]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c423b16046c04993bf4efd813e8cf5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering Dataset:   0%|          | 0/1446 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered down to 718 samples.\n",
      "  Found 718 moving samples (action 0.13) in validation set.\n"
     ]
    }
   ],
   "source": [
    "data_transform = config.TRANSFORM\n",
    "\n",
    "full_dataset = JetbotDataset(\n",
    "    csv_path=config.CSV_PATH,\n",
    "    data_dir=config.DATA_DIR,\n",
    "    image_size=config.IMAGE_SIZE,\n",
    "    num_prev_frames=config.NUM_PREV_FRAMES,\n",
    "    transform=data_transform\n",
    ")\n",
    "print(f\"Full dataset size: {len(full_dataset)}\")\n",
    "\n",
    "split_file_path = os.path.join(config.OUTPUT_DIR, getattr(config, 'SPLIT_DATASET_FILENAME', 'dataset_split.pth'))\n",
    "if os.path.exists(split_file_path):\n",
    "    print(f\"Loading dataset split from {split_file_path}\")\n",
    "    split_data = torch.load(split_file_path)\n",
    "    train_indices, val_indices = split_data['train_indices'], split_data['val_indices']\n",
    "    train_dataset = torch.utils.data.Subset(full_dataset, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(full_dataset, val_indices)\n",
    "else:\n",
    "    print(\"Creating new train/val split...\")\n",
    "    total_size = len(full_dataset)\n",
    "    train_size = int(total_size * 0.9)\n",
    "    val_size = total_size - train_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size]) # Using torch.random_split by default\n",
    "    torch.save({\n",
    "        'train_indices': train_dataset.indices,\n",
    "        'val_indices': val_dataset.indices,\n",
    "    }, split_file_path)\n",
    "    print(f\"Saved new dataset split to {split_file_path}\")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Train Dataloader: {len(train_dataloader)} batches of size {BATCH_SIZE}\")\n",
    "print(f\"Validation Dataloader: {len(val_dataloader)} batches of size {BATCH_SIZE}\")\n",
    "\n",
    "# Prepare filtered validation subsets for visualization ###\n",
    "if len(val_dataset) > 0:\n",
    "    print(\"Preparing filtered validation subsets for visualization...\")\n",
    "    val_stopped_subset = filter_dataset_by_action(val_dataset, target_actions=0.0)\n",
    "    print(f\"  Found {len(val_stopped_subset)} stopped samples in validation set.\")\n",
    "    \n",
    "    moving_action_val = wandb_config['MOVING_ACTION_VALUE_FOR_VIS']\n",
    "    val_moving_subset = filter_dataset_by_action(val_dataset, target_actions=moving_action_val)\n",
    "    print(f\"  Found {len(val_moving_subset)} moving samples (action {moving_action_val}) in validation set.\")\n",
    "else:\n",
    "    print(\"Validation dataset is empty. Skipping creation of filtered subsets.\")\n",
    "    val_stopped_subset = Subset(val_dataset, [])\n",
    "    val_moving_subset = Subset(val_dataset, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a88c5dfd-b062-4bc7-9bef-910ede6bcb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing Models ---\n",
      "Using InnerModel (Diamond-style U-Net) as the inner model.\n",
      "InnerModelImpl parameter count: 227,699,203\n",
      "Denoiser model created and training sigma distribution configured. Total parameter count: 227,699,203\n",
      "DiffusionSampler created for visualization.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Initializing Models ---\")\n",
    "\n",
    "# 1. InnerModel (U-Net part of the Denoiser)\n",
    "try:\n",
    "    inner_model_config = models.InnerModelConfig( # This is diamond_models.InnerModelConfig\n",
    "        img_channels=DM_IMG_CHANNELS,\n",
    "        num_steps_conditioning=DM_NUM_STEPS_CONDITIONING, # This is NUM_PREV_FRAMES\n",
    "        cond_channels=DM_COND_CHANNELS,\n",
    "        depths=DM_UNET_DEPTHS,\n",
    "        channels=DM_UNET_CHANNELS,\n",
    "        attn_depths=DM_UNET_ATTN_DEPTHS,\n",
    "        num_actions=DM_NUM_ACTIONS, # From config, e.g., 2 for JetBot\n",
    "        is_upsampler=DM_IS_UPSAMPLER # Will be set by DenoiserConfig later too\n",
    "    )\n",
    "    inner_model_instance = models.InnerModel(inner_model_config).to(DEVICE) # diamond_models.InnerModelImpl\n",
    "    print(\"Using InnerModel (Diamond-style U-Net) as the inner model.\")\n",
    "    print(f\"InnerModelImpl parameter count: {sum(p.numel() for p in inner_model_instance.parameters() if p.requires_grad):,}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not instantiate InnerModelImpl due to: {e}. Ensure 'InnerModelConfig', 'InnerModelImpl', dependencies, and DM_* config parameters are correct.\")\n",
    "    raise\n",
    "\n",
    "# 2. Denoiser (using diamond_models.Denoiser)\n",
    "try:\n",
    "    denoiser_cfg = models.DenoiserConfig( # Our new dataclass\n",
    "        inner_model=inner_model_config, # Pass the config, not the instance here if Denoiser instantiates it.\n",
    "                                        # diamond_models.Denoiser takes an InnerModelConfig for its own InnerModel.\n",
    "                                        # Re-checking diamond_models.py: Denoiser.__init__(self, cfg: DenoiserConfig)\n",
    "                                        # cfg.inner_model.is_upsampler = self.is_upsampler\n",
    "                                        # self.inner_model = InnerModel(cfg.inner_model) <--- Correct, it expects InnerModelConfig in DenoiserConfig\n",
    "        sigma_data=DM_SIGMA_DATA,\n",
    "        sigma_offset_noise=DM_SIGMA_OFFSET_NOISE,\n",
    "        noise_previous_obs=DM_NOISE_PREVIOUS_OBS,\n",
    "        upsampling_factor=DM_UPSAMPLING_FACTOR\n",
    "    )\n",
    "    # Ensure DenoiserConfig's inner_model field matches diamond_models.InnerModelConfig type\n",
    "    # The `models.InnerModelConfig` is already an alias to `diamond_models.InnerModelConfig`\n",
    "    denoiser = models.Denoiser(cfg=denoiser_cfg).to(DEVICE) # Pass the config object\n",
    "    \n",
    "    # Setup training sigma distribution for the Denoiser\n",
    "    sigma_dist_train_cfg = models.SigmaDistributionConfig(\n",
    "        loc=DM_SIGMA_P_MEAN,\n",
    "        scale=DM_SIGMA_P_STD,\n",
    "        sigma_min=DM_SIGMA_MIN_TRAIN,\n",
    "        sigma_max=DM_SIGMA_MAX_TRAIN\n",
    "    )\n",
    "    denoiser.setup_training(sigma_dist_train_cfg) # Call setup_training\n",
    "    print(f\"Denoiser model created and training sigma distribution configured. Total parameter count: {sum(p.numel() for p in denoiser.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Could not instantiate or configure Denoiser (from diamond_models.py) due to: {e}.\")\n",
    "    raise\n",
    "\n",
    "# 3. DiffusionSampler (using diamond_models.DiffusionSampler)\n",
    "try:\n",
    "    sampler_cfg = models.DiffusionSamplerConfig( # Our new dataclass\n",
    "        num_steps_denoising=SAMPLER_NUM_STEPS,\n",
    "        sigma_min=SAMPLER_SIGMA_MIN,\n",
    "        sigma_max=SAMPLER_SIGMA_MAX,\n",
    "        rho=SAMPLER_RHO,\n",
    "        order=SAMPLER_ORDER,\n",
    "        s_churn=SAMPLER_S_CHURN,\n",
    "        s_tmin=SAMPLER_S_TMIN,\n",
    "        s_tmax=SAMPLER_S_TMAX,\n",
    "        s_noise=SAMPLER_S_NOISE\n",
    "    )\n",
    "    diffusion_sampler = models.DiffusionSampler( # This is diamond_models.DiffusionSampler\n",
    "        denoiser=denoiser, # Pass the denoiser instance\n",
    "        cfg=sampler_cfg    # Pass the sampler config object\n",
    "    ) # Sampler itself might not need .to(DEVICE) if it doesn't have parameters\n",
    "    print(\"DiffusionSampler created for visualization.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not instantiate DiffusionSampler (from diamond_models.py) due to: {e}.\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c569caca-e8a2-43c0-b379-7fe99a107dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Setting up Optimizer ---\n",
      "Optimizer: AdamW with LR=5e-05\n",
      "Wandb is watching the denoiser model for gradients and parameters.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Setting up Optimizer ---\")\n",
    "optimizer = torch.optim.AdamW(denoiser.parameters(), lr=LEARNING_RATE)\n",
    "lr_scheduler = None # Placeholder\n",
    "print(f\"Optimizer: AdamW with LR={LEARNING_RATE}\")\n",
    "\n",
    "### WANDB: Added wandb.watch() for gradient tracking ###\n",
    "# Watch the model to log gradients and parameters. log_freq can be adjusted.\n",
    "# For example, log_freq=len(train_dataloader) would log once per epoch.\n",
    "# log_freq=100 means log every 100 batches.\n",
    "# `log=\"all\"` logs gradients and parameters.\n",
    "wandb.watch(denoiser, log=\"all\", log_freq=100) # Adjust log_freq as needed\n",
    "print(\"Wandb is watching the denoiser model for gradients and parameters.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a157fe9b-0b61-4b2d-9901-c985db9a7a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No specific checkpoint in config.LOAD_CHECKPOINT. Found existing best_train_loss model: C:\\Projects\\jetbot-diffusion-world-model-kong-finder-aux\\output_model_5hz_DIAMOND_laundry\\checkpoints\\denoiser_model_best_train_loss.pth\n",
      "Loading checkpoint from: C:\\Projects\\jetbot-diffusion-world-model-kong-finder-aux\\output_model_5hz_DIAMOND_laundry\\checkpoints\\denoiser_model_best_train_loss.pth\n",
      "Resuming training from epoch 161. Last best train_loss_ma: 0.008766\n"
     ]
    }
   ],
   "source": [
    "START_EPOCH = 0\n",
    "BEST_TRAIN_LOSS_MA_FROM_CKPT = float('inf')\n",
    "PREVIOUS_BEST_TRAIN_MODEL_PATH = None\n",
    "BEST_VAL_LOSS_MA_FROM_CKPT = float('inf') # Added for validation loss tracking\n",
    "PREVIOUS_BEST_VAL_MODEL_PATH = None # Added for best validation model path\n",
    "\n",
    "# Correctly use LOAD_CHECKPOINT from config.py for the specific path\n",
    "load_path_config = config.LOAD_CHECKPOINT \n",
    "best_train_loss_model_default_path = os.path.join(config.CHECKPOINT_DIR, \"denoiser_model_best_train_loss.pth\")\n",
    "best_val_loss_model_default_path = os.path.join(config.CHECKPOINT_DIR, \"denoiser_model_best_val_loss.pth\") # Added for val loss checkpoint\n",
    "\n",
    "load_path = load_path_config\n",
    "if load_path: # If a specific path is set in config, use it\n",
    "    print(f\"Attempting to load checkpoint from config.LOAD_CHECKPOINT: {load_path}\")\n",
    "elif os.path.exists(best_val_loss_model_default_path): # Else, try the default best val loss model\n",
    "    load_path = best_val_loss_model_default_path\n",
    "    print(f\"No specific checkpoint in config.LOAD_CHECKPOINT. Found existing best_val_loss model: {load_path}\")\n",
    "elif os.path.exists(best_train_loss_model_default_path): # Else, try the default best train loss model\n",
    "    load_path = best_train_loss_model_default_path\n",
    "    print(f\"No specific checkpoint in config.LOAD_CHECKPOINT. Found existing best_train_loss model: {load_path}\")\n",
    "\n",
    "\n",
    "if load_path and os.path.exists(load_path):\n",
    "    print(f\"Loading checkpoint from: {load_path}\")\n",
    "    try:\n",
    "        checkpoint = torch.load(load_path, map_location=DEVICE)\n",
    "        denoiser.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        START_EPOCH = checkpoint.get('epoch', 0) + 1\n",
    "        BEST_TRAIN_LOSS_MA_FROM_CKPT = checkpoint.get('best_train_loss_ma', float('inf'))\n",
    "        BEST_VAL_LOSS_MA_FROM_CKPT = checkpoint.get('best_val_loss_ma', float('inf')) # Load best_val_loss_ma\n",
    "        if load_path.endswith(\"denoiser_model_best_train_loss.pth\"): \n",
    "            PREVIOUS_BEST_TRAIN_MODEL_PATH = load_path\n",
    "        elif load_path.endswith(\"denoiser_model_best_val_loss.pth\"): # Check if best val loss model is loaded\n",
    "            PREVIOUS_BEST_VAL_MODEL_PATH = load_path # Update path for best val model\n",
    "        print(f\"Resuming training from epoch {START_EPOCH}. Last best train_loss_ma: {BEST_TRAIN_LOSS_MA_FROM_CKPT:.6f}, Last best val_loss_ma: {BEST_VAL_LOSS_MA_FROM_CKPT:.6f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading checkpoint: {e}. Starting from scratch.\")\n",
    "        START_EPOCH = 0\n",
    "        BEST_TRAIN_LOSS_MA_FROM_CKPT = float('inf')\n",
    "        BEST_VAL_LOSS_MA_FROM_CKPT = float('inf') # Reset on error\n",
    "else:\n",
    "    if load_path_config: # If a path was specified but not found\n",
    "        print(f\"Specified checkpoint not found: {load_path_config}. Starting from scratch.\")\n",
    "    else: # No checkpoint specified and default best not found\n",
    "        print(\"No checkpoint found or specified. Starting from scratch.\")\n",
    "        # Ensure vars are initialized even if starting from scratch (though defaults are usually fine)\n",
    "        BEST_TRAIN_LOSS_MA_FROM_CKPT = float('inf')\n",
    "        BEST_VAL_LOSS_MA_FROM_CKPT = float('inf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd2a55d8-725e-4b4b-a8c6-db5ad831aaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization helpers defined.\n"
     ]
    }
   ],
   "source": [
    "def tensor_to_pil(tensor_img):\n",
    "    tensor_img = (tensor_img.clamp(-1, 1) + 1) / 2\n",
    "    tensor_img = tensor_img.detach().cpu().permute(1, 2, 0).numpy()\n",
    "    if tensor_img.shape[2] == 1:\n",
    "        tensor_img = tensor_img.squeeze(2)\n",
    "    # Ensure array is writeable for PIL\n",
    "    if not tensor_img.flags.writeable:\n",
    "        tensor_img = np.ascontiguousarray(tensor_img)\n",
    "    if tensor_img.dtype != np.uint8: # This check might be problematic if tensor_img is already uint8\n",
    "        pil_img_array = (tensor_img * 255).astype(np.uint8)\n",
    "    else:\n",
    "        pil_img_array = tensor_img # Already uint8\n",
    "    pil_img = PILImage.fromarray(pil_img_array)\n",
    "    return pil_img\n",
    "\n",
    "def save_visualization_samples(generated_tensor, gt_current_tensor, gt_prev_frames_sequence, epoch, save_dir, prefix=\"val_vis\"):\n",
    "    \"\"\"\n",
    "    Saves a visualization comparing a single generated image, its corresponding GT current image,\n",
    "    and the sequence of GT previous frames.\n",
    "    - generated_tensor, gt_current_tensor: [C, H, W]\n",
    "    - gt_prev_frames_sequence: [NumPrev, C, H, W]\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    generated_tensor = generated_tensor.detach().cpu()\n",
    "    gt_current_tensor = gt_current_tensor.detach().cpu()\n",
    "    gt_prev_frames_sequence = gt_prev_frames_sequence.detach().cpu()\n",
    "\n",
    "    num_prev_frames = config.NUM_PREV_FRAMES # Get from global config\n",
    "\n",
    "    num_cols = num_prev_frames + 1  # N previous frames + 1 current GT\n",
    "    # Create a 2 rows, num_cols columns subplot\n",
    "    fig, axs = plt.subplots(2, num_cols, figsize=(num_cols * 3, 6), squeeze=False) # squeeze=False ensures axs is always 2D\n",
    "\n",
    "    try:\n",
    "        # Top row: Previous GT frames and Current GT frame\n",
    "        for i in range(num_prev_frames):\n",
    "            axs[0, i].imshow(tensor_to_pil(gt_prev_frames_sequence[i]))\n",
    "            axs[0, i].set_title(f\"GT Prev {i+1}\")\n",
    "            axs[0, i].axis('off')\n",
    "            axs[1, i].axis('off') # Keep bottom row empty under previous GT frames\n",
    "\n",
    "        axs[0, num_prev_frames].imshow(tensor_to_pil(gt_current_tensor))\n",
    "        axs[0, num_prev_frames].set_title(\"GT Current\")\n",
    "        axs[0, num_prev_frames].axis('off')\n",
    "\n",
    "        # Bottom row, last column: Generated frame (aligned under Current GT)\n",
    "        axs[1, num_prev_frames].imshow(tensor_to_pil(generated_tensor))\n",
    "        axs[1, num_prev_frames].set_title(\"Generated\")\n",
    "        axs[1, num_prev_frames].axis('off')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error visualizing image for prefix {prefix}, epoch {epoch}: {e}\")\n",
    "        # Clear figure and display error text\n",
    "        for r in range(axs.shape[0]):\n",
    "            for c in range(axs.shape[1]):\n",
    "                axs[r,c].axis('off')\n",
    "        fig.clear() \n",
    "        plt.text(0.5, 0.5, \"Error displaying image\", ha=\"center\", va=\"center\", transform=fig.transFigure)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(save_dir, f\"{prefix}_epoch_{epoch:04d}.png\") \n",
    "    plt.savefig(save_path)\n",
    "    plt.close(fig)\n",
    "    return save_path\n",
    "    \n",
    "def prepare_single_sample_for_sampler(sample_data, device):\n",
    "    target_img, action_single, prev_frames_flat_unbatched = sample_data # prev_frames_flat_unbatched is [NumPrev*C, H, W]\n",
    "    \n",
    "    # Add batch dimension (B=1) and move to device\n",
    "    gt_current_frame_batch = target_img.unsqueeze(0).to(device) # Shape: [1, C, H, W]\n",
    "    action_single_batch = action_single.unsqueeze(0).to(device) # Shape: [1, 1]\n",
    "    # prev_frames_flat_for_sampler_input needs to be [B, NumPrev*C, H, W] for the view later if used directly by sampler\n",
    "    # but for DIAMOND sampler, prev_obs is [B, NumPrevFrames, C, H, W]\n",
    "    \n",
    "    num_prev_frames_const = config.NUM_PREV_FRAMES\n",
    "    img_channels_const = DM_IMG_CHANNELS # Assumes DM_IMG_CHANNELS is globally available or from config\n",
    "    img_h_const = config.IMAGE_SIZE\n",
    "    img_w_const = config.IMAGE_SIZE\n",
    "\n",
    "    # Reshape prev_frames_flat_unbatched for sampler input [1, NumPrev, C, H, W]\n",
    "    prev_obs_for_sampler_input_5d = prev_frames_flat_unbatched.view(\n",
    "        num_prev_frames_const,\n",
    "        img_channels_const,\n",
    "        img_h_const,\n",
    "        img_w_const\n",
    "    ).unsqueeze(0).to(device) # Add batch dim and send to device\n",
    "\n",
    "    action_sequence_for_sampler = action_single_batch.repeat(1, config.NUM_PREV_FRAMES).long()\n",
    "    \n",
    "    # For visualization, we want the GT previous frames, unbatched and sequenced: [NumPrev, C, H, W]\n",
    "    gt_prev_frames_seq_for_vis = prev_frames_flat_unbatched.view(\n",
    "        num_prev_frames_const,\n",
    "        img_channels_const,\n",
    "        img_h_const,\n",
    "        img_w_const\n",
    "    ) # This is already on CPU if sample_data came directly from dataset before .to(device)\n",
    "      # It will be detached and moved to CPU again in save_visualization_samples\n",
    "    \n",
    "    return prev_obs_for_sampler_input_5d, action_sequence_for_sampler, gt_current_frame_batch, gt_prev_frames_seq_for_vis\n",
    "\n",
    "print(\"Visualization helpers defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "552a8563-7183-497d-953d-7b29f6a86ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation epoch functions adapted for Batch object and Denoiser.forward.\n"
     ]
    }
   ],
   "source": [
    "def train_denoiser_epoch(denoiser_model, train_dl, opt, grad_clip_val, device, epoch_num_for_log, num_train_batches_total, num_val_batches_total): # Added num_batches args\n",
    "    denoiser_model.train()\n",
    "    total_loss = 0.0\n",
    "    progress_bar = tqdm(train_dl, desc=f\"Epoch {epoch_num_for_log} [Train]\", leave=False)\n",
    "    \n",
    "    num_prev_frames = config.NUM_PREV_FRAMES\n",
    "    c, h, w = DM_IMG_CHANNELS, config.IMAGE_SIZE, config.IMAGE_SIZE\n",
    "    \n",
    "    for batch_idx, (target_img_batch, action_batch, prev_frames_flat_batch) in enumerate(progress_bar):\n",
    "        opt.zero_grad()\n",
    "        current_batch_size = target_img_batch.shape[0]\n",
    "        target_img_batch = target_img_batch.to(device)\n",
    "        action_batch = action_batch.to(device)\n",
    "        prev_frames_flat_batch = prev_frames_flat_batch.to(device)\n",
    "        prev_frames_seq_batch = prev_frames_flat_batch.view(current_batch_size, num_prev_frames, c, h, w)\n",
    "        batch_obs_tensor = torch.cat((prev_frames_seq_batch, target_img_batch.unsqueeze(1)), dim=1)\n",
    "        batch_act_tensor = action_batch.repeat(1, num_prev_frames).long()\n",
    "        batch_mask_padding = torch.ones(current_batch_size, num_prev_frames + 1, device=device, dtype=torch.bool)\n",
    "        current_batch_obj = models.Batch(obs=batch_obs_tensor, act=batch_act_tensor, mask_padding=batch_mask_padding)\n",
    "        loss, logs = denoiser_model(current_batch_obj)\n",
    "        loss.backward()\n",
    "        if grad_clip_val > 0: torch.nn.utils.clip_grad_norm_(denoiser_model.parameters(), grad_clip_val)\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({\"Loss\": loss.item(), \"DenoisingLoss\": logs.get(\"loss_denoising\", \"N/A\")})\n",
    "\n",
    "        if batch_idx % 10 == 0: # Log every 10 batches\n",
    "            # Corrected global step calculation using passed-in num_batches\n",
    "            global_step = (epoch_num_for_log - 1) * (num_train_batches_total + num_val_batches_total) + batch_idx\n",
    "            wandb.log({\n",
    "                \"train_batch_loss\": loss.item(),\n",
    "                \"train_batch_denoising_loss\": logs.get(\"loss_denoising\"),\n",
    "            }, step=global_step)\n",
    "    \n",
    "    return total_loss / len(train_dl) if len(train_dl) > 0 else 0\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_denoiser_epoch(denoiser_model, val_dl, device, epoch_num_for_log, num_train_batches_total, num_val_batches_total): # Added num_batches args\n",
    "    denoiser_model.eval()\n",
    "    total_loss = 0.0\n",
    "    progress_bar = tqdm(val_dl, desc=f\"Epoch {epoch_num_for_log} [Valid]\", leave=False)\n",
    "    num_prev_frames = config.NUM_PREV_FRAMES\n",
    "    c, h, w = DM_IMG_CHANNELS, config.IMAGE_SIZE, config.IMAGE_SIZE\n",
    "\n",
    "    for batch_idx, (target_img_batch, action_batch, prev_frames_flat_batch) in enumerate(progress_bar):\n",
    "        current_batch_size = target_img_batch.shape[0]\n",
    "        target_img_batch = target_img_batch.to(device)\n",
    "        action_batch = action_batch.to(device)\n",
    "        prev_frames_flat_batch = prev_frames_flat_batch.to(device)\n",
    "        prev_frames_seq_batch = prev_frames_flat_batch.view(current_batch_size, num_prev_frames, c, h, w)\n",
    "        batch_obs_tensor = torch.cat((prev_frames_seq_batch, target_img_batch.unsqueeze(1)), dim=1)\n",
    "        batch_act_tensor = action_batch.repeat(1, num_prev_frames).long()\n",
    "        batch_mask_padding = torch.ones(current_batch_size, num_prev_frames + 1, device=device, dtype=torch.bool)\n",
    "        current_batch_obj = models.Batch(obs=batch_obs_tensor, act=batch_act_tensor, mask_padding=batch_mask_padding)\n",
    "        loss, logs = denoiser_model(current_batch_obj)\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({\"Val Loss\": loss.item(), \"DenoisingLoss\": logs.get(\"loss_denoising\", \"N/A\")})\n",
    "\n",
    "        if batch_idx % 10 == 0: # Log every 10 batches\n",
    "            # Corrected global step calculation using passed-in num_batches\n",
    "            global_step = (epoch_num_for_log - 1) * (num_train_batches_total + num_val_batches_total) + num_train_batches_total + batch_idx\n",
    "            wandb.log({\n",
    "                \"val_batch_loss\": loss.item(),\n",
    "                \"val_batch_denoising_loss\": logs.get(\"loss_denoising\"),\n",
    "             }, step=global_step)\n",
    "    \n",
    "    return total_loss / len(val_dl) if len(val_dl) > 0 else 0\n",
    "\n",
    "\n",
    "print(\"Training and validation epoch functions adapted for Batch object and Denoiser.forward.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "098af240-7c1a-442a-9ae2-9903e367a7fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Training Process ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 162 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 162 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/1000 - Train Loss: 0.0087 (MA: 0.0087), Val Loss: 0.0104 (MA: 0.0104), Duration: 0:13:12.932615\n",
      "  Train Loss MA improved to 0.008673 from 0.008766 (1.06% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 162\n",
      "Epoch 162: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 163 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 163 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/1000 - Train Loss: 0.0085 (MA: 0.0086), Val Loss: 0.0103 (MA: 0.0103), Duration: 0:13:10.263848\n",
      "  Train Loss MA improved to 0.008567 from 0.008673 (1.22% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 163\n",
      "Epoch 163: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 164 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 164 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/1000 - Train Loss: 0.0085 (MA: 0.0086), Val Loss: 0.0104 (MA: 0.0103), Duration: 0:13:08.582960\n",
      "  Train Loss MA improved to 0.008554 from 0.008567 (0.15% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 164\n",
      "Epoch 164: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 165 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 165 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/1000 - Train Loss: 0.0087 (MA: 0.0086), Val Loss: 0.0100 (MA: 0.0103), Duration: 0:13:08.809205\n",
      "  No improvement in train loss MA for 1 epoch(s). Best MA: 0.008554, Current MA: 0.008583\n",
      "Epoch 165: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 166 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 166 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/1000 - Train Loss: 0.0086 (MA: 0.0086), Val Loss: 0.0101 (MA: 0.0102), Duration: 0:13:08.974950\n",
      "  No improvement in train loss MA for 2 epoch(s). Best MA: 0.008554, Current MA: 0.008594\n",
      "Epoch 166: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 167 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 167 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/1000 - Train Loss: 0.0085 (MA: 0.0086), Val Loss: 0.0101 (MA: 0.0102), Duration: 0:13:09.021085\n",
      "  No improvement in train loss MA for 3 epoch(s). Best MA: 0.008554, Current MA: 0.008570\n",
      "Epoch 167: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 168 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 168 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000 - Train Loss: 0.0086 (MA: 0.0086), Val Loss: 0.0101 (MA: 0.0101), Duration: 0:13:10.573066\n",
      "  No improvement in train loss MA for 4 epoch(s). Best MA: 0.008554, Current MA: 0.008579\n",
      "Epoch 168: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 169 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 169 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000 - Train Loss: 0.0085 (MA: 0.0086), Val Loss: 0.0099 (MA: 0.0100), Duration: 0:13:09.245794\n",
      "  No improvement in train loss MA for 5 epoch(s). Best MA: 0.008554, Current MA: 0.008568\n",
      "  Patience met, but not enough historical data (3 points out of 10) to reliably calculate percentage improvement for early stopping.\n",
      "Epoch 169: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 170 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 170 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/1000 - Train Loss: 0.0084 (MA: 0.0085), Val Loss: 0.0100 (MA: 0.0100), Duration: 0:13:08.974674\n",
      "  Train Loss MA improved to 0.008546 from 0.008554 (0.10% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 170\n",
      "Epoch 170: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n",
      "Saved loss plot up to epoch 170\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 171 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 171 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/1000 - Train Loss: 0.0083 (MA: 0.0085), Val Loss: 0.0104 (MA: 0.0101), Duration: 0:13:07.181937\n",
      "  Train Loss MA improved to 0.008525 from 0.008546 (0.25% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 171\n",
      "Epoch 171: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 172 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 172 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000 - Train Loss: 0.0087 (MA: 0.0085), Val Loss: 0.0094 (MA: 0.0100), Duration: 0:13:06.681893\n",
      "  No improvement in train loss MA for 1 epoch(s). Best MA: 0.008525, Current MA: 0.008527\n",
      "Epoch 172: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 173 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 173 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/1000 - Train Loss: 0.0083 (MA: 0.0085), Val Loss: 0.0128 (MA: 0.0105), Duration: 0:13:06.575550\n",
      "  Train Loss MA improved to 0.008512 from 0.008525 (0.15% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 173\n",
      "Epoch 173: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 174 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 174 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/1000 - Train Loss: 0.0085 (MA: 0.0085), Val Loss: 0.0095 (MA: 0.0104), Duration: 0:13:06.930505\n",
      "  No improvement in train loss MA for 1 epoch(s). Best MA: 0.008512, Current MA: 0.008512\n",
      "Epoch 174: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 175 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 175 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/1000 - Train Loss: 0.0084 (MA: 0.0085), Val Loss: 0.0106 (MA: 0.0106), Duration: 0:13:08.751127\n",
      "  Train Loss MA improved to 0.008482 from 0.008512 (0.35% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 175\n",
      "Epoch 175: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 176 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 176 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/1000 - Train Loss: 0.0083 (MA: 0.0084), Val Loss: 0.0096 (MA: 0.0104), Duration: 0:13:07.051481\n",
      "  Train Loss MA improved to 0.008447 from 0.008482 (0.41% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 176\n",
      "Epoch 176: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 177 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 177 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/1000 - Train Loss: 0.0084 (MA: 0.0084), Val Loss: 0.0100 (MA: 0.0105), Duration: 0:13:07.216748\n",
      "  Train Loss MA improved to 0.008444 from 0.008447 (0.04% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 177\n",
      "Epoch 177: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 178 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a841b3b977148128391db025358a527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 178 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/1000 - Train Loss: 0.0083 (MA: 0.0084), Val Loss: 0.0100 (MA: 0.0100), Duration: 0:13:07.779427\n",
      "  Train Loss MA improved to 0.008408 from 0.008444 (0.43% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 178\n",
      "Epoch 178: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a006fa14a504e198ac24bf09212b4a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 179 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7792fc323b2423daaea827fc650be66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 179 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/1000 - Train Loss: 0.0083 (MA: 0.0084), Val Loss: 0.0095 (MA: 0.0100), Duration: 0:13:06.040650\n",
      "  Train Loss MA improved to 0.008391 from 0.008408 (0.20% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 179\n",
      "Epoch 179: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47407fae4f1c4ded9c1a743ac48976bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 180 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c3d9bfb4d34919b7139d2ff9f9088f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 180 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/1000 - Train Loss: 0.0084 (MA: 0.0084), Val Loss: 0.0098 (MA: 0.0098), Duration: 0:13:07.725927\n",
      "  No improvement in train loss MA for 1 epoch(s). Best MA: 0.008391, Current MA: 0.008398\n",
      "Epoch 180: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n",
      "Saved loss plot up to epoch 180\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3e64d618aa48208be6b0f01fbd5d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 181 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b814ac84d447a6a9e92f7f6f409db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 181 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1000 - Train Loss: 0.0083 (MA: 0.0084), Val Loss: 0.0101 (MA: 0.0099), Duration: 0:13:08.272331\n",
      "  No improvement in train loss MA for 2 epoch(s). Best MA: 0.008391, Current MA: 0.008393\n",
      "Epoch 181: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7942739177684e93a601b6366e3e72d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 182 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de0f4f2cbdf495baf1f100425cf5af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 182 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/1000 - Train Loss: 0.0082 (MA: 0.0083), Val Loss: 0.0099 (MA: 0.0098), Duration: 0:13:06.219331\n",
      "  Train Loss MA improved to 0.008342 from 0.008391 (0.59% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 182\n",
      "Epoch 182: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fedaea2df5ba4eec98c62c12e5694fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 183 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6345caf756046ba9f543a05d1a2236b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 183 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/1000 - Train Loss: 0.0083 (MA: 0.0083), Val Loss: 0.0124 (MA: 0.0103), Duration: 0:13:05.927232\n",
      "  Train Loss MA improved to 0.008341 from 0.008342 (0.02% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 183\n",
      "Epoch 183: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e35ea267890f4d33b450ba11c71fa34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 184 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da94fb23d3d647b5b251d5dcf9af3892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 184 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/1000 - Train Loss: 0.0083 (MA: 0.0083), Val Loss: 0.0095 (MA: 0.0103), Duration: 0:13:07.291845\n",
      "  Train Loss MA improved to 0.008316 from 0.008341 (0.30% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 184\n",
      "Epoch 184: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d73042dec44827a253323bfacdc594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 185 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9c4a059891445c99f5d7267f633312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 185 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/1000 - Train Loss: 0.0082 (MA: 0.0083), Val Loss: 0.0096 (MA: 0.0103), Duration: 0:13:05.495980\n",
      "  Train Loss MA improved to 0.008298 from 0.008316 (0.21% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 185\n",
      "Epoch 185: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e63234ee524329973bef2f3eebcc4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 186 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11b8b5255d24f738f10987672b60218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 186 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/1000 - Train Loss: 0.0083 (MA: 0.0083), Val Loss: 0.0094 (MA: 0.0102), Duration: 0:13:06.240349\n",
      "  No improvement in train loss MA for 1 epoch(s). Best MA: 0.008298, Current MA: 0.008303\n",
      "Epoch 186: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde90610dadc452f80f1a097dae64104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 187 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6229111240454ea4bb85c91f82c971c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 187 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/1000 - Train Loss: 0.0082 (MA: 0.0083), Val Loss: 0.0097 (MA: 0.0101), Duration: 0:13:03.734879\n",
      "  Train Loss MA improved to 0.008281 from 0.008298 (0.21% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 187\n",
      "Epoch 187: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3365922653404971a8c929c17549b2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 188 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07f65ffece14958bf897677754f2bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 188 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/1000 - Train Loss: 0.0080 (MA: 0.0083), Val Loss: 0.0091 (MA: 0.0095), Duration: 0:13:06.267921\n",
      "  Train Loss MA improved to 0.008251 from 0.008281 (0.37% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 188\n",
      "Epoch 188: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b850c621b74124a50977e3783b1c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 189 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22ee127017b4534b3cfeda1e05f5baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 189 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/1000 - Train Loss: 0.0083 (MA: 0.0083), Val Loss: 0.0094 (MA: 0.0095), Duration: 0:13:03.120329\n",
      "  No improvement in train loss MA for 1 epoch(s). Best MA: 0.008251, Current MA: 0.008251\n",
      "Epoch 189: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3324b46b6a94be4bf497ce18a49d19c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 190 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf79b36106b4026afe4af79b79ca250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 190 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/1000 - Train Loss: 0.0079 (MA: 0.0082), Val Loss: 0.0095 (MA: 0.0094), Duration: 0:13:04.532690\n",
      "  Train Loss MA improved to 0.008201 from 0.008251 (0.61% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 190\n",
      "Epoch 190: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n",
      "Saved loss plot up to epoch 190\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f520ce4c1b41e3bc929700e13ed3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 191 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3005a0920ed4ed39bdef9065756ff5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 191 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/1000 - Train Loss: 0.0081 (MA: 0.0082), Val Loss: 0.0098 (MA: 0.0095), Duration: 0:13:03.043549\n",
      "  Train Loss MA improved to 0.008178 from 0.008201 (0.27% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 191\n",
      "Epoch 191: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca34c2f8fc13424c86db0a06ab1e3f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 192 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f1c317bef64b48a4649d314dc9096d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 192 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/1000 - Train Loss: 0.0080 (MA: 0.0082), Val Loss: 0.0095 (MA: 0.0095), Duration: 0:13:03.908586\n",
      "  Train Loss MA improved to 0.008159 from 0.008178 (0.23% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 192\n",
      "Epoch 192: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c9351af7b24f16853cbee59ee7a8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 193 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4a040363934c0e843d0c44ebc2e553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 193 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/1000 - Train Loss: 0.0080 (MA: 0.0081), Val Loss: 0.0099 (MA: 0.0096), Duration: 0:13:03.353022\n",
      "  Train Loss MA improved to 0.008132 from 0.008159 (0.33% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 193\n",
      "Epoch 193: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c74187201c43efa5a182ee51fe87e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 194 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3dc664477744bd1818259f57774a498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 194 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/1000 - Train Loss: 0.0079 (MA: 0.0081), Val Loss: 0.0106 (MA: 0.0099), Duration: 0:13:04.166636\n",
      "  Train Loss MA improved to 0.008093 from 0.008132 (0.48% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 194\n",
      "Epoch 194: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6e445ee66644929216406ac868f93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 195 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd41491d36640208a54ea2b9985122f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 195 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/1000 - Train Loss: 0.0081 (MA: 0.0081), Val Loss: 0.0099 (MA: 0.0100), Duration: 0:13:05.197145\n",
      "  Train Loss MA improved to 0.008089 from 0.008093 (0.05% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 195\n",
      "Epoch 195: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9a0001c4ab4b58b1c81b96565cef77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 196 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4e5d7229b3437e97036266ab182b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 196 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196/1000 - Train Loss: 0.0080 (MA: 0.0081), Val Loss: 0.0103 (MA: 0.0100), Duration: 0:13:03.669448\n",
      "  Train Loss MA improved to 0.008058 from 0.008089 (0.38% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 196\n",
      "Epoch 196: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5208021875334d70aa11324893ff69c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 197 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958d803aafcd4ff1bfffccdbd09ea69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 197 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/1000 - Train Loss: 0.0080 (MA: 0.0080), Val Loss: 0.0100 (MA: 0.0101), Duration: 0:13:03.171759\n",
      "  Train Loss MA improved to 0.008042 from 0.008058 (0.20% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 197\n",
      "Epoch 197: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f261381caac0464db431bf81f2d4eecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 198 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cfcdf2598b541619881d873cecb6e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 198 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/1000 - Train Loss: 0.0079 (MA: 0.0080), Val Loss: 0.0095 (MA: 0.0101), Duration: 0:13:03.664426\n",
      "  Train Loss MA improved to 0.008032 from 0.008042 (0.12% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 198\n",
      "Epoch 198: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8192b393c2de4a47813752ea6fee6d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 199 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e77640411a4f558211375220e8ecfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 199 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/1000 - Train Loss: 0.0079 (MA: 0.0080), Val Loss: 0.0102 (MA: 0.0100), Duration: 0:13:05.086125\n",
      "  Train Loss MA improved to 0.007990 from 0.008032 (0.53% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 199\n",
      "Epoch 199: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6418d572b04f18b7184444353c8558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 200 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8862bf969e354f7da07daa057a6b6305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 200 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/1000 - Train Loss: 0.0079 (MA: 0.0080), Val Loss: 0.0097 (MA: 0.0099), Duration: 0:13:03.639387\n",
      "  Train Loss MA improved to 0.007983 from 0.007990 (0.09% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 200\n",
      "Epoch 200: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n",
      "Saved loss plot up to epoch 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 201 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 201 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/1000 - Train Loss: 0.0079 (MA: 0.0080), Val Loss: 0.0098 (MA: 0.0098), Duration: 0:13:07.154952\n",
      "  Train Loss MA improved to 0.007969 from 0.007983 (0.18% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 201\n",
      "Epoch 201: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 202 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 202 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202/1000 - Train Loss: 0.0080 (MA: 0.0080), Val Loss: 0.0089 (MA: 0.0096), Duration: 0:13:03.677889\n",
      "  No improvement in train loss MA for 1 epoch(s). Best MA: 0.007969, Current MA: 0.007972\n",
      "Epoch 202: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 203 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 203 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203/1000 - Train Loss: 0.0077 (MA: 0.0079), Val Loss: 0.0090 (MA: 0.0095), Duration: 0:13:05.539957\n",
      "  Train Loss MA improved to 0.007943 from 0.007969 (0.32% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 203\n",
      "Epoch 203: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 204 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 204 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204/1000 - Train Loss: 0.0079 (MA: 0.0079), Val Loss: 0.0101 (MA: 0.0095), Duration: 0:13:04.841214\n",
      "  No improvement in train loss MA for 1 epoch(s). Best MA: 0.007943, Current MA: 0.007948\n",
      "Epoch 204: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 205 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 205 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205/1000 - Train Loss: 0.0079 (MA: 0.0079), Val Loss: 0.0094 (MA: 0.0095), Duration: 0:13:04.224736\n",
      "  Train Loss MA improved to 0.007925 from 0.007943 (0.23% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 205\n",
      "Epoch 205: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 206 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 206 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206/1000 - Train Loss: 0.0078 (MA: 0.0079), Val Loss: 0.0096 (MA: 0.0094), Duration: 0:13:03.161351\n",
      "  Train Loss MA improved to 0.007904 from 0.007925 (0.27% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 206\n",
      "Epoch 206: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 207 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 207 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207/1000 - Train Loss: 0.0078 (MA: 0.0079), Val Loss: 0.0100 (MA: 0.0096), Duration: 0:13:04.622776\n",
      "  Train Loss MA improved to 0.007881 from 0.007904 (0.29% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 207\n",
      "Epoch 207: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 208 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 208 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/1000 - Train Loss: 0.0079 (MA: 0.0079), Val Loss: 0.0097 (MA: 0.0098), Duration: 0:13:04.938059\n",
      "  No improvement in train loss MA for 1 epoch(s). Best MA: 0.007881, Current MA: 0.007886\n",
      "Epoch 208: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 209 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 209 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/1000 - Train Loss: 0.0079 (MA: 0.0079), Val Loss: 0.0092 (MA: 0.0096), Duration: 0:13:04.101113\n",
      "  No improvement in train loss MA for 2 epoch(s). Best MA: 0.007881, Current MA: 0.007886\n",
      "Epoch 209: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 210 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 210 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210/1000 - Train Loss: 0.0077 (MA: 0.0079), Val Loss: 0.0100 (MA: 0.0097), Duration: 0:13:04.010712\n",
      "  Train Loss MA improved to 0.007871 from 0.007881 (0.12% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 210\n",
      "Epoch 210: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n",
      "Saved loss plot up to epoch 210\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 211 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 211 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/1000 - Train Loss: 0.0078 (MA: 0.0079), Val Loss: 0.0089 (MA: 0.0096), Duration: 0:13:06.111940\n",
      "  Train Loss MA improved to 0.007863 from 0.007871 (0.10% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 211\n",
      "Epoch 211: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 212 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 212 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212/1000 - Train Loss: 0.0076 (MA: 0.0078), Val Loss: 0.0098 (MA: 0.0095), Duration: 0:13:04.237962\n",
      "  Train Loss MA improved to 0.007818 from 0.007863 (0.58% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 212\n",
      "Epoch 212: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 213 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 213 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/1000 - Train Loss: 0.0078 (MA: 0.0078), Val Loss: 0.0099 (MA: 0.0096), Duration: 0:13:19.263400\n",
      "  No improvement in train loss MA for 1 epoch(s). Best MA: 0.007818, Current MA: 0.007824\n",
      "Epoch 213: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 214 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 214 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214/1000 - Train Loss: 0.0079 (MA: 0.0078), Val Loss: 0.0097 (MA: 0.0097), Duration: 0:13:25.601215\n",
      "  Train Loss MA improved to 0.007817 from 0.007818 (0.01% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 214\n",
      "Epoch 214: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 215 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 215 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/1000 - Train Loss: 0.0076 (MA: 0.0078), Val Loss: 0.0095 (MA: 0.0096), Duration: 0:13:26.931171\n",
      "  Train Loss MA improved to 0.007789 from 0.007817 (0.36% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 215\n",
      "Epoch 215: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 216 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 216 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/1000 - Train Loss: 0.0078 (MA: 0.0078), Val Loss: 0.0121 (MA: 0.0102), Duration: 0:13:25.359940\n",
      "  Train Loss MA improved to 0.007783 from 0.007789 (0.08% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 216\n",
      "Epoch 216: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 217 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 217 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/1000 - Train Loss: 0.0077 (MA: 0.0078), Val Loss: 0.0099 (MA: 0.0102), Duration: 0:13:24.517374\n",
      "  Train Loss MA improved to 0.007775 from 0.007783 (0.10% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 217\n",
      "Epoch 217: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 218 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 218 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/1000 - Train Loss: 0.0077 (MA: 0.0077), Val Loss: 0.0088 (MA: 0.0100), Duration: 0:13:25.545886\n",
      "  Train Loss MA improved to 0.007750 from 0.007775 (0.32% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 218\n",
      "Epoch 218: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 219 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 219 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219/1000 - Train Loss: 0.0077 (MA: 0.0077), Val Loss: 0.0101 (MA: 0.0101), Duration: 0:13:25.037696\n",
      "  Train Loss MA improved to 0.007731 from 0.007750 (0.25% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 219\n",
      "Epoch 219: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 220 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 220 [Valid]:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/1000 - Train Loss: 0.0076 (MA: 0.0077), Val Loss: 0.0101 (MA: 0.0102), Duration: 0:13:35.275565\n",
      "  Train Loss MA improved to 0.007722 from 0.007731 (0.11% improvement).\n",
      "  Saved new best model (train loss MA) at epoch 220\n",
      "Epoch 220: Generating multiple visualization samples...\n",
      "  Generating fixed sample (index 0 from val_dataset)...\n",
      "  Generating random stopped sample...\n",
      "  Generating random moving sample (action 0.13)...\n",
      "Saved loss plot up to epoch 220\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e873f6ca1042dfabfecfd1be754181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 221 [Train]:   0%|          | 0/3253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m current_epoch_num_for_log \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# final_epoch_completed = epoch # Moved to end of loop for correct value if early stopping\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_denoiser_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdenoiser_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdenoiser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_clip_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGRAD_CLIP_VALUE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch_num_for_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_epoch_num_for_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_batches_total\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_train_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_val_batches_total\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_val_batches\u001b[49m\u001b[43m      \u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m all_train_losses_for_plot\u001b[38;5;241m.\u001b[39mappend(avg_train_loss)\n\u001b[0;32m     34\u001b[0m train_loss_moving_avg_q\u001b[38;5;241m.\u001b[39mappend(avg_train_loss)\n",
      "Cell \u001b[1;32mIn[11], line 9\u001b[0m, in \u001b[0;36mtrain_denoiser_epoch\u001b[1;34m(denoiser_model, train_dl, opt, grad_clip_val, device, epoch_num_for_log, num_train_batches_total, num_val_batches_total)\u001b[0m\n\u001b[0;32m      6\u001b[0m num_prev_frames \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mNUM_PREV_FRAMES\n\u001b[0;32m      7\u001b[0m c, h, w \u001b[38;5;241m=\u001b[39m DM_IMG_CHANNELS, config\u001b[38;5;241m.\u001b[39mIMAGE_SIZE, config\u001b[38;5;241m.\u001b[39mIMAGE_SIZE\n\u001b[1;32m----> 9\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_img_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_frames_flat_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcurrent_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget_img_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mC:\\Projects\\pythonenv-deeprl\\Lib\\site-packages\\tqdm\\notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[1;32m--> 250\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Projects\\pythonenv-deeprl\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mC:\\Projects\\pythonenv-deeprl\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mC:\\Projects\\pythonenv-deeprl\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mC:\\Projects\\pythonenv-deeprl\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mC:\\Projects\\pythonenv-deeprl\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:399\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mC:\\Projects\\pythonenv-deeprl\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:399\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mC:\\Projects\\jetbot-diffusion-world-model-kong-finder\\jetbot_dataset.py:95\u001b[0m, in \u001b[0;36mJetbotDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     92\u001b[0m     prev_img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir, prev_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m'\u001b[39m]))\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     93\u001b[0m     prev_frames\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(prev_img) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;28;01melse\u001b[39;00m prev_img)\n\u001b[1;32m---> 95\u001b[0m cur_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_img\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;28;01melse\u001b[39;00m cur_img\n\u001b[0;32m     96\u001b[0m prev_frames_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(prev_frames, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cur_img, torch\u001b[38;5;241m.\u001b[39mtensor([action], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32), prev_frames_tensor\n",
      "File \u001b[1;32mC:\\Projects\\pythonenv-deeprl\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mC:\\Projects\\pythonenv-deeprl\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Projects\\pythonenv-deeprl\\Lib\\site-packages\\torchvision\\transforms\\functional.py:173\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    171\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mview(pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m], pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m], F_pil\u001b[38;5;241m.\u001b[39mget_image_num_channels(pic))\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mdefault_float_dtype)\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m255\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"--- Starting Training Process ---\")\n",
    "overall_training_start_time = time.time() \n",
    "\n",
    "all_train_losses_for_plot = [] \n",
    "all_val_losses_for_plot = []   \n",
    "\n",
    "train_loss_moving_avg_q = deque(maxlen=TRAIN_MOVING_AVG_WINDOW)\n",
    "best_train_loss_ma = BEST_TRAIN_LOSS_MA_FROM_CKPT \n",
    "epochs_without_improvement_train = 0\n",
    "previous_best_train_model_path = PREVIOUS_BEST_TRAIN_MODEL_PATH \n",
    "\n",
    "val_loss_moving_avg_q = deque(maxlen=VAL_MOVING_AVG_WINDOW)\n",
    "best_val_loss_ma = BEST_VAL_LOSS_MA_FROM_CKPT # Initialize best_val_loss_ma\n",
    "previous_best_val_model_path = PREVIOUS_BEST_VAL_MODEL_PATH # Initialize previous_best_val_model_path\n",
    "\n",
    "final_epoch_completed = START_EPOCH -1 # Corrected initialization\n",
    "\n",
    "num_train_batches = len(train_dataloader)\n",
    "num_val_batches = len(val_dataloader)\n",
    "\n",
    "for epoch in range(START_EPOCH, NUM_EPOCHS):\n",
    "    epoch_start_time = time.time()\n",
    "    current_epoch_num_for_log = epoch + 1\n",
    "    # final_epoch_completed = epoch # Moved to end of loop for correct value if early stopping\n",
    "\n",
    "    avg_train_loss = train_denoiser_epoch(\n",
    "        denoiser_model=denoiser, \n",
    "        train_dl=train_dataloader, \n",
    "        opt=optimizer,\n",
    "        grad_clip_val=GRAD_CLIP_VALUE, \n",
    "        device=DEVICE, \n",
    "        epoch_num_for_log=current_epoch_num_for_log,\n",
    "        num_train_batches_total=num_train_batches, \n",
    "        num_val_batches_total=num_val_batches      \n",
    "    )\n",
    "    all_train_losses_for_plot.append(avg_train_loss)\n",
    "    train_loss_moving_avg_q.append(avg_train_loss)\n",
    "    current_train_moving_avg = sum(train_loss_moving_avg_q) / len(train_loss_moving_avg_q) if train_loss_moving_avg_q else float('inf')\n",
    "\n",
    "    avg_val_loss = validate_denoiser_epoch(\n",
    "        denoiser_model=denoiser, \n",
    "        val_dl=val_dataloader, \n",
    "        device=DEVICE, \n",
    "        epoch_num_for_log=current_epoch_num_for_log,\n",
    "        num_train_batches_total=num_train_batches, \n",
    "        num_val_batches_total=num_val_batches      \n",
    "    )\n",
    "    all_val_losses_for_plot.append(avg_val_loss)\n",
    "    val_loss_moving_avg_q.append(avg_val_loss) \n",
    "    current_val_moving_avg = sum(val_loss_moving_avg_q) / len(val_loss_moving_avg_q) if val_loss_moving_avg_q else float('inf')\n",
    "\n",
    "    epoch_duration_seconds = time.time() - epoch_start_time\n",
    "    epoch_duration_formatted = str(datetime.timedelta(seconds=epoch_duration_seconds))\n",
    "\n",
    "    print(f\"Epoch {current_epoch_num_for_log}/{NUM_EPOCHS} - Train Loss: {avg_train_loss:.4f} (MA: {current_train_moving_avg:.4f}), Val Loss: {avg_val_loss:.4f} (MA: {current_val_moving_avg:.4f}), Duration: {epoch_duration_formatted}\")\n",
    "\n",
    "    ### WANDB: Log epoch-level metrics ###\n",
    "    \n",
    "    wandb_log_data = {\n",
    "        \"epoch\": current_epoch_num_for_log,\n",
    "        \"avg_train_loss\": avg_train_loss,\n",
    "        \"train_loss_ma\": current_train_moving_avg,\n",
    "        \"avg_val_loss\": avg_val_loss,\n",
    "        \"val_loss_ma\": current_val_moving_avg,\n",
    "        \"best_val_loss_ma_so_far\": best_val_loss_ma, # Log best val loss MA so far\n",
    "        \"epoch_duration_sec\": epoch_duration_seconds,\n",
    "        \"learning_rate\": optimizer.param_groups[0]['lr']\n",
    "    }\n",
    "    \n",
    "    if lr_scheduler: lr_scheduler.step(avg_val_loss if isinstance(lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau) else None)\n",
    "\n",
    "    # Save model based on Validation Loss MA\n",
    "    if current_val_moving_avg < best_val_loss_ma:\n",
    "        improvement_val_over_absolute_best = (best_val_loss_ma - current_val_moving_avg) / abs(best_val_loss_ma + 1e-9) * 100\n",
    "        print(f\"  Val Loss MA improved to {current_val_moving_avg:.6f} from {best_val_loss_ma:.6f} ({improvement_val_over_absolute_best:.2f}% improvement).\")\n",
    "        best_val_loss_ma = current_val_moving_avg\n",
    "        new_best_val_model_path = os.path.join(config.CHECKPOINT_DIR, \"denoiser_model_best_val_loss.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': denoiser.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_train_loss,\n",
    "            'val_loss': avg_val_loss,\n",
    "            'best_train_loss_ma': best_train_loss_ma, \n",
    "            'best_val_loss_ma': best_val_loss_ma\n",
    "        }, new_best_val_model_path)\n",
    "        print(f\"  Saved new best model (val loss MA) at epoch {current_epoch_num_for_log}\")\n",
    "        if previous_best_val_model_path and previous_best_val_model_path != new_best_val_model_path and os.path.exists(previous_best_val_model_path):\n",
    "            try:\n",
    "                os.remove(previous_best_val_model_path)\n",
    "                print(f\"  Deleted previous best val model: {previous_best_val_model_path}\")\n",
    "            except OSError as e:\n",
    "                print(f\"  Warning: Could not delete previous best val model '{previous_best_val_model_path}': {e}\")\n",
    "        previous_best_val_model_path = new_best_val_model_path\n",
    "\n",
    "    should_stop_early = False\n",
    "    # Early stopping logic (using EARLY_STOPPING_MIN_EPOCHS correctly)\n",
    "    if current_epoch_num_for_log > EARLY_STOPPING_MIN_EPOCHS: # Check after min epochs completed\n",
    "        if current_train_moving_avg < best_train_loss_ma : \n",
    "            # ... (rest of early stopping logic seems okay, ensure it uses current_epoch_num_for_log correctly)\n",
    "            improvement_over_absolute_best = (best_train_loss_ma - current_train_moving_avg) / abs(best_train_loss_ma + 1e-9) * 100\n",
    "            print(f\"  Train Loss MA improved to {current_train_moving_avg:.6f} from {best_train_loss_ma:.6f} ({improvement_over_absolute_best:.2f}% improvement).\")\n",
    "            best_train_loss_ma = current_train_moving_avg\n",
    "            epochs_without_improvement_train = 0\n",
    "            new_best_model_path = os.path.join(config.CHECKPOINT_DIR, \"denoiser_model_best_train_loss.pth\")\n",
    "            torch.save({\n",
    "                'epoch': epoch, 'model_state_dict': denoiser.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(), 'loss': avg_train_loss, \n",
    "                'val_loss': avg_val_loss, 'best_train_loss_ma': best_train_loss_ma,\n",
    "                'best_val_loss_ma': best_val_loss_ma # Also save best_val_loss_ma when saving based on train loss\n",
    "            }, new_best_model_path)\n",
    "            print(f\"  Saved new best model (train loss MA) at epoch {current_epoch_num_for_log}\")\n",
    "            if previous_best_train_model_path and previous_best_train_model_path != new_best_model_path and os.path.exists(previous_best_train_model_path):\n",
    "                try: os.remove(previous_best_train_model_path); print(f\"  Deleted previous best train model: {previous_best_train_model_path}\")\n",
    "                except OSError as e: print(f\"  Warning: Could not delete previous best train model '{previous_best_train_model_path}': {e}\")\n",
    "            previous_best_train_model_path = new_best_model_path\n",
    "        else: \n",
    "            epochs_without_improvement_train += 1\n",
    "            print(f\"  No improvement in train loss MA for {epochs_without_improvement_train} epoch(s). Best MA: {best_train_loss_ma:.6f}, Current MA: {current_train_moving_avg:.6f}\")\n",
    "            if epochs_without_improvement_train >= EARLY_STOPPING_PATIENCE:\n",
    "                # ... (percentage improvement check)\n",
    "                idx_before_streak_started = len(all_train_losses_for_plot) - epochs_without_improvement_train -1 # Index of the epoch before non-improvement streak\n",
    "                # Ensure indices are valid\n",
    "                if idx_before_streak_started >= 0:\n",
    "                    # Calculate MA from historical_losses_for_ma of length TRAIN_MOVING_AVG_WINDOW ending at idx_before_streak_started\n",
    "                    historical_window_start = max(0, idx_before_streak_started - TRAIN_MOVING_AVG_WINDOW + 1)\n",
    "                    historical_losses_for_ma_calc = all_train_losses_for_plot[historical_window_start : idx_before_streak_started + 1]\n",
    "\n",
    "                    if len(historical_losses_for_ma_calc) >= TRAIN_MOVING_AVG_WINDOW // 2 : # Need at least half window\n",
    "                        historical_train_ma = sum(historical_losses_for_ma_calc) / len(historical_losses_for_ma_calc)\n",
    "                        # Improvement is positive if current_train_moving_avg is smaller\n",
    "                        percentage_improvement_vs_historical = (historical_train_ma - current_train_moving_avg) / abs(historical_train_ma + 1e-9) * 100\n",
    "                        print(f\"  Patience met. Current Train MA: {current_train_moving_avg:.6f}, Historical MA before streak ({len(historical_losses_for_ma_calc)} epochs): {historical_train_ma:.6f}. Improvement: {percentage_improvement_vs_historical:.2f}%\")\n",
    "                        if percentage_improvement_vs_historical < EARLY_STOPPING_PERCENTAGE:\n",
    "                            should_stop_early = True\n",
    "                            print(f\"Early stopping triggered: Improvement {percentage_improvement_vs_historical:.2f}% < threshold {EARLY_STOPPING_PERCENTAGE}%.\")\n",
    "                    else:\n",
    "                        print(f\"  Patience met, but not enough historical data ({len(historical_losses_for_ma_calc)} points out of {TRAIN_MOVING_AVG_WINDOW}) to reliably calculate percentage improvement for early stopping.\")\n",
    "                else:\n",
    "                     print(f\"  Patience met, but not enough historical data (idx_before_streak_started = {idx_before_streak_started}) to compare.\")\n",
    "\n",
    "    \n",
    "    if (current_epoch_num_for_log % SAVE_MODEL_EVERY == 0) or (epoch == NUM_EPOCHS - 1):\n",
    "        is_best_this_epoch = current_train_moving_avg == best_train_loss_ma # Check if current MA is the best overall\n",
    "        # Avoid saving regular checkpoint if it's also the best_train_loss epoch to prevent duplicate saves\n",
    "        if not (is_best_this_epoch and os.path.join(config.CHECKPOINT_DIR, \"denoiser_model_best_train_loss.pth\") == previous_best_train_model_path):\n",
    "             torch.save({\n",
    "                'epoch': epoch, 'model_state_dict': denoiser.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(), 'loss': avg_train_loss,\n",
    "                'val_loss': avg_val_loss, 'best_train_loss_ma': best_train_loss_ma, # Save current best_train_loss_ma\n",
    "                'best_val_loss_ma': best_val_loss_ma # Also save best_val_loss_ma for regular epoch saves\n",
    "            }, os.path.join(config.CHECKPOINT_DIR, f\"denoiser_model_epoch_{current_epoch_num_for_log:04d}.pth\"))\n",
    "             print(f\"Saved model checkpoint at epoch {current_epoch_num_for_log}\")\n",
    "    \n",
    "    final_epoch_completed = epoch # Update last completed epoch here\n",
    "    if should_stop_early: break\n",
    "\n",
    "    if (current_epoch_num_for_log % SAMPLE_EVERY == 0) or (epoch == NUM_EPOCHS - 1) or should_stop_early:\n",
    "        print(f\"Epoch {current_epoch_num_for_log}: Generating multiple visualization samples...\")\n",
    "        denoiser.eval()\n",
    "        vis_wandb_log_data = {} # Accumulate images here for a single wandb.log call\n",
    "\n",
    "        # --- 1. Fixed Sample ---\n",
    "        fixed_sample_idx = wandb_config.get('FIXED_VIS_SAMPLE_IDX', 0)\n",
    "        if fixed_sample_idx < len(val_dataset):\n",
    "            print(f\"  Generating fixed sample (index {fixed_sample_idx} from val_dataset)...\")\n",
    "            fixed_sample_data = val_dataset[fixed_sample_idx]\n",
    "            prev_obs_fixed, prev_act_fixed, gt_fixed_batch, gt_prev_frames_fixed_seq = prepare_single_sample_for_sampler(fixed_sample_data, DEVICE) # gt_fixed_batch is [1,C,H,W]\n",
    "            with torch.no_grad():\n",
    "                generated_output_tuple_fixed = diffusion_sampler.sample(prev_obs=prev_obs_fixed, prev_act=prev_act_fixed)\n",
    "            \n",
    "            if generated_output_tuple_fixed:\n",
    "                generated_image_batch_fixed = generated_output_tuple_fixed[0] # This is [1, C, H, W]\n",
    "                if generated_image_batch_fixed.ndim == 4 and generated_image_batch_fixed.shape[0] == 1:\n",
    "                    generated_image_to_save_fixed = generated_image_batch_fixed[0] # Extract single image: [C, H, W]\n",
    "                else:\n",
    "                    generated_image_to_save_fixed = generated_image_batch_fixed # Fallback, though should be 4D\n",
    "    \n",
    "                gt_image_to_save_fixed = gt_fixed_batch[0] # Extract single GT image: [C, H, W]\n",
    "    \n",
    "                vis_path_fixed = save_visualization_samples(\n",
    "                    generated_image_to_save_fixed, # Should be [C,H,W]\n",
    "                    gt_image_to_save_fixed,        # Should be [C,H,W]\n",
    "                    gt_prev_frames_fixed_seq,\n",
    "                    current_epoch_num_for_log,\n",
    "                    config.SAMPLE_DIR,\n",
    "                    prefix=f\"val_vis_fixed_idx{fixed_sample_idx}\"\n",
    "                )\n",
    "                if vis_path_fixed and wandb.run:\n",
    "                    vis_wandb_log_data[f\"validation_samples/fixed_idx_{fixed_sample_idx}\"] = wandb.Image(vis_path_fixed, caption=f\"Epoch {current_epoch_num_for_log} Fixed Sample (Val Idx {fixed_sample_idx})\")\n",
    "            else:\n",
    "                print(\"  Warning: Sampler did not return output for fixed sample.\")\n",
    "        else:\n",
    "            print(f\"  Warning: FIXED_SAMPLE_IDX {fixed_sample_idx} is out of bounds for val_dataset (size {len(val_dataset)}). Skipping fixed sample.\")\n",
    "    \n",
    "        # --- 2. Random Stopped Sample (Action 0.0) ---\n",
    "        if len(val_stopped_subset) > 0:\n",
    "            print(\"  Generating random stopped sample...\")\n",
    "            random_stopped_idx_in_subset = random.randint(0, len(val_stopped_subset) - 1)\n",
    "            stopped_sample_data = val_stopped_subset[random_stopped_idx_in_subset]\n",
    "            prev_obs_stopped, prev_act_stopped, gt_stopped_batch, gt_prev_frames_stopped_seq = prepare_single_sample_for_sampler(stopped_sample_data, DEVICE) # gt_stopped_batch is [1,C,H,W]\n",
    "            with torch.no_grad():\n",
    "                generated_output_tuple_stopped = diffusion_sampler.sample(prev_obs=prev_obs_stopped, prev_act=prev_act_stopped)\n",
    "            \n",
    "            if generated_output_tuple_stopped:\n",
    "                generated_image_batch_stopped = generated_output_tuple_stopped[0] # This is [1, C, H, W]\n",
    "                if generated_image_batch_stopped.ndim == 4 and generated_image_batch_stopped.shape[0] == 1:\n",
    "                    generated_image_to_save_stopped = generated_image_batch_stopped[0] # Extract single image: [C, H, W]\n",
    "                else:\n",
    "                    generated_image_to_save_stopped = generated_image_batch_stopped\n",
    "    \n",
    "                gt_image_to_save_stopped = gt_stopped_batch[0] # Extract single GT image: [C, H, W]\n",
    "    \n",
    "                vis_path_stopped = save_visualization_samples(\n",
    "                    generated_image_to_save_stopped, # Should be [C,H,W]\n",
    "                    gt_image_to_save_stopped,        # Should be [C,H,W]\n",
    "                    gt_prev_frames_stopped_seq,\n",
    "                    current_epoch_num_for_log,\n",
    "                    config.SAMPLE_DIR,\n",
    "                    prefix=\"val_vis_stopped_random\"\n",
    "                )\n",
    "                if vis_path_stopped and wandb.run:\n",
    "                    vis_wandb_log_data[\"validation_samples/random_stopped\"] = wandb.Image(vis_path_stopped, caption=f\"Epoch {current_epoch_num_for_log} Random Stopped Sample\")\n",
    "            else:\n",
    "                print(\"  Warning: Sampler did not return output for stopped sample.\")\n",
    "        else:\n",
    "            print(\"  Warning: No stopped (action 0.0) samples found in validation set. Skipping random stopped sample.\")\n",
    "    \n",
    "        # --- 3. Random Moving Sample ---\n",
    "        moving_action_val_vis = wandb_config.get('MOVING_ACTION_VALUE_FOR_VIS', 0.1)\n",
    "        if len(val_moving_subset) > 0:\n",
    "            print(f\"  Generating random moving sample (action {moving_action_val_vis})...\")\n",
    "            random_moving_idx_in_subset = random.randint(0, len(val_moving_subset) - 1)\n",
    "            moving_sample_data = val_moving_subset[random_moving_idx_in_subset]\n",
    "            prev_obs_moving, prev_act_moving, gt_moving_batch, gt_prev_frames_moving_seq = prepare_single_sample_for_sampler(moving_sample_data, DEVICE) # gt_moving_batch is [1,C,H,W]\n",
    "            with torch.no_grad():\n",
    "                generated_output_tuple_moving = diffusion_sampler.sample(prev_obs=prev_obs_moving, prev_act=prev_act_moving)\n",
    "    \n",
    "            if generated_output_tuple_moving:\n",
    "                generated_image_batch_moving = generated_output_tuple_moving[0] # This is [1, C, H, W]\n",
    "                if generated_image_batch_moving.ndim == 4 and generated_image_batch_moving.shape[0] == 1:\n",
    "                    generated_image_to_save_moving = generated_image_batch_moving[0] # Extract single image: [C, H, W]\n",
    "                else:\n",
    "                    generated_image_to_save_moving = generated_image_batch_moving\n",
    "    \n",
    "                gt_image_to_save_moving = gt_moving_batch[0] # Extract single GT image: [C, H, W]\n",
    "    \n",
    "                vis_path_moving = save_visualization_samples(\n",
    "                    generated_image_to_save_moving, # Should be [C,H,W]\n",
    "                    gt_image_to_save_moving,        # Should be [C,H,W]\n",
    "                    gt_prev_frames_moving_seq,\n",
    "                    current_epoch_num_for_log,\n",
    "                    config.SAMPLE_DIR,\n",
    "                    prefix=f\"val_vis_moving_act{str(moving_action_val_vis).replace('.', 'p')}_random\"\n",
    "                )\n",
    "                if vis_path_moving and wandb.run:\n",
    "                    vis_wandb_log_data[f\"validation_samples/random_moving_act{str(moving_action_val_vis).replace('.', 'p')}\"] = wandb.Image(vis_path_moving, caption=f\"Epoch {current_epoch_num_for_log} Random Moving Sample (Action {moving_action_val_vis})\")\n",
    "            else:\n",
    "                print(\"  Warning: Sampler did not return output for moving sample.\")\n",
    "        else:\n",
    "            print(f\"  Warning: No moving (action {moving_action_val_vis}) samples found in validation set. Skipping random moving sample.\")\n",
    "        \n",
    "        denoiser.train() # Set model back to training mode\n",
    "        # Log all accumulated data for this epoch (losses + images)\n",
    "        if wandb.run:\n",
    "            wandb.log({**wandb_log_data, **vis_wandb_log_data})\n",
    "    elif wandb.run: # If not sampling, still log epoch metrics\n",
    "         wandb.log(wandb_log_data)\n",
    "\n",
    "\n",
    "    if (current_epoch_num_for_log % PLOT_EVERY == 0) or (epoch == NUM_EPOCHS - 1) or should_stop_early :\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(all_train_losses_for_plot, label=\"Avg Train Loss\")\n",
    "        plt.plot(all_val_losses_for_plot, label=\"Avg Validation Loss\")\n",
    "        if len(all_train_losses_for_plot) >= TRAIN_MOVING_AVG_WINDOW:\n",
    "            train_ma_plot = [sum(all_train_losses_for_plot[i-TRAIN_MOVING_AVG_WINDOW+1:i+1])/TRAIN_MOVING_AVG_WINDOW for i in range(TRAIN_MOVING_AVG_WINDOW-1, len(all_train_losses_for_plot))]\n",
    "            plt.plot(range(TRAIN_MOVING_AVG_WINDOW-1, len(all_train_losses_for_plot)), train_ma_plot, label=f'Train Loss MA ({TRAIN_MOVING_AVG_WINDOW} epochs)', linestyle=':')\n",
    "        if len(all_val_losses_for_plot) >= VAL_MOVING_AVG_WINDOW:\n",
    "            val_ma_plot = [sum(all_val_losses_for_plot[i-VAL_MOVING_AVG_WINDOW+1:i+1])/VAL_MOVING_AVG_WINDOW for i in range(VAL_MOVING_AVG_WINDOW-1, len(all_val_losses_for_plot))]\n",
    "            plt.plot(range(VAL_MOVING_AVG_WINDOW-1, len(all_val_losses_for_plot)), val_ma_plot, label=f'Val Loss MA ({VAL_MOVING_AVG_WINDOW} epochs)', linestyle='--')\n",
    "        plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(f\"Progress (Epoch {current_epoch_num_for_log})\")\n",
    "        plt.legend(); plt.grid(True)\n",
    "        plt.savefig(os.path.join(config.PLOT_DIR, f\"loss_plot_epoch_{current_epoch_num_for_log:04d}.png\"))\n",
    "        ### WANDB: Log epoch loss plot ###\n",
    "        wandb.log({\"epoch_loss_plot\": wandb.Image(plt, caption=f\"Loss Plot Epoch {current_epoch_num_for_log}\")})\n",
    "        plt.close()\n",
    "        print(f\"Saved loss plot up to epoch {current_epoch_num_for_log}\")\n",
    "\n",
    "overall_training_end_time = time.time()\n",
    "total_training_duration_seconds = overall_training_end_time - overall_training_start_time\n",
    "total_training_duration_formatted = str(datetime.timedelta(seconds=total_training_duration_seconds))\n",
    "\n",
    "# final_epoch_completed is the last epoch index that ran (0-indexed)\n",
    "print(f\"--- Training Complete (Stopped after epoch {final_epoch_completed + 1}) ---\") \n",
    "print(f\"Total training duration: {total_training_duration_formatted}\") \n",
    "\n",
    "# Final Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(all_train_losses_for_plot, label=\"Avg Train Loss\")\n",
    "plt.plot(all_val_losses_for_plot, label=\"Avg Validation Loss\")\n",
    "if len(all_train_losses_for_plot) >= TRAIN_MOVING_AVG_WINDOW:\n",
    "    train_ma_plot = [sum(all_train_losses_for_plot[i-TRAIN_MOVING_AVG_WINDOW+1:i+1])/TRAIN_MOVING_AVG_WINDOW for i in range(TRAIN_MOVING_AVG_WINDOW-1, len(all_train_losses_for_plot))]\n",
    "    plt.plot(range(TRAIN_MOVING_AVG_WINDOW-1, len(all_train_losses_for_plot)), train_ma_plot, label=f'Train Loss MA ({TRAIN_MOVING_AVG_WINDOW} epochs)', linestyle=':')\n",
    "if len(all_val_losses_for_plot) >= VAL_MOVING_AVG_WINDOW:\n",
    "    val_ma_plot = [sum(all_val_losses_for_plot[i-VAL_MOVING_AVG_WINDOW+1:i+1])/VAL_MOVING_AVG_WINDOW for i in range(VAL_MOVING_AVG_WINDOW-1, len(all_val_losses_for_plot))]\n",
    "    plt.plot(range(VAL_MOVING_AVG_WINDOW-1, len(all_val_losses_for_plot)), val_ma_plot, label=f'Val Loss MA ({VAL_MOVING_AVG_WINDOW} epochs)', linestyle='--')\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(f\"Denoiser Final Training & Validation Loss (Up to Epoch {final_epoch_completed + 1})\")\n",
    "plt.legend(); plt.grid(True)\n",
    "final_loss_plot_path = os.path.join(config.PLOT_DIR, \"denoiser_final_loss_plot.png\")\n",
    "plt.savefig(final_loss_plot_path)\n",
    "# plt.show() # Usually not needed in script, but can be uncommented for interactive\n",
    "print(f\"Final loss plot saved to {final_loss_plot_path}\")\n",
    "\n",
    "### WANDB: Log final loss plot and finish run ###\n",
    "wandb.log({\"final_loss_plot\": wandb.Image(final_loss_plot_path, caption=f\"Final Loss Plot up to Epoch {final_epoch_completed + 1}\")})\n",
    "wandb.finish()\n",
    "print(\"Wandb run finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df2a66-c46d-40eb-9a23-09203bd3883b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
