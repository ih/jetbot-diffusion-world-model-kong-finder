{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2608de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from importnb import Notebook\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.functional import structural_similarity_index_measure as ssim\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import config\n",
    "import models\n",
    "with Notebook():\n",
    "    from jetbot_dataset import JetbotDataset\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70c1f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the model checkpoints (update these as needed)\n",
    "MODEL_A_PATH = \"C:\\Projects\\jetbot-diffusion-world-model-kong-finder-aux\\output_model_5hz_DIAMOND_laundry_30_sessions\\checkpoints\\denoiser_model_best_val_loss.pth\"\n",
    "MODEL_B_PATH = 'model_b.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66627d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded combined CSV with columns: ['session_id', 'image_path', 'timestamp', 'action']\n",
      "Loaded holdout dataset with 1469 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: irvin-hwang (irvin-hwang-simulacra-systems) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Projects\\jetbot-diffusion-world-model-kong-finder\\wandb\\run-20250624_160036-bf9j22ly</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/irvin-hwang-simulacra-systems/model_comparison/runs/bf9j22ly' target=\"_blank\">rare-bee-1</a></strong> to <a href='https://wandb.ai/irvin-hwang-simulacra-systems/model_comparison' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/irvin-hwang-simulacra-systems/model_comparison' target=\"_blank\">https://wandb.ai/irvin-hwang-simulacra-systems/model_comparison</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/irvin-hwang-simulacra-systems/model_comparison/runs/bf9j22ly' target=\"_blank\">https://wandb.ai/irvin-hwang-simulacra-systems/model_comparison/runs/bf9j22ly</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/irvin-hwang-simulacra-systems/model_comparison/runs/bf9j22ly?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x20b840af350>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = JetbotDataset(config.HOLDOUT_CSV_PATH, config.HOLDOUT_DATA_DIR, config.IMAGE_SIZE, config.NUM_PREV_FRAMES, transform=config.TRANSFORM)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "print(f'Loaded holdout dataset with {len(dataset)} samples.')\n",
    "wandb.init(project=\"model_comparison\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b661fa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sampler(checkpoint_path, device):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    inner_cfg = models.InnerModelConfig(\n",
    "        img_channels=config.DM_IMG_CHANNELS,\n",
    "        num_steps_conditioning=config.DM_NUM_STEPS_CONDITIONING,\n",
    "        cond_channels=config.DM_COND_CHANNELS,\n",
    "        depths=config.DM_UNET_DEPTHS,\n",
    "        channels=config.DM_UNET_CHANNELS,\n",
    "        attn_depths=config.DM_UNET_ATTN_DEPTHS,\n",
    "        num_actions=config.DM_NUM_ACTIONS,\n",
    "        is_upsampler=config.DM_IS_UPSAMPLER\n",
    "    )\n",
    "    denoiser_cfg = models.DenoiserConfig(\n",
    "        inner_model=inner_cfg,\n",
    "        sigma_data=config.DM_SIGMA_DATA,\n",
    "        sigma_offset_noise=config.DM_SIGMA_OFFSET_NOISE,\n",
    "        noise_previous_obs=config.DM_NOISE_PREVIOUS_OBS,\n",
    "        upsampling_factor=config.DM_UPSAMPLING_FACTOR\n",
    "    )\n",
    "    denoiser = models.Denoiser(cfg=denoiser_cfg).to(device)\n",
    "    denoiser.load_state_dict(checkpoint['model_state_dict'])\n",
    "    denoiser.eval()\n",
    "    sampler_cfg = models.DiffusionSamplerConfig(\n",
    "        num_steps_denoising=config.SAMPLER_NUM_STEPS,\n",
    "        sigma_min=config.SAMPLER_SIGMA_MIN,\n",
    "        sigma_max=config.SAMPLER_SIGMA_MAX,\n",
    "        rho=config.SAMPLER_RHO,\n",
    "        order=getattr(config, 'SAMPLER_ORDER', 1),\n",
    "        s_churn=getattr(config, 'SAMPLER_S_CHURN', 0.0)\n",
    "    )\n",
    "    return models.DiffusionSampler(denoiser=denoiser, cfg=sampler_cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce15efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_quantitative(sampler, dataloader, device, num_prev_frames, action_tolerance=1e-6):\n",
    "    sampler.denoiser.eval()\n",
    "    metrics={'overall':{'mse':[], 'ssim':[]}}\n",
    "    with torch.no_grad():\n",
    "        for current_img, action_tensor, prev_frames_tensor in tqdm(dataloader, desc='Evaluating'):\n",
    "            current_img=current_img.to(device)\n",
    "            action_tensor=action_tensor.to(device)\n",
    "            prev_frames_tensor=prev_frames_tensor.to(device)\n",
    "            prev_obs=prev_frames_tensor.view(1, num_prev_frames, current_img.shape[1], current_img.shape[2], current_img.shape[3])\n",
    "            prev_act=action_tensor.long().repeat(1, num_prev_frames)\n",
    "            pred,_=sampler.sample(prev_obs=prev_obs, prev_act=prev_act)\n",
    "            mse=F.mse_loss(pred, current_img).item()\n",
    "            pred_normalized=(pred.clamp(-1,1)+1)/2\n",
    "            gt_normalized=(current_img.clamp(-1,1)+1)/2\n",
    "            ssim_val=ssim(pred_normalized, gt_normalized, data_range=1.0).item()\n",
    "            metrics['overall']['mse'].append(mse)\n",
    "            metrics['overall']['ssim'].append(ssim_val)\n",
    "            key=0.0 if abs(action_tensor.item())<action_tolerance else float(action_tensor.item())\n",
    "            if key not in metrics:\n",
    "                metrics[key]={'mse':[], 'ssim':[]}\n",
    "            metrics[key]['mse'].append(mse)\n",
    "            metrics[key]['ssim'].append(ssim_val)\n",
    "    avg_metrics={}\n",
    "    for k,v in metrics.items():\n",
    "        if v['mse']:\n",
    "            avg_metrics[k]={\n",
    "                'avg_mse': float(np.mean(v['mse'])),\n",
    "                'avg_ssim': float(np.mean(v['ssim'])),\n",
    "                'count': len(v['mse'])\n",
    "            }\n",
    "        else:\n",
    "            avg_metrics[k]={'avg_mse': float('nan'), 'avg_ssim': float('nan'), 'count':0}\n",
    "    return avg_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e11dc8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_alternating(sampler_a, sampler_b, dataloader, device, num_prev_frames):\n",
    "    metrics = {'A': {'mse': [], 'ssim': []}, 'B': {'mse': [], 'ssim': []}}\n",
    "    with torch.no_grad():\n",
    "        for idx, (current_img, action_tensor, prev_frames_tensor) in enumerate(tqdm(dataloader, desc='Evaluating')):\n",
    "            current_img = current_img.to(device)\n",
    "            action_tensor = action_tensor.to(device)\n",
    "            prev_frames_tensor = prev_frames_tensor.to(device)\n",
    "            prev_obs = prev_frames_tensor.view(1, num_prev_frames, current_img.shape[1], current_img.shape[2], current_img.shape[3])\n",
    "            prev_act = action_tensor.long().repeat(1, num_prev_frames)\n",
    "            pred_a, _ = sampler_a.sample(prev_obs=prev_obs, prev_act=prev_act)\n",
    "            pred_b, _ = sampler_b.sample(prev_obs=prev_obs, prev_act=prev_act)\n",
    "            for key, pred in [('A', pred_a), ('B', pred_b)]:\n",
    "                mse = F.mse_loss(pred, current_img).item()\n",
    "                pred_norm = (pred.clamp(-1,1)+1)/2\n",
    "                gt_norm = (current_img.clamp(-1,1)+1)/2\n",
    "                ssim_val = ssim(pred_norm, gt_norm, data_range=1.0).item()\n",
    "                metrics[key]['mse'].append(mse)\n",
    "                metrics[key]['ssim'].append(ssim_val)\n",
    "                avg_mse = float(np.mean(metrics[key]['mse']))\n",
    "                avg_ssim = float(np.mean(metrics[key]['ssim']))\n",
    "                print(f'Sample {idx} Model {key} -> MSE: {mse:.4f}, SSIM: {ssim_val:.4f}, Avg MSE: {avg_mse:.4f}, Avg SSIM: {avg_ssim:.4f}')\n",
    "                wandb.log({f\"{key}/mse\": mse, f\"{key}/ssim\": ssim_val, f\"{key}/avg_mse\": avg_mse, f\"{key}/avg_ssim\": avg_ssim, \"sample_idx\": idx})\n",
    "    results = {}\n",
    "    for key, vals in metrics.items():\n",
    "        if vals['mse']:\n",
    "            results[key] = {\n",
    "                'avg_mse': float(np.mean(vals['mse'])),\n",
    "                'avg_ssim': float(np.mean(vals['ssim'])),\n",
    "                'count': len(vals['mse'])\n",
    "            }\n",
    "        else:\n",
    "            results[key] = {'avg_mse': float('nan'), 'avg_ssim': float('nan'), 'count': 0}\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b523bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8e0a9e342741ed85a7d6770709df30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\pythonenv-deeprl\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:70: FutureWarning: Importing `spectral_angle_mapper` from `torchmetrics.functional` was deprecated and will be removed in 2.0. Import `spectral_angle_mapper` from `torchmetrics.image` instead.\n",
      "  _future_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 Model A -> MSE: 0.0077, SSIM: 0.8767, Avg MSE: 0.0077, Avg SSIM: 0.8767\n",
      "Sample 0 Model B -> MSE: 0.0077, SSIM: 0.8761, Avg MSE: 0.0077, Avg SSIM: 0.8761\n",
      "Sample 1 Model A -> MSE: 0.0081, SSIM: 0.8686, Avg MSE: 0.0079, Avg SSIM: 0.8726\n",
      "Sample 1 Model B -> MSE: 0.0081, SSIM: 0.8686, Avg MSE: 0.0079, Avg SSIM: 0.8723\n"
     ]
    }
   ],
   "source": [
    "device = config.DEVICE\n",
    "sampler_a = load_sampler(MODEL_A_PATH, device)\n",
    "sampler_b = load_sampler(MODEL_A_PATH, device)\n",
    "results = evaluate_models_alternating(sampler_a, sampler_b, dataloader, device, config.NUM_PREV_FRAMES)\n",
    "print('Model A Overall:', results.get('A'))\n",
    "print('Model B Overall:', results.get('B'))\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b03e1-5e7b-4501-85f5-d0fa8c8279f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
